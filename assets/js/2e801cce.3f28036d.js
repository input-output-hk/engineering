"use strict";(self.webpackChunkengineering_iog_io=self.webpackChunkengineering_iog_io||[]).push([[9450],{6029:function(e){e.exports=JSON.parse('{"blogPosts":[{"id":"2022-08-01-ghc-update","metadata":{"permalink":"/2022-08-01-ghc-update","source":"@site/blog/2022-08-01-ghc-update-2022-07.md","title":"GHC DevX July 2022 Update","description":"This is the July 2022 monthly update from the GHC DevX team at IOG.","date":"2022-08-01T00:00:00.000Z","formattedDate":"August 1, 2022","tags":[{"label":"ghc","permalink":"/tags/ghc"}],"readingTime":1.25,"truncated":false,"authors":[{"name":"Sylvain Henry","title":"Haskell DevX Engineer @ IOG","email":"sylvain.henry@iohk.io","key":"sylvain"}],"frontMatter":{"slug":"2022-08-01-ghc-update","title":"GHC DevX July 2022 Update","authors":["sylvain"],"tags":["ghc"]},"nextItem":{"title":"The GHCJS Linker","permalink":"/2022-07-26-the-ghcjs-linker"}},"content":"This is the July 2022 monthly update from the GHC DevX team at IOG.\\n\\n## JavaScript Backend for GHC\\n\\nFor a few months we have been merging GHCJS (Haskell to JavaScript compiler)\\ninto GHC. We set our first milestone to be the ability to compile and to run the\\nusual \\"Hello World\\" program. This month we finally reached it!\\n\\nWe are now focusing on:\\n\\n- fixing failing tests in GHC\'s testsuite (~2800 unexpected failures). To do that, we\\n  have to implement new primops, to fix bugs we introduced while we ported the\\n  code from GHCJS, etc.\\n\\n- implementing support for the \\"js-sources\\" Cabal stanza in Hadrian. Currently\\n  the JS backend finds the JS sources required for the RTS and for base into\\n  explicitly defined location. It was only a stop-gap measure and we now need to\\n  implement proper support for user-provided JavaScript files.\\n\\n- documenting and refactoring the source code and making it similar to other GHC\\n  modules. As an example, GHCJS used the text package which isn\'t a boot\\n  package. Hence we first switched to use GHC\'s ShortText implementation and now\\n  we switched to a FastString based implementation.\\n\\n- adding back GHCJS\'s features that we haven\'t ported for some reasons (e.g. the\\n  compactor, TH, etc.).\\n\\nYou can follow our progress on our development branch\\n[here](https://gitlab.haskell.org/ghc/ghc/-/tree/wip/js-staging).\\n\\n## Blog posts\\n\\nFor the time being, we will focus blog post topics on GHCJS internals and\\nrelated topics. A few of these blog posts are currently under review and should\\nbe published shortly."},{"id":"2022-07-26-the-ghcjs-linker","metadata":{"permalink":"/2022-07-26-the-ghcjs-linker","source":"@site/blog/2022-07-26-ghcjs-linker.md","title":"The GHCJS Linker","description":"Introduction","date":"2022-07-26T00:00:00.000Z","formattedDate":"July 26, 2022","tags":[{"label":"ghc","permalink":"/tags/ghc"},{"label":"javascript","permalink":"/tags/javascript"},{"label":"linking","permalink":"/tags/linking"}],"readingTime":5.125,"truncated":false,"authors":[{"name":"Luite Stegeman","title":"Haskell DevX Engineer @ IOG","email":"luite.stegeman@iohk.io","key":"luite"}],"frontMatter":{"slug":"2022-07-26-the-ghcjs-linker","title":"The GHCJS Linker","date":"July 26, 2022","authors":["luite"],"tags":["ghc","javascript","linking"]},"prevItem":{"title":"GHC DevX July 2022 Update","permalink":"/2022-08-01-ghc-update"},"nextItem":{"title":"Primitive Type Representation in GHC\'s upcoming JS-backend","permalink":"/2022-07-20-js-backend-prim-types"}},"content":"## Introduction\\n\\nI recently gave a short presentation on the workings of the GHCJS linker. This post is a summary of the content.\\n\\n## JavaScript \\"executables\\"\\n\\nThe task of a linker is collecting and organizing object files and resources into a loadable library or executable program. JavaScript can be run in various environments, for example the browser or node.js, and not in all of these the concept of an executable makes sense.\\n\\nTherefore, when we link a Haskell program, we generate a `jsexe` directory filled with various files that allow us to run the JavaScript result:\\n\\n| File        | Description          |\\n| :----:        | :---:             |\\n| `out.js`      | compiled/linked Haskell code          |\\n| `out.frefs.*` | list of foreign calls from `out.js` |\\n| `out.stats`   | source code size origin statistics for `out.js` |\\n| `lib.js`      | non-Haskell code, from `js-sources` in packages and RTS. possibly preprocessed |\\n| `rts.js`      | generated part of RTS (apply functions and similarly repetitive things) |\\n| `runmain.js`  | single line just starts `main` |\\n| `all.js`      | complete runnable program, created by combining `out.js`, `lib.js`, `rts.js` and `runmain.js` |\\n\\nMost of the work done by the linker is producing `out.js`, and that\'s what we\'ll be focusing on in the next sections.\\n\\n## Building `out.js`\\n\\nThe linker builds `out.js` by collecting all code reachable from `main` (and a few other symbols required by the RTS) and generating the required initialization code for all top-level data. The code is found in object files. These object files have the following structure:\\n\\n| Section        | Description          |\\n| :----:        | :---:             |\\n| Header       | version number and offsets of other sections       |\\n| String table | shared string table, referred to by `Dependencies` and `Code`, to avoid duplication in file and memory |\\n| Dependencies | Dependency data, internally between binding groups and externally to symbols in other object files |\\n| Code         | Compiled Haskell code stored as serialized JavaScript AST and metadata. Code is organized in binding groups |\\n\\nThe object files contain binding groups of mutually dependent bindings. These are the smallest units of code that can be linked. Each binding group has some associated metadata required for initialization of the heap objects in the group. The metadata contains for example constructor tags (e.g. 1 for `Nothing`, 2 for `Just`), the arity of functions and static reference tables.\\n\\nFrom a high level, the procedure that the linker follows is this:\\n\\n| Step |\\n| :---: |\\n| Read object files from dependencies into memory |\\n| Decode dependency part of all object files in dependencies (includes reading the string tables) |\\n| Using dependency data, find all code reachable from `main` |\\n| Decode reachable binding groups |\\n| Render AST to JavaScript |\\n| Construct initializers from metadata | \\n\\nWe avoid decoding (deserializing) the binding groups that do end up in the linked result to keep the memory consumption lower. Still the linker requires a lot of memory for larger programs, so we may need to make more improvements in the future.\\n\\n## The Compactor\\n\\nThe compactor is an optional link-time transformation step that reduces code size. It consists of a lightweight (i.e. no expensive operations like dataflow analysis) rewrite of the code contained in the object files. The compactor is disabled when linking with the `-debug` flag. There are a few steps involved.\\n\\n### Renaming private symbols\\n\\nHaskell names are quite long by default: they need to be globally unique, hence they contain their defining unit-id and module name. For example: `mtl-2.2.2-somehash-Control.Monad.State.Lazy.execState_go1` (special characters would be z-encoded but it isn\'t shown here).\\n\\nPrivate symbols are only referred to from within the same module. It doesn\'t matter which JavaScript name we pick for them, as long as there is no overlap between the names from different modules. The compactor renames all the private symbols using a global sequence to ensure short names that do not overlap.\\n\\n### Block Initializer\\n\\nWithout the compactor, the linker generates an `h$initObj` initialization call (or `h$o`) call for each global Haskell heap value. The code for this can get quite big. The compactor collects all heap objects to be initialized in a single large array and encodes the metadata in a string. This makes the initialization code much more compact.\\n\\n### Deduplication\\n\\nAn optional step in the compactor is deduplication of code. When deduplication is enabled with the `-dedupe` flag, the compactor looks for functionally equivalent pieces of JavaScript in the output and merges them. This can result in a significant reduction of code size.\\n\\n## Incremental Linking\\n\\nThe linker supports building programs that are loaded incrementally. This is used for example for Template Haskell. The process that runs the Template Haskell stays alive during compilation of a whole module. When the first Template Haskell expression is compiled, it is linked against all its dependencies (including the RTS) and the resulting JavaScript code is sent over to be run in the evaluator process.\\n\\nAs subsequent Template Haskell expressions are evaluated in the same process, there is no need to load already loaded dependencies (including the RTS) again and it is much more efficient to avoid doing so. Therefore the linker keeps track of which dependencies have already been linked and each subsequent TH expression is only linked against dependencies that are not already loaded in the evaluator process.\\n\\nIt\'s also possible for users to use this functionality directly, with the `-generate-base` to create a \\"linker state\\" file along with the regular `jsexe` files. Another program can then be linked with `-use-base=state_file`, resulting in a program which leaves out everything already present in the first program.\\n\\n## Future Improvements\\n\\nMemory consumption is the biggest problem in the linker at the moment. Possible ways to achieve this are compression, more efficient representation of the data structures or more incremental loading of the parts from the object files that we need.\\n\\nIn terms of functionality, we don\'t take advantage of JavaScript modules yet. It would be good if we could improve the linker to support linking a library as a JavaScript module. We should also consider making use of `foreign export javascript` for this purpose."},{"id":"2022-07-20-js-backend-prim-types","metadata":{"permalink":"/2022-07-20-js-backend-prim-types","source":"@site/blog/2022-07-20-js-backend-prim-types.md","title":"Primitive Type Representation in GHC\'s upcoming JS-backend","description":"1.  GHC Primitives","date":"2022-07-20T00:00:00.000Z","formattedDate":"July 20, 2022","tags":[{"label":"ghc","permalink":"/tags/ghc"},{"label":"javascript","permalink":"/tags/javascript"},{"label":"explanation","permalink":"/tags/explanation"},{"label":"knowledge_engineering","permalink":"/tags/knowledge-engineering"}],"readingTime":10.455,"truncated":false,"authors":[{"name":"Jeffrey M. Young","title":"Haskell DevX Engineer @ IOG","url":"https://iog.io/en/","key":"doyougnu"},{"name":"Sylvain Henry","title":"Haskell DevX Engineer @ IOG","email":"sylvain.henry@iohk.io","key":"sylvain"}],"frontMatter":{"slug":"2022-07-20-js-backend-prim-types","title":"Primitive Type Representation in GHC\'s upcoming JS-backend","date":"July 20, 2022","authors":["doyougnu","sylvain"],"tags":["ghc","javascript","explanation","knowledge_engineering"]},"prevItem":{"title":"The GHCJS Linker","permalink":"/2022-07-26-the-ghcjs-linker"},"nextItem":{"title":"Lightweight Haskell Threads on JavaScript","permalink":"/2022-07-18-lightweight-threads-on-JavaScript"}},"content":"1.  [GHC Primitives](#orge86cd4a)\\n    1.  [The Easy Cases](#org75a0c27)\\n    2.  [ByteArray#, MutableByteArray#, SmallArray#, MutableSmallArray#,](#org5eb1aee)\\n    3.  [Addr# and StablePtr#](#org0de7f9e)\\n    4.  [Numbers: The Involved Case](#orgfa8aeb4)\\n        1.  [Working with 64-bit Types](#orgc9d245e)\\n        2.  [Unwrapped Number Optimization](#org453f9cc)\\n    5.  [But what about the other stuff!](#org2e2e79e)\\n\\nOne of the key challenges in any novel backend is representing GHC primitive\\ntypes in the new backend. For JavaScript, this is especially tricky, as\\nJavaScript only has 8 primitive types and some of those types, such as `number` do\\nnot directly map to any Haskell primitive type, such as `Int8#`. This post walks\\nthrough the most important GHC primitives and describes our implementation for\\neach in the JavaScript backend. This post is intended to be an\\nexplanation-oriented post, light on details, but just enough to understand how\\nthe system works.\\n\\n\\n<a id=\\"orge86cd4a\\"></a>\\n\\n# GHC Primitives\\n\\nThere are 36 `primtype`s that GHC defines in `primops.txt.pp`:\\n\\n1.  `Char#`\\n2.  `Int8#`, `Int16#`, `Int32#`, `Int64#`, `Int#`\\n3.  `Word8#`, `Word16#`, `Word32#`, `Word64#`, `Word#`\\n4.  `Double#`, `Float#`,\\n5.  `Array#`, `MutableArray#`,, `SmallArray#`, `SmallMutableArray#`\\n6.  `ByteArray#`, `MutableByteArray#`\\n7.  `Addr#`\\n8.  `MutVar#`, `TVar#`, `MVar#`,\\n9.  `IOPort#`, `State#`, `RealWorld`, `ThreadId#`\\n10. `Weak#`, `StablePtr#`, `StableName#`, `Compact#`, `BCO`,\\n11. `Fun`, `Proxy#`\\n12. `StackSnapshot#`\\n13. `VECTOR`\\n\\nSome of these are unsupported in the JS-backend, such as `VECTOR` or lower\\npriority such as `StackSnapshot#`. We&rsquo;ll begin with the easy cases.\\n\\n\\n<a id=\\"org75a0c27\\"></a>\\n\\n## The Easy Cases\\n\\nThe easy cases are the cases that are implemented as JavaScript objects. In\\ngeneral, this is the big hammer used when nothing else will do. We&rsquo;ll expand on\\nthe use of objects&#x2014;especially representing heap objects&#x2014;in a future post,\\nbut for the majority of cases we mimic the STG-machine behavior for GHC heap\\nobjects using JavaScript heap objects. For example,\\n\\n    var someConstructor =\\n        { f  =                   // entry function of the datacon worker\\n        , m  = 0                 // garbage collector mark\\n        , d1 = first arg         // First data field for the constructor\\n        , d2 = arity = 2: second arg // second field, or object containing the remaining fields\\n               arity > 2: { d1, d2, ...} object with remaining args (starts with \\"d1 = x2\\"!)\\n        }\\n\\nThis is the general recipe; we define a JavaScript object that contains\\nproperties which correspond to the entry function of the heap object; in this\\ncase that is the entry function, `f` for a constructor, some meta data for garbage\\ncollection `m`, and pointers to the fields of the constructor or whatever else the\\nheap object might need. Using JavaScript objects allows straightforward\\ntranslations of several GHC types. For example `TVar`s and `MVar`s:\\n\\n    // stg.js.pp\\n    /** @constructor */\\n    function h$TVar(v) {\\n        TRACE_STM(\\"creating TVar, value: \\" + h$collectProps(v));\\n        this.val        = v;           // current value\\n        this.blocked    = new h$Set(); // threads that get woken up if this TVar is updated\\n        this.invariants = null;        // invariants that use this TVar (h$Set)\\n        this.m          = 0;           // gc mark\\n        this._key       = ++h$TVarN;   // for storing in h$Map/h$Set\\n    #ifdef GHCJS_DEBUG_ALLOC\\n        h$debugAlloc_notifyAlloc(this);\\n    #endif\\n    }\\n\\n    // stm.js.pp\\n    function h$MVar() {\\n      TRACE_SCHEDULER(\\"h$MVar constructor\\");\\n      this.val     = null;\\n      this.readers = new h$Queue();\\n      this.writers = new h$Queue();\\n      this.waiters = null;  // waiting for a value in the MVar with ReadMVar\\n      this.m       = 0; // gc mark\\n      this.id      = ++h$mvarId;\\n    #ifdef GHCJS_DEBUG_ALLOC\\n      h$debugAlloc_notifyAlloc(this);\\n    #endif\\n    }\\n\\nNotice that both implementations defined properties specific to the semantics of\\nthe Haskell type. JavaScript functions which create these objects follow the\\nnaming convention `h$<something>` and reside in *Shim* files. *Shim* files are\\nJavaScript files that the JS-backend links against and are written in pure\\nJavaScript. This allows us to save some compile time by not generating code\\nwhich doesn&rsquo;t change, and decompose the backend into JavaScript modules.\\n\\nThis strategy is also how functions are implemented in the JS-backend. Function\\nobjects are generated by `StgToJS.Expr.genExpr` and `StgToJS.Apply.genApp` but\\nfollow this recipe:\\n\\n    var myFUN =\\n     { f  = <function itself>\\n     , m  = <garbage collector mark>\\n     , d1 = free variable 1\\n     , d2 = free variable 2\\n     }\\n\\nTo summarize; for most cases we write custom JavaScript objects which hold\\nwhatever machinery is needed as properties to satisfy the expected semantics of\\nthe Haskell type. This is the strategy that implements: `TVar`, `MVar`, `MutVar` and\\n`Fun`.\\n\\n\\n<a id=\\"org5eb1aee\\"></a>\\n\\n## ByteArray#, MutableByteArray#, SmallArray#, MutableSmallArray#,\\n\\n`ByteArray#` and friends map to JavaScript\'s\\n[`ArrayBuffer`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/ArrayBuffer)\\nobject. The `ArrayBuffer` object provides a fixed-length, raw binary data\\nbuffer. To index into the `ArrayBuffer` we need to know the type of data the\\nbuffer is expected to hold. So we make engineering tradeoff; we allocate typed\\nviews of the buffer payload once at buffer allocation time. This prevents\\nallocations from views later when we might be handling the buffer in a hot loop,\\nat the cost of slower initialization. For example, consider the `mem.js.pp`\\nshim, which defines `ByteArray#`:\\n\\n    // mem.js.pp\\n    function h$newByteArray(len) {\\n      var len0 = Math.max(h$roundUpToMultipleOf(len, 8), 8);\\n      var buf = new ArrayBuffer(len0);\\n      return { buf: buf\\n             , len: len\\n             , i3: new Int32Array(buf)\\n             , u8: new Uint8Array(buf)\\n             , u1: new Uint16Array(buf)\\n             , f3: new Float32Array(buf)\\n             , f6: new Float64Array(buf)\\n             , dv: new DataView(buf)\\n             , m: 0\\n             }\\n    }\\n\\n `buf` is the payload of the `ByteArray#`, `len` is the length of the\\n`ByteArray#`. `i3` to `dv` are the _views_ of the payload; each view is an\\nobject which interprets the raw data in `buf` differently according to type. For\\nexample, `i3` interprets `buf` as holding `Int32`, while `dv` interprets `buf`\\nas a\\n[`DataView`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/DataView)\\nand so on. The final property, `m`, is the garbage collector marker.\\n\\n\\n<a id=\\"org0de7f9e\\"></a>\\n\\n## Addr# and StablePtr#\\n\\n`Addr#` and `StablePtr#` are implemented as a pair of `ByteArray#` and an `Int#`\\noffset into the array. We&rsquo;ll focus on `Addr#` because `StablePtr#` is the\\nsame implementation, with the exception that the `StablePtr#` is tracked in the\\nglobal variable `h$stablePtrBuf`. `Addr#`s do not have an explicit constructor,\\nrather they are implicitly constructed. For example, consider `h$rts_mkPtr`\\nwhich creates a `Ptr` that contains an `Addr#`:\\n\\n    function h$rts_mkPtr(x) {\\n      var buf, off = 0;\\n      if(typeof x == \'string\') {\\n    \\n        buf = h$encodeUtf8(x);\\n        off = 0;\\n      } else if(typeof x == \'object\' &&\\n         typeof x.len == \'number\' &&\\n         x.buf instanceof ArrayBuffer) {\\n    \\n        buf = x;\\n        off = 0;\\n      } else if(x.isView) {\\n    \\n        buf = h$wrapBuffer(x.buffer, true, 0, x.buffer.byteLength);\\n        off = x.byteOffset;\\n      } else {\\n    \\n        buf = h$wrapBuffer(x, true, 0, x.byteLength);\\n        off = 0;\\n      }\\n      return (h$c2(h$baseZCGHCziPtrziPtr_con_e, (buf), (off)));\\n    }\\n\\nThe function does some type inspection to check for the special case on\\n`string`. If we do not have a string then a `Ptr`, which contains an `Addr#`, is\\nreturned. The `Addr#` is implicitly constructed by allocating a new\\n`ArrayBuffer` and an offset into that buffer. The `object` case is an idempotent\\ncheck; if the input is already such a `Ptr`, then just return the input. The\\ncases which do the work are the cases which call to `h$wrapBuffer`:\\n\\n    // mem.js.pp\\n    function h$wrapBuffer(buf, unalignedOk, offset, length) {\\n      if(!unalignedOk && offset && offset % 8 !== 0) {\\n        throw (\\"h$wrapBuffer: offset not aligned:\\" + offset);\\n      }\\n      if(!buf || !(buf instanceof ArrayBuffer))\\n        throw \\"h$wrapBuffer: not an ArrayBuffer\\"\\n      if(!offset) { offset = 0; }\\n      if(!length || length < 0) { length = buf.byteLength - offset; }\\n      return { buf: buf\\n             , len: length\\n             , i3: (offset%4) ? null : new Int32Array(buf, offset, length >> 2)\\n             , u8: new Uint8Array(buf, offset, length)\\n             , u1: (offset%2) ? null : new Uint16Array(buf, offset, length >> 1)\\n             , f3: (offset%4) ? null : new Float32Array(buf, offset, length >> 2)\\n             , f6: (offset%8) ? null : new Float64Array(buf, offset, length >> 3)\\n             , dv: new DataView(buf, offset, length)\\n             };\\n    }\\n\\n`h$wrapBuffer` is a utility function that does some offset checks and performs\\nthe allocation for the typed views as described above.\\n\\n\\n<a id=\\"orgfa8aeb4\\"></a>\\n\\n## Numbers: The Involved Case\\n\\nTranslating numbers has three issues. First, JavaScript has no concept of\\nfixed-precision 64-bit types such as `Int64#` and `Word64#`. Second, JavaScript\\nbitwise operators only support _signed_ 32-bit values (except the unsigned\\n[right\\nshift](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Unsigned_right_shift)\\noperator of course). Third, numbers are atomic types and do not require any\\nspecial properties for correct semantics, thus using wrapping objects gains us\\nnothing at the cost of indirection.\\n\\n\\n<a id=\\"orgc9d245e\\"></a>\\n\\n### Working with 64-bit Types\\n\\nTo express 64-bit numerics, we simply use two 32-bit numbers, one to express\\nthe high bits, one for the low bits. For example, consider comparing two `Int64#:`\\n\\n    // arith.js.pp\\n    function h$hs_ltInt64(h1,l1,h2,l2) {\\n      if(h1 === h2) {\\n        var l1s = l1 >>> 1;\\n        var l2s = l2 >>> 1;\\n        return (l1s < l2s || (l1s === l2s && ((l1&1) < (l2&1)))) ? 1 : 0;\\n      } else {\\n        return (h1 < h2) ? 1 : 0;\\n      }\\n    }\\n\\nThe less than comparison function expects four inputs, two for each `Int64#` in\\nHaskell. The first number is represented by `h1` and `l1` (*high* and *low*),\\nand similarly the second number is represented by `h2` and `l2`. The comparison\\nis straightforward, we check equivalence of our high bits, if equal then we\\ncheck the lower bits while being careful with signedness. No surprises here.\\n\\nFor the bitwise operators we store both `Word32#` and `Word#` as 32-bit signed\\nvalues, and then map any values greater or equal `2^31` bits to negative values.\\nThis way we stay within the 32-bit range even though in Haskell these types only\\nsupport nonnegative values.\\n\\n\\n<a id=\\"org453f9cc\\"></a>\\n\\n### Unwrapped Number Optimization\\n\\nThe JS backend uses JavaScript values to represent both Haskell heap objects and\\nunboxed values (note that this isn\'t the only possible implementation, see\\n[^1]). As such, it doesn\'t require that all heap objects have the same\\nrepresentation (e.g. a JavaScript object with a \\"tag\\" field indicating its type)\\nbecause we can rely on JS introspection for the same purpose (especially\\n`typeof`). Hence this optimization consists in using a more efficient JavaScript\\ntype to represent heap objects when possible, and to fallback on the generic\\nrepresentation otherwise.\\n\\nThis optimization particularly applies to `Boxed` numeric values (`Int`, `Word`,\\n`Int8`, etc.) which can be directly represented with a JavaScript number,\\nsimilarly to how unboxed `Int#`, `Word#`, `Int8#`, etc. values are represented.\\n\\nPros:\\n\\n- Fewer allocations and indirections: instead of one JavaScript object with a\\n  field containing a number value, we directly have the number value.\\n\\nCons:\\n\\n- More complex code to deal with heap objects that can have different\\n  representations\\n\\nThe optimization is applicable when:\\n\\n1.  We have a single data type with a single data constructor.\\n2.  The constructor holds a single field that *can only* be a particular type.\\n\\nIf these invariants hold then, we remove the wrapping object and instead refer\\nto the value held by the constructor directly. `Int8` is the simplest case for\\nthis optimization. In Haskell we have:\\n\\n    data Int8 = Int8 Int8#\\n\\nNotice that this definition satisfies the requirements. A direct translation in\\nthe JS backend would be:\\n\\n    // An Int8 Thunk represented as an Object with an entry function, f\\n    // and payload, d1.\\n    var anInt8 = { d1 = <Int8# payload>\\n                 , f  : entry function which would scrutinize the payload\\n                 }\\n\\nWe can operationally distinguish between a `Thunk` and an `Int8` because these\\nwill have separate types in the `StgToJS` GHC pass and will have separate types\\n(`object` vs `number`) at runtime. In contrast, in Haskell an `Int8` may\\nactually be a `Thunk` until it is scrutinized *and then* becomes the `Int8`\\npayload (i.e., call-by-need). So this means that we will always know when we\\nhave an `Int8` rather than a `Thunk` and therefore we can omit the wrapper\\nobject and convert this code to just:\\n\\n    // no object, just payload\\n    var anInt8 = = <Int8# payload>\\n\\nFor the interested reader, this optimization takes place in the JavaScript code\\ngenerator module `GHC.StgToJS.Arg`, specifically the functions `allocConStatic`,\\n`isUnboxableCon`, and `primRepVt`.\\n\\n\\n<a id=\\"org2e2e79e\\"></a>\\n\\n## But what about the other stuff!\\n\\n-   `Char#`: is represented by a `number`, i.e., the [code point](https://en.wikipedia.org/wiki/Code_point)\\n-   `Float#/Double#`: Both represented as a JavaScript Double. This means that\\n    `Float#` has excess precision and thus we do not generate exactly the same\\n    answers as other platforms which are IEEE754 compliant. Full emulation of\\n    single precision Floats does not seem to be worth the effort as of writing.\\n    Our implementation represents these in a `ByteArray#`, where each `Float#`\\n    takes 4 bytes in the `ByteArray#`. This means that the precision is reduced\\n    to a 32-bit Float.\\n\\n[^1]: An alternative approach would be to use some JS ArrayBuffers as memory\\n    blocks into which Haskell values and heap objects would be allocated. As an\\n    example this is the approach used by the Asterius compiler. The RTS would\\n    then need to be much more similar to the C RTS and the optimization\\n    presented in this section wouldn\'t apply because we couldn\'t rely on\\n    introspection of JS values."},{"id":"2022-07-18-lightweight-threads-on-JavaScript","metadata":{"permalink":"/2022-07-18-lightweight-threads-on-JavaScript","source":"@site/blog/2022-07-18-ghcjs-threads.md","title":"Lightweight Haskell Threads on JavaScript","description":"Introduction","date":"2022-07-18T00:00:00.000Z","formattedDate":"July 18, 2022","tags":[{"label":"ghc","permalink":"/tags/ghc"},{"label":"javascript","permalink":"/tags/javascript"},{"label":"concurrency","permalink":"/tags/concurrency"},{"label":"ffi","permalink":"/tags/ffi"}],"readingTime":3.915,"truncated":false,"authors":[{"name":"Luite Stegeman","title":"Haskell DevX Engineer @ IOG","email":"luite.stegeman@iohk.io","key":"luite"}],"frontMatter":{"slug":"2022-07-18-lightweight-threads-on-JavaScript","title":"Lightweight Haskell Threads on JavaScript","date":"July 18, 2022","authors":["luite"],"tags":["ghc","javascript","concurrency","ffi"]},"prevItem":{"title":"Primitive Type Representation in GHC\'s upcoming JS-backend","permalink":"/2022-07-20-js-backend-prim-types"},"nextItem":{"title":"GHC DevX June 2022 Update","permalink":"/2022-07-01-ghc-update"}},"content":"## Introduction\\n\\nI recently gave a short presentation on the topic of threads in GHCJS to the GHC team at IOG. This blog post is a summary of the content.\\n\\n## JavaScript and Threads\\n\\nJavaScript is fundamentally single threaded. There are ways to share specific data between tasks but it\'s not possible to run multiple threads that have access to a shared memory space of JavaScript data.\\n\\nThe single JavaScript thread is often responsible for multiple tasks. For example a node.js server handles multiple simultaneous connections and a web application may be dealing with user input while downloading new data in the background.\\n\\nThis means that any single task should take care to never block execution of the other task. JavaScript\'s canonical answer is to use asynchronous programming. A function reading a file returns immediately without waiting for the file data to be loaded in memory. When the data is ready, a user-supplied callback is called to continue processing the data.\\n\\n## Haskell Threads\\n\\nConcurrent Haskell supports lightweight threads through `forkIO`. These threads are scheduled on top of one more more operating system thread. A blocking foreign call blocks an OS thread but other lightweight threads can still run on other OS threads if available.\\n\\nThere is no built-in support for foreign calls with a callback in the style of JavaScript. Functions imported with `foreign import ccall interruptible` can be interrupted by sending an asynchronous exception to the corresponding lightweight thread.\\n\\n## Lightweight Threads in JavaScript\\n\\nGHCJS implements lightweight threads on top of the single JavaScript thread. The scheduler switches between threads and handles synchronization through `MVar` and `STM` as expected from other Haskell platforms.\\n\\nForeign calls that don\'t block can be handled in the usual way. We extend the foreign function interface with a new type `foreign import javascript interruptible` that conveniently supports the callback mechanism used by JavaScript frameworks. The foreign call is supplied with an additional argument `$c` representing a callback to be called with the result when ready. From the Haskell side the corresponding lightweight thread is blocked until `$c` is called. This type of foreign call can be interrupted with an asynchronous exception to the lightweight Haskell thread.\\n\\nBy default, Haskell threads in the JS environment run asynchronously. A call to `h$run` returns immediately and starts the thread in the background. This works for tasks that does not require immediate actions. For situations that require more immediate action, such as dealing with event handler propagation, there is `h$runSync`. This starts a synchronous thread that is not interleaved with other task. If possible, the thread runs to completion before the call to `h$runSync` returns. If the thread blocks for any reason, such as waiting for an `MVar` or a `foreign import javascript interruptible` call, synchronous execution cannot complete. The blocking task is then either interrupted with an exception or the thread is \\"demoted\\" to a regular asynchronous thread.\\n\\n## Black Holes\\n\\nWhen a Haskell value is evaluated, its heap object is overwritten by a black hole. This black hole marks the value as being evaluated and prevents other threads from doing the same. \\"black holing\\" can be done either immediately or \\"lazily\\", when the garbage collector is run. GHCJS implements immediate blackholing.\\n\\nBlack holes give rise to an interesting problem in the presence of synchronous and asynchronous threads. Typically if we use `h$runSync`, we want to have some guarantee that at least part of the task will run succesfully without blocking. For the most past it\'s fairly clear which parts of our task depends on potentially blocking IO or thread synchronization. But black holes throw a spanner in the works: Suddenly any \\"pure\\" data structure can be a source of blocking if it is under evaluation by another thread.\\n\\nTo regain some predictability and usability of synchronous threads, the `h$runSync` scheduler can run other Haskell threads in order to \\"clear\\" a black hole. The process ends all black holes have been cleared or when any of the black holes is impossible to clear because of a blocking situation.\\n\\nThis all happens transparantly to the caller of `h$runSync`, if the black holes could be cleared it appears as if they were never there.\\n\\n## Conclusion\\n\\nWe have lightweight Haskell threads in the single-threaded JavaScript environment and extend the foreign function interface to easily support foreign calls that depend on an asynchronous callback. This way, only the Haskell lightweight thread blocks.\\n\\nBy default, Haskell threads are asynchronous and run in the background: The scheduler interleaves the tasks and synchronization between threads. For situations that require immediate results or actions there are synchronous threads. Synchronous threads cannot block and are not interleaved with other tasks except when a black hole is encountered."},{"id":"2022-07-01-ghc-update","metadata":{"permalink":"/2022-07-01-ghc-update","source":"@site/blog/2022-07-01-ghc-update-2022-06.md","title":"GHC DevX June 2022 Update","description":"This is the June 2022 monthly update from the GHC DevX team at IOG.","date":"2022-07-01T00:00:00.000Z","formattedDate":"July 1, 2022","tags":[{"label":"ghc","permalink":"/tags/ghc"}],"readingTime":1.635,"truncated":false,"authors":[{"name":"Sylvain Henry","title":"Haskell DevX Engineer @ IOG","email":"sylvain.henry@iohk.io","key":"sylvain"}],"frontMatter":{"slug":"2022-07-01-ghc-update","title":"GHC DevX June 2022 Update","authors":["sylvain"],"tags":["ghc"]},"prevItem":{"title":"Lightweight Haskell Threads on JavaScript","permalink":"/2022-07-18-lightweight-threads-on-JavaScript"},"nextItem":{"title":"GHC DevX May 2022 Update","permalink":"/2022-06-01-ghc-update"}},"content":"This is the June 2022 monthly update from the GHC DevX team at IOG.\\n\\n## JavaScript Backend for GHC\\n\\nFor a few months we have been merging GHCJS (Haskell to JavaScript compiler) into GHC.\\nWe set our first milestone to be the ability to compile and to run the usual \\"Hello World\\" program.\\nIt turned out to be much more involved than we initially thought (requiring FFI support, etc.), but we should be getting there soon.\\n\\nThis month we have made the following progress:\\n\\n- **Linking**: GHCJS requires some functions to be directly implemented in\\n  JavaScript (e.g. the RTS, some low-level functions in base). We have added support\\n  for linking `.js` files. We\'ve also added support for a preprocessing pass with CPP\\n  for `.js.pp` files.\\n\\n- **js-sources**: there is some ongoing work to load these external JavaScript\\n  files from installed libraries. Cabal provides a `js-sources` stanza for this,\\n  we need to adapt Hadrian to make use of it.\\n\\n- **Binary vs Objectable**: GHCJS used its own ByteString-based Objectable\\n  type-class: we replaced it with GHC\'s similar Binary type-class.\\n  Josh has published a [blog\\n  post](https://engineering.iog.io/2022/05/24/april-GHCJS-Objectable-vs-GHC-Binary)\\n  about their differences.\\n\\n- **64-bit primops**: we\'ve added support for 64-bit primops (Word64# and Int64#\\n  types). In GHCJS (GHC 8.10), these were still implemented as foreign function\\n  calls. It\'s no longer true on GHC head.\\n\\n- **base library**: added CPP as required to support the JS backend. Ported and\\n  converted FFI imports from GHCJS to use JavaScript fat arrows (we haven\'t\\n  implemented GHCJS\'s fancy import syntax yet).\\n\\nNow we can compile and link the \\"HelloWorld\\" program.\\nTo reach the first milestone we only have to fix the remaining runtime errors.\\n\\nYou can follow our progress on our development branch [here](https://gitlab.haskell.org/ghc/ghc/-/tree/wip/js-staging).\\nWe now rebase this branch every Friday to avoid lagging too much behind GHC head.\\n\\n## Haskell Optimization Handbook\\n\\nThe \\"Haskell Optimization Handbook\\" is an [accepted proposal](https://github.com/haskellfoundation/tech-proposals/blob/main/proposals/accepted/026-haskell-optimization-handbook.md) of the Haskell Foundation.\\nJeff has been steadily writing some initial material as per the project plan."},{"id":"2022-06-01-ghc-update","metadata":{"permalink":"/2022-06-01-ghc-update","source":"@site/blog/2022-06-01-ghc-update-2022-05.md","title":"GHC DevX May 2022 Update","description":"This is the May 2022 monthly update from the GHC DevX team at IOG.","date":"2022-06-01T00:00:00.000Z","formattedDate":"June 1, 2022","tags":[{"label":"ghc","permalink":"/tags/ghc"}],"readingTime":2.61,"truncated":false,"authors":[{"name":"Sylvain Henry","title":"Haskell DevX Engineer @ IOG","email":"sylvain.henry@iohk.io","key":"sylvain"}],"frontMatter":{"slug":"2022-06-01-ghc-update","title":"GHC DevX May 2022 Update","authors":["sylvain"],"tags":["ghc"]},"prevItem":{"title":"GHC DevX June 2022 Update","permalink":"/2022-07-01-ghc-update"},"nextItem":{"title":"Objectable vs GHC Binary","permalink":"/2022/05/24/april-GHCJS-Objectable-vs-GHC-Binary"}},"content":"This is the May 2022 monthly update from the GHC DevX team at IOG.\\n\\n## JavaScript Backend for GHC\\n\\nFor a few months we have been merging GHCJS (Haskell to JavaScript compiler) into GHC.\\nWe set our first milestone to be the ability to compile and to run the usual \\"Hello World\\" program.\\nIt turned out to be much more involved than we initially thought (requiring FFI support, etc.), but we should be getting there soon.\\n\\nThis month we have made the following progress:\\n\\n- **RTS**: we have modified Hadrian and ``rts.cabal`` in order to build a valid\\n  native ``rts`` unit that GHC can use, in particular containing appropriate\\n  header files.\\n\\n- **linker**: the JS linker has been hooked up with GHC\'s driver.\\n  We fixed several panics in the linker due to erroneous symbol generation code.\\n  These bugs were introduced while porting the code from the old 8.10 pretty-printing infrastructure to the newer one.\\n\\n- **boot libraries**: the JS backend can now build and link all the boot libraries.\\nNote that we are not claiming that they are all usable yet. In particular complete FFI support is lacking, but the JS backend Hadrian build completes and so we can start using the produced JS cross-compiler.\\n\\n- **levity polymorphism**: building ``ghc-prim`` uncovered a lurking bug related to\\n  levity polymorphism. It wasn\'t noticed in GHCJS 8.10 because it is also\\n  related to the ``BoxedRep`` proposal that introduced a constructor application\\n  in a commonly used ``RuntimeRep``.\\n\\n- **sized literals**: support for new sized literals have been added to the code\\n  generator.\\n\\nNow that have achieved a build process that actually produces a JS cross compiler, we are confronting and fixing issues in the produced JavaScript code, such as adding, managing, and debugging CPP conditional compilation blocks in JS shim files. You can follow our progress on our development branch [here](https://gitlab.haskell.org/ghc/ghc/-/tree/wip/js-staging).\\n\\n## External Static Plugins\\n\\nGHC doesn\'t support plugins in cross-compilers [#14335](https://gitlab.haskell.org/ghc/ghc/-/issues/14335).\\nSome time ago, we came up with a solution called \\"external static plugins\\" [!7377](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7377).\\nThese are plugins that are directly loaded from shared libaries, bypassing the issue with usual plugins.\\n\\nOur colleague Shea Levy confirmed that the approach works, backported it to GHC 8.10, and has been working on making it work in stage1 cross-compilers for Windows.\\nKudos for this work, Shea.\\n\\nAs the current user-interface based on environment variables isn\'t convenient, we have been working on adding new command-line flags to GHC instead.\\nWe expect to propose this for integration into GHC when the new interface will be fully implemented.\\n\\n## Blog posts\\n\\nInspired by our friends and colleagues at Well-Typed and Tweag, we have been starting to write blog posts for IOG\'s engineering blog.\\nThey will mostly be about stuff we are working on or that we are interested in.\\nFeel free to send us feedback about these posts and to send us topics you would be interested to read about.\\n\\n- https://engineering.iog.io/2022-04-28-on-the-inlining-of-integer-and-natural-operations\\n- https://engineering.iog.io/2022-05-02-setup-ext-stg-interp\\n- https://engineering.iog.io/2022-05-17-javascript-template-haskell-external-interpreter\\n\\n## Haskell Optimization Handbook\\n\\nThe \\"Haskell Optimization Handbook\\" is an [accepted proposal](https://github.com/haskellfoundation/tech-proposals/blob/main/proposals/accepted/026-haskell-optimization-handbook.md) of the Haskell Foundation.\\nJeff has been working behind the scene to make this proposal concrete.\\nMore about this in the upcoming months."},{"id":"/2022/05/24/april-GHCJS-Objectable-vs-GHC-Binary","metadata":{"permalink":"/2022/05/24/april-GHCJS-Objectable-vs-GHC-Binary","source":"@site/blog/2022-05-24-april-GHCJS-Objectable-vs-GHC-Binary.md","title":"Objectable vs GHC Binary","description":"As part of the integration of GHCJS into GHC as a cross-compilation backend, we\'ve converted the binary serialisation that GHCJS previously used, which was via its Objectable typeclass, into GHC\'s internal Binary typeclass representation. In doing this, we gain access to instances for serialising many of GHC\'s internal data types, and, importantly, we can reuse GHC\'s mechanism for serialising its Name and FastString types, which are written to lookup tables in order to maintain identity, as well as allowing for space savings on disk.","date":"2022-05-24T00:00:00.000Z","formattedDate":"May 24, 2022","tags":[],"readingTime":10.605,"truncated":false,"authors":[],"frontMatter":{},"prevItem":{"title":"GHC DevX May 2022 Update","permalink":"/2022-06-01-ghc-update"},"nextItem":{"title":"JavaScript, Template Haskell and the External Interpreter","permalink":"/2022-05-17-javascript-template-haskell-external-interpreter"}},"content":"As part of the integration of GHCJS into GHC as a cross-compilation backend, we\'ve converted the binary serialisation that GHCJS previously used, which was via its `Objectable` typeclass, into GHC\'s internal `Binary` typeclass representation. In doing this, we gain access to instances for serialising many of GHC\'s internal data types, and, importantly, we can reuse GHC\'s mechanism for serialising its `Name` and `FastString` types, which are written to lookup tables in order to maintain identity, as well as allowing for space savings on disk.\\n\\nIn this post, we will explain how the GHC `Binary` and GHCJS `Objectable` approaches work, and compare their tradeoffs.\\n\\n## How GHC Binary Works\\n\\nInternally, GHC uses the `Name` data type to track the uniqueness of objects during compilation. Amongst information relating to the definition of a `Name` within the Haskell source, a `Name` also contains a `Unique` integer (the value of which is provided by the complation environment monad). Using this `Unique` integer, which is unpacked in `Name`\'s definition, we can make O(1) equality comparisons without following further memory references - allowing for this operation to be very quick, which will have a large effect on compilation performance given how often it is used.\\n\\n`FastString` is used within GHC to store short, string-like data, and, similarly to `Name`, `FastString` uses a unique integer to allow for very fast equality comparisons. Primarily, `FastString` is used to represent variables and other definitions, and is used both in `Name` as the string-representation of a name with extra information attached, as well as directly, representing names that don\'t require this extra information, such as local variables.\\n\\nIn GHC\'s `.hi` interface files, `Name` and `FastString` are serialised differently compared to other data structures. They are written in the main data structure payload as indicies of a table, and these tables contain the actual string-like data of these types. So, an interface file might resemble:\\n\\n* Header\\n  * Magic number for recognising interface files\\n  * Pointer to `Name` symbol table\\n  * Pointer to `FastString` dictionary\\n* Main data structure payload\\n* `Name` symbol table\\n* `FastString` dictionary\\n\\nImportantly, the `FastString` dictionary must be written _after_ the `Name` symbol table, because `Name`s contain `FastString`s, so writing the symbol table will expand the dictionary. Additionally, because we only have one buffer, and we don\'t know the size of the payload until it\'s written, the tables cannot be written in the header, and instead serialisation code must reserve space for the table pointers and jump back to write the pointers once the table locations are known.\\n\\nDuring serialisation, GHC uses mutable data structures to store both the serialised binary buffer, as well as these tables:\\n\\n```haskell\\ndata BinHandle\\n  = BinMem {                     -- binary data stored in an unboxed array\\n     bh_usr :: UserData,         -- sigh, need parameterized modules :-)\\n     _off_r :: !FastMutInt,      -- the current offset\\n     _sz_r  :: !FastMutInt,      -- size of the array (cached)\\n     _arr_r :: !(IORef BinArray) -- the array (bounds: (0,size-1))\\n    }\\n\\ndata UserData =\\n   UserData {\\n        -- for *deserialising* only:\\n        ud_get_name :: BinHandle -> IO Name,\\n        ud_get_fs   :: BinHandle -> IO FastString,\\n\\n        -- for *serialising* only:\\n        ud_put_nonbinding_name :: BinHandle -> Name -> IO (),\\n        -- ^ serialize a non-binding \'Name\' (e.g. a reference to another\\n        -- binding).\\n        ud_put_binding_name :: BinHandle -> Name -> IO (),\\n        -- ^ serialize a binding \'Name\' (e.g. the name of an IfaceDecl)\\n        ud_put_fs   :: BinHandle -> FastString -> IO ()\\n   }\\n```\\n\\nHere, we see that various functions are stored in the handle structure, to be later referenced by their respective types in their `GHC.Utils.Binary.Binary` typeclass instances. Notice that the instance of `Binary Name` references `ud_put_nonbinding_name` and `ud_get_name`. Similarly, the `Binary FastString` instance uses `ud_put_fs` and `ud_get_fs`.\\n\\n```haskell\\nclass Binary a where\\n    put_   :: BinHandle -> a -> IO ()\\n    put    :: BinHandle -> a -> IO (Bin a)\\n    get    :: BinHandle -> IO a\\n\\ninstance Binary FastString where\\n  put_ bh f =\\n    case getUserData bh of\\n        UserData { ud_put_fs = put_fs } -> put_fs bh f\\n\\n  get bh =\\n    case getUserData bh of\\n        UserData { ud_get_fs = get_fs } -> get_fs bh\\n\\ninstance Binary Name where\\n   put_ bh name =\\n      case getUserData bh of\\n        UserData{ ud_put_nonbinding_name = put_name } -> put_name bh name\\n\\n   get bh =\\n      case getUserData bh of\\n        UserData { ud_get_name = get_name } -> get_name bh\\n```\\n\\nIn `GHC.Iface.Binary`, helper types and functions are defined to store the `Name` symbol table and `FastString` dictionary in a mutable data structure. Here, `putFastString` is intended to be partially applied - passing it an appropriately initialised `BinDictionary` so that the resulting function can be stored in the `us_put_fs` field of the `UserData`. `allocateFastString` does the low-level work here, incrementing the index and modifying the mutable map (stored as a `UniqFM`, which is map keyed on types that contain `Unique`s - recalling that these are used for fast equality comparisons):\\n\\n```haskell\\ndata BinDictionary = BinDictionary {\\n        bin_dict_next :: !FastMutInt, -- The next index to use\\n        bin_dict_map  :: !(IORef (UniqFM FastString (Int,FastString)))\\n                                -- indexed by FastString\\n  }\\n\\nputFastString :: BinDictionary -> BinHandle -> FastString -> IO ()\\nputFastString dict bh fs = allocateFastString dict fs >>= put_ bh\\n\\nallocateFastString :: BinDictionary -> FastString -> IO Word32\\nallocateFastString BinDictionary { bin_dict_next = j_r,\\n                                   bin_dict_map  = out_r} f = do\\n    out <- readIORef out_r\\n    let !uniq = getUnique f\\n    case lookupUFM_Directly out uniq of\\n        Just (j, _)  -> return (fromIntegral j :: Word32)\\n        Nothing -> do\\n           j <- readFastMutInt j_r\\n           writeFastMutInt j_r (j + 1)\\n           writeIORef out_r $! addToUFM_Directly out uniq (j, f)\\n           return (fromIntegral j :: Word32)\\n```\\n\\nLater, in `GHC.Iface.Binary`, `getWithUserData` and `putWithUserData` will structure the header, and initialise the `UserData` functions to write to/read from mutable tables. Notice that we must first reserve header space for pointers to the lookup tables, as well as initialise the mutable tables, write these initialised structures to the `UserData` (for example, we see the previous `putFastString` partially applied here), then write the main payload, then write the lookup tables (`Name` symbol table first, because writing this can add to the `FastString` dictionary), and finally jump back to fill in the pointers to these tables:\\n\\n```haskell\\nputWithUserData :: Binary a => TraceBinIFace -> BinHandle -> a -> IO ()\\nputWithUserData traceBinIface bh payload = do\\n    -- Remember where the dictionary pointer will go\\n    dict_p_p <- tellBin bh\\n    -- Placeholder for ptr to dictionary\\n    put_ bh dict_p_p\\n\\n    -- Remember where the symbol table pointer will go\\n    symtab_p_p <- tellBin bh\\n    put_ bh symtab_p_p\\n    -- Make some initial state\\n    symtab_next <- newFastMutInt 0\\n    symtab_map <- newIORef emptyUFM\\n    let bin_symtab = BinSymbolTable {\\n                         bin_symtab_next = symtab_next,\\n                         bin_symtab_map  = symtab_map }\\n    dict_next_ref <- newFastMutInt 0\\n    dict_map_ref <- newIORef emptyUFM\\n    let bin_dict = BinDictionary {\\n                       bin_dict_next = dict_next_ref,\\n                       bin_dict_map  = dict_map_ref }\\n\\n    -- Put the main thing,\\n    bh <- return $ setUserData bh $ newWriteState (putName bin_dict bin_symtab)\\n                                                  (putName bin_dict bin_symtab)\\n                                                  (putFastString bin_dict)\\n    put_ bh payload\\n\\n    -- Write the symtab pointer at the front of the file\\n    symtab_p <- tellBin bh        -- This is where the symtab will start\\n    putAt bh symtab_p_p symtab_p  -- Fill in the placeholder\\n    seekBin bh symtab_p           -- Seek back to the end of the file\\n\\n    -- Write the symbol table itself\\n    symtab_next <- readFastMutInt symtab_next\\n    symtab_map  <- readIORef symtab_map\\n    putSymbolTable bh symtab_next symtab_map\\n    case traceBinIface of\\n      QuietBinIFace         -> return ()\\n      TraceBinIFace printer ->\\n         printer (text \\"writeBinIface:\\" <+> int symtab_next\\n                                        <+> text \\"Names\\")\\n\\n    -- NB. write the dictionary after the symbol table, because\\n    -- writing the symbol table may create more dictionary entries.\\n\\n    -- Write the dictionary pointer at the front of the file\\n    dict_p <- tellBin bh          -- This is where the dictionary will start\\n    putAt bh dict_p_p dict_p      -- Fill in the placeholder\\n    seekBin bh dict_p             -- Seek back to the end of the file\\n\\n    -- Write the dictionary itself\\n    dict_next <- readFastMutInt dict_next_ref\\n    dict_map  <- readIORef dict_map_ref\\n    putDictionary bh dict_next dict_map\\n    case traceBinIface of\\n      QuietBinIFace         -> return ()\\n      TraceBinIFace printer ->\\n         printer (text \\"writeBinIface:\\" <+> int dict_next\\n                                        <+> text \\"dict entries\\")\\n```\\n\\nIn summary, we see a number of structural characteristics of code using GHC\'s Binary implementation:\\n* Use of a single buffer means that the lookup tables can\'t be written in the header, so we have to reserve space for table pointers in the header, and jump back once we know where they will be located in order to write the pointers to the buffer. Essentially, an ordering of file sections is enforced by the data dependencies of the payload containing `Name`s and `FastString`s, and `Name`s containing `FastString`s - which means these must be written in this order, but reading must be done in the reverse order, causing the need for pointers in the header.\\n* Jumping around in binary buffers results in weakly enforced types and fiddly, code that Haskell\'s type system isn\'t able to help us debug\\n* Must carry about read/write functions for the lookup table types (`Name` and `FastString`), which are `undefined` during the opposite serialisation stage, and are hard-coded into the handle, reducing extensibility.\\n\\n## How Objectable Works\\n\\nIn comparison, GHCJS previously involved using instances of the `Objectable` typeclass to serialise its interface files:\\n\\n```haskell\\nimport qualified Data.Binary as DB\\n\\ndata SymbolTable\\n  = SymbolTable !Int !(Map ShortText Int)\\n  deriving (Show)\\n\\ntype PutSM = St.StateT SymbolTable DB.PutM -- FIXME: StateT isn\'t strict enough apparently\\ntype PutS  = PutSM ()\\ntype GetS  = ReaderT ObjEnv DB.Get\\n\\nclass Objectable a where\\n  put :: a -> PutS\\n  get :: GetS a\\n  putList :: [a] -> PutS\\n  putList = putListOf put\\n  getList :: GetS [a]\\n  getList = getListOf get\\n```\\n\\nHere we see that GHCJS has opted for a different approach that avoids the mutable buffer by instead using `Data.Binary` instances that work via concatenating lazy `ByteString`s. Additionally, the mutable tables are replaced with a `State` monad that holds the symbol table as a `Map` structure.\\n\\nBecause `Data.Binary` forms lazy `ByteString`s, it\'s trivial to serialise the individual parts of the interface file and later concatenate these using `ByteString`\'s monoid instance - allowing for all of the sections of the file to be defined declaratively at the top-level of the function in order of their appearance within the file.\\n\\n```haskell\\nobject\'\\n  :: ModuleName                 -- ^ module\\n  -> SymbolTable                -- ^ final symbol table\\n  -> Deps                       -- ^ dependencies\\n  -> [([ShortText],ByteString)] -- ^ serialized units and their exported symbols, the first unit is module-global\\n  -> ByteString\\nobject\' mod_name st0 deps0 os = hdr <> symbs <> deps1 <> idx <> mconcat (map snd os)\\n  where\\n    hdr          = putHeader (Header (moduleNameTag mod_name) (bl symbs) (bl deps1) (bl idx))\\n    bl           = fromIntegral . B.length\\n    deps1        = putDepsSection deps0\\n    (sti, idx)   = putIndex st0 os\\n    symbs        = putSymbolTable sti\\n```\\n\\nIn summary, the use of multiple `ByteString` sections that are later concatenated offer several different structural characteristics compared to the use of a single mutable buffer:\\n* The final ordering of the sections is flexible, because they are serialsied separately, so any data dependencies don\'t introduce ordering in the file - which we see in the `where` clause of `object\'`\\n* Types are more strongly enforced because imperative `seekBin` instructions aren\'t required. However, each section is still _deserialised_ by taking a substring of the file to be read as that section type. Of course, all serialisation eventually results in raw binary, so the simplification of concatenating the sections into the final file without jumping around limits the places that bugs can hide\\n* Visually, the ordering of the sections within the final file is very clear - we see in `object\'` that every section is simply listed _in order_ on one line, concatenated together.\\n\\n## Conclusion\\n\\nMaking use of GHC\'s existing infrastructure lets the GHCJS backend to make use of the `FastString` and `Name` data types, as well as allowing for the removal of a significant amount of now-redundant code.\\n\\nAdditionally, interface file generation using GHC\'s `Binary` appears to be very fast - for example, attempts to hide the handle behind a reader monad significantly reduce the compiler\'s performance as measured by CI. Speculatively, looking at the generated core, this could be because the optimiser has a much better time with the style of IO code that is used - rather than being a limitation of more abstacted approaches.\\n\\nThe comparison provided the GHCJS\'s old approach makes it clear that GHC\'s `Binary` implementation, while very useful, has potential to be improved in both readability and extensiblity. However, because CI has shown that serialisation performance has a significant effect on overall compilation performance, this tradeoff must be considered when making any changes. Potentially, these readability shortfalls in GHC\'s implementation might just be the result of legacy code, and so benchmarks of other approaches, such as `Data.Binary`, should be used to guide future work in improving the readability and flexibility of GHC\'s serialisation without sacrificing performance."},{"id":"2022-05-17-javascript-template-haskell-external-interpreter","metadata":{"permalink":"/2022-05-17-javascript-template-haskell-external-interpreter","source":"@site/blog/2022-05-17-javascript-template-haskell-ext-interp.md","title":"JavaScript, Template Haskell and the External Interpreter","description":"Introduction","date":"2022-05-17T00:00:00.000Z","formattedDate":"May 17, 2022","tags":[{"label":"ghc ghcjs javascript tooling profiling","permalink":"/tags/ghc-ghcjs-javascript-tooling-profiling"}],"readingTime":6.805,"truncated":false,"authors":[{"name":"Luite Stegeman","title":"Haskell DevX Engineer @ IOG","email":"luite.stegeman@iohk.io","key":"luite"}],"frontMatter":{"slug":"2022-05-17-javascript-template-haskell-external-interpreter","title":"JavaScript, Template Haskell and the External Interpreter","date":"May 17, 2022","authors":["luite"],"tags":["ghc ghcjs javascript tooling profiling"]},"prevItem":{"title":"Objectable vs GHC Binary","permalink":"/2022/05/24/april-GHCJS-Objectable-vs-GHC-Binary"},"nextItem":{"title":"GHC April 2022 Update","permalink":"/ghc-update-2022-04"}},"content":"## Introduction\\n\\nAt IOG DevX we have been working on integrating various bits of GHCJS into GHC, with the goal of having a fully working JavaScript backend for the 9.6 release. For some parts this has mostly consisted of an update of the code to use the newer GHC API and dependencies. Other bits, like the Template Haskell runner, need more work.\\n\\nThis post gives an overview of the existing approaches for running Template Haskell in GHC based cross compilers and our plan for the JavaScript backend. Hopefully we can revisit this topic once all the work has been done, and see what exactly we ended up with.\\n\\n## The GHCJS Template Haskell Runner\\n\\nWhen I first worked on Template Haskell (TH) support for GHCJS, there was no mechanism to combine Template Haskell with cross compilation in GHC.\\n\\nNormally, Template Haskell is run by loading library code directly into the GHC process and using the bytecode interpreter for the current module. Template Haskell can directly access GHC data structures through the `Q` monad. Clearly this would not be possible for GHCJS: We only have JavaScript code available for the libraries and the organization of the JavaScript data structures is very different from what GHC uses internally.\\n\\nSo I had to look for an alternative. Running Template Haskell consists of two parts:\\n\\n   1. loading/executing the TH code\\n   2. handling compiler queries from the TH code, for example looking up names or types\\n\\nRunning the TH code can be done by first compiling the Haskell to JavaScript and then using the JavaScript `eval` feature.\\n\\nTemplate Haskell code can query the compiler using the `Quasi` typeclass. I noticed that none of the methods required passing around functions or complicated data structures, so it would be possible to serialize each request and response and send it to another process.\\n\\nSo I went ahead and implemented this approach with a script `thrunner.js` to load and start the code in a node.js server, a message type with serialization, and a new instance of the `Quasi` typeclass to handle the communication with the compiler via the messages. This is still what\'s in use by GHCJS to this day. Every time GHCJS encounters Template Haskell, it starts a `thrunner` process and the compiler communicates with it over a pipe.\\n\\nAfter starting `thrunner.js` GHCJS sends the Haskell parts of the Template Haskell runnner to the script. This includes the runtime system and the implementation of the `Quasi` typeclass and communication protocol. After that, the TH session starts. A typical TH session looks as follows:\\n\\n| Compiler | thrunner |\\n| :---     | :----    |\\n| `RunTH THExp <js code> <source location>` | |\\n| | `LookupName (Just <name-string>)` |\\n| `LookupName\' (Just <name>)` |\\n| | `Reify <name>` |\\n| `Reify\' <name-info>` | |\\n| | `RunTH\' <result>` |\\n| `RunTH THDec <js code> <source location>` | |\\n| | `AddTopDecls <declarations>` |\\n| `AddTopDecls\'` | |\\n| | `RunTH\' <result>` |\\n| `FinishTH True` | |\\n| | `FinishTH\' <memory-consumption>` |\\n\\nEach message is followed up by a corresponding reply. For example, a `LookupName\'` response follows a `LookupName` request and a `RunTH` message will eventually generate a `RunTH\'` result. The first `RunTH` message contains the compiled JavaScript for the Template Haskell code, along with its dependencies. Each subsequent `RunTH` only includes dependencies that have not already been sent.\\n\\nThe `thrunner` process stays alive during the compilation of at least an entire module, allowing for persistent state (`putQ`/`getQ`).\\n\\n## The GHC External Interpreter\\n\\nIf we build a Haskell program with (cost centre) profiling, the layout of our data structures changes to include bookkeeping of cost centre information. This means that we need a special profiling runtime system to run this code.\\n\\nWhat can we do if we want to run our profiled build in GHCi or Template Haskell? We cannot load compiled profiling libraries into GHC directly; its runtime system expects non-profiled code. We could use a profiled version of the compiler itself, but this would make all compilation very slow. Or we could somehow separate the profiled code of our own program from the non-profiled code in the compiler.\\n\\nThis was Simon Marlow\'s motivation for adapting the GHCJS `thrunner` approach, integrating in GHC and extending it it to support GHCi and bytecode. This functionality can be activated with the `-fexternal-interpreter` flag and has been available since GHC version 8.0.1. When the external interpreter is activated, GHC starts a separate process, `iserv` (customizable with the `-pgmi` flag) which has the role analogous to the `thrunner` script for GHCJS.\\n\\nOver time, the `iserv` code has evolved with GHC and has been extended to include more operations. By now, there are quite a few differences in features:\\n\\n| Feature | thrunner | iserv |\\n| :--- | :----:   | :---: |\\n| Template Haskell support | yes       | yes   |\\n| GHCi   | no | yes |\\n| Debugger | no | yes |\\n| Bytecode | no | yes |\\n| Object code | through pipe | from file |\\n| Object code linking | compiler | iserv process |\\n\\n`thrunner` is not quite as complete as `iserv`: It lacks GHCi and the debugger, and there is no bytecode support. But these features are not essential for basic Template Haskell.\\n\\n## Proxies and Bytecodes\\n\\nWe have now seen two systems for running Template Haskell code outside the compiler process: The original GHCJS `thrunner` and the extended GHC `iserv`.\\n\\nClearly it isn\'t ideal to have multiple \\"external interpreter\\" systems in GHC, therefore we plan to switch from `thrunner` to `iserv` for the upcoming JavaScript GHC backend. We don\'t need the debugger or GHCi support yet, but we do need to adapt to other changes in the infrastructure. So what does this mean in practice?\\n\\nThe biggest change is that we have to rework the linker: `thrunner` does not contain any linking logic by itself: GHCJS compiles everything to JavaScript and sends compiled code to the `thrunner` process, ready to be executed. In contrast, `iserv` has a loader for object and archive files. When dependencies need to be loaded into the interpreter, GHC just gives it the file name.\\n\\nAnother change is using the updated message types. In the `thrunner` session example above we could see that each message is paired with a response. For example a `RunTH\'` response always follows a `RunTH` message, with possibly other messages in between. `iserv` has an interesting approach for the `Message` datatype: Instead of having pairs of data constructors for each message and its response, `iserv` has a GADT `Message a`, where the `a` type parameter indicates the expected response payload for each data constructor.\\n\\nDuring development of the `thrunner` program it turned out to be very useful to save and replay Template Haskell sessions for debugging purposes. We\'d like to do this again, but now saving the message in a readable/writable format. Since we\'re dealing with JavaScript, JSON appears to be the obvious choice.\\n\\nOur plan is to have an `iserv` implementation that consists of a JavaScript part that runs in node.js and a proxy process to handle communication with GHC. The proxy process converts the messages between GHC\'s own (`binary` based) serialization format and JSON. The proxy process is relatively simple, but it does reveal one downside of the new GADT based message types: A proxy is stateful. We must always know which message we have sent to convert the response back from JSON to `binary`.\\n\\nIt\'s not yet known whether we will implement a full bytecode interpreter. We expect it to become clear during implementation whether we can get away without one early on.\\n\\n## Conclusion\\n\\nWe have seen how Template Haskell and GHCi code can be run outside the GHC process for profiling or cross compiling, with both the `thrunner` approach in GHCJS and the newer `iserv` in GHC.\\n\\nWe at IOG DevX are working on switching to the `iserv` infrastructure for the upcoming GHC JavaScript backend, which involves a substantial rewrite, mainly because of differences in linking. This is a work in progress, and we intend to revisit this topic in another blog post once the final design has been implemented."},{"id":"ghc-update-2022-04","metadata":{"permalink":"/ghc-update-2022-04","source":"@site/blog/2022-05-13-ghc-update-2022-04.md","title":"GHC April 2022 Update","description":"Welcome to the (rather late) April 2022 monthly update from the GHC DevX team at IOG. Since the last update we\'ve continued work on the upcoming JavaScript backend for GHC. Unfortunately, we have nothing to show quite yet but that doesn\'t mean nothing has happened! On the contrary, we\'ve made great progress and are close to that crucial first milestone hello world. Besides our work on the JavaScript backend, we were pleased to finally push through the Modularizing GHC paper that Sylvain has been working on for 2+ years! It causes quite the splash on the Haskell discourse and reddit, we recommend reading it if you haven\'t already (links below). Alright, enough introduction let\'s get into the update.","date":"2022-05-13T00:00:00.000Z","formattedDate":"May 13, 2022","tags":[{"label":"ghc","permalink":"/tags/ghc"}],"readingTime":1.94,"truncated":false,"authors":[{"name":"Sylvain Henry","title":"Haskell DevX Engineer @ IOG","email":"sylvain.henry@iohk.io","key":"sylvain"},{"name":"Jeffrey M. Young","title":"Haskell DevX Engineer @ IOG","url":"https://iog.io/en/","key":"doyougnu"}],"frontMatter":{"slug":"ghc-update-2022-04","title":"GHC April 2022 Update","authors":["sylvain","doyougnu"],"tags":["ghc"]},"prevItem":{"title":"JavaScript, Template Haskell and the External Interpreter","permalink":"/2022-05-17-javascript-template-haskell-external-interpreter"},"nextItem":{"title":"Setting up Csaba\'s External STG Interpreter","permalink":"/2022-05-02-setup-ext-stg-interp"}},"content":"Welcome to the (rather late) April 2022 monthly update from the GHC DevX team at IOG. Since the last update we\'ve continued work on the upcoming JavaScript backend for GHC. Unfortunately, we have nothing to show quite yet but that doesn\'t mean nothing has happened! On the contrary, we\'ve made great progress and are close to that crucial first milestone `hello world`. Besides our work on the JavaScript backend, we were pleased to finally push through the [Modularizing GHC](https://hsyl20.fr/home/posts/2022-05-03-modularizing-ghc-paper.html) paper that Sylvain has been working on for 2+ years! It causes quite the splash on the Haskell discourse and reddit, we recommend reading it if you haven\'t already (links below). Alright, enough introduction let\'s get into the update.\\n\\n## JavaScript Backend\\n\\nWe have made the following progresses in the implementation of a JavaScript\\nbackend for GHC (adapted from GHCJS):\\n\\n- **linker**: ported GHCJS\'s linker code into GHC. A lot of code was duplicated from GHC and\\n  slightly modified for GHCJS\'s needs, making the process far from trivial.\\n\\n- **testsuite**: fixed Hadrian to run GHC\'s testsuite with cross-compilers\\n  [!7850](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7850). There are\\n  remaining issues though (see\\n  [#21292](https://gitlab.haskell.org/ghc/ghc/-/issues/21292)).\\n\\n- **build system**: fixes for GHC\'s configure script were ported (e.g. support for\\n  the \\"ghcjs\\" target in ``config.sub``). GHCJS\'s custom\\n  build script was integrated into ``configure.ac``. We can now\\n  configure the build with: ``./configure --target=js-unknown-ghcjs``\\n\\n- **TH**: we have conducted some experiments to find the best way to bridge GHCJS\'s\\n  TH runner and GHC\'s external interpreter. This will be described in details in\\n  a future blog post.\\n\\n- **FFI**: basic support for JavaScript FFI has been ported from GHCJS to GHC. We\\n  haven\'t ported the JavaScript parser, so we have dropped the fancy import\\n  syntax (e.g. \\"$1.xyz\\"). It should be enough to build boot libraries and we\\n  will add JS parsing support later.\\n\\nAt this stage, we are working on building boot libraries and on supporting\\nlinking with the JS RTS.\\n\\nDevelopment happens in the following branch: https://gitlab.haskell.org/ghc/ghc/-/tree/wip/js-staging\\n\\n\\n## Modularity paper\\n\\nSylvain, Jeffrey, and John Ericson (from Obsidian Systems) wrote a paper about\\n\\"modularizing GHC\\" using domain-driven design.\\n\\n- Announce blog post: https://hsyl20.fr/home/posts/2022-05-03-modularizing-ghc-paper.html\\n- Paper: https://hsyl20.fr/home/files/papers/2022-ghc-modularity.pdf\\n- Reddit: https://www.reddit.com/r/haskell/comments/uhdu4l/modularizing_ghc_paper/\\n- Discourse: https://discourse.haskell.org/t/modularizing-ghc-paper/4471\\n\\nWe\'ve got a lot of great feedback about it (expect a first revision soon).\\nWe also got a GHC contribution directly inspired by the paper (see\\n[!8160](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/8160)) which was\\nvery welcome!"},{"id":"2022-05-02-setup-ext-stg-interp","metadata":{"permalink":"/2022-05-02-setup-ext-stg-interp","source":"@site/blog/2022-05-02-setup-ext-stg-interp.md","title":"Setting up Csaba\'s External STG Interpreter","description":"Table of Contents","date":"2022-05-02T00:00:00.000Z","formattedDate":"May 2, 2022","tags":[{"label":"ghc","permalink":"/tags/ghc"},{"label":"stg","permalink":"/tags/stg"},{"label":"tooling","permalink":"/tags/tooling"},{"label":"profiling","permalink":"/tags/profiling"},{"label":"optimization","permalink":"/tags/optimization"}],"readingTime":17.305,"truncated":false,"authors":[{"name":"Jeffrey M. Young","title":"Haskell DevX Engineer @ IOG","url":"https://iog.io/en/","key":"doyougnu"}],"frontMatter":{"slug":"2022-05-02-setup-ext-stg-interp","title":"Setting up Csaba\'s External STG Interpreter","date":"May 2, 2022","authors":["doyougnu"],"tags":["ghc","stg","tooling","profiling","optimization"]},"prevItem":{"title":"GHC April 2022 Update","permalink":"/ghc-update-2022-04"},"nextItem":{"title":"On the inlining of Integer and Natural operations","permalink":"/2022-04-28-on-the-inlining-of-integer-and-natural-operations"}},"content":"## Table of Contents\\n- [Making sense of the project](#orgfeb334e)\\n- [Building a working external STG interpreter](#org1d461dc)\\n  - [ghc.nix](#orgb670539)\\n  - [Building ghc-wpc](#orgbb3f1d5)\\n  - [Building the stg tooling](#org9ef4bc5)\\n- [Building the external-stg-interpreter](#org4a2eaf9)\\n- [Linking the external-stg-interpreter](#org1d34a2e)\\n- [The whole setup process on a demo](#org2daa4b8)\\n- [Summary](#org8193a1a)\\n  - [File Descriptions](#org940ba90)\\n  - [Step-by-Step guide for running the interpreter on your code](#org8e9f409)\\n\\nHaskell is a great language camouflaged by lackluster tooling. This situation\\nhas led to well-known problems (who could forget Cabal hell?). A less discussed\\nproblem is what I will call the &ldquo;Black-box syndrome&rdquo;: It is hard to\\nknow *exactly* what the memory representation and runtime performance of my\\nHaskell programs are[^1]. Now black-box syndrome is not *only* a problem,\\nit is also one of the nice features in the language since like all good\\nabstractions it elides things I&rsquo;d rather not care about, at least most of\\nthe time. In other words, I am happy I don&rsquo;t have to do manual memory\\nmanipulation!\\n\\nHowever, when I have my optimization hat on, I run face first into black-box syndrome. The crux of the problem is a tension between the need for observation during performance engineering and optimization, and the need to ship fast code. During development we want to be able to open up a system, see exactly how it is working, make tweaks, package it back up and test again. I want to be able to answer questions like &ldquo;Why is my executable this size?&rdquo;, &ldquo;Which code is a hot loop?&rdquo;, or &ldquo;When does my code do direct, known or unknown function calls?&rdquo;.\\n\\nIn order to answer these questions we need the ability to observe *every part of that system as the machine experiences it*, without this ability we have no way to make progress other than test, change some code, compile and test again in an ad-hoc manner. And therein lies the problem, most Haskell tooling is insufficient to provide the observability that we would like, instead the tooling often expects and requires us to make source code changes to our program or even recompile all of our libraries and code for a profiling way. This leads to the idea and *the expectation* in the Haskell community that Haskell programs are hard to optimize because the barrier to entry for optimization has artificially increased.\\n\\n[Csaba Hruska](https://www.patreon.com/csaba_hruska) has recently been making headway in this area with his work on the [GRIN](https://youtu.be/iXhh0NSR67k) compiler and an external STG interpreter. His STG interpreter (and patched ghc) exactly solve these problems and he has demonstrated dumping the entire call graph of large Haskell projects, filter to hot loops and finding unknown function calls in these graphs. If you haven&rsquo;t seen his [demo](https://www.youtube.com/watch?v=wt6iCgYmVGA&t=2054s) be sure to watch it, it is well worth your time.\\n\\nThis post is the first in a new blog series. In this blog series we&rsquo;re going to kick the tires on the external STG interpreter see what it can do, and what we can uncover in some popular libraries by using it. In particular, I&rsquo;m interested in running it on projects I&rsquo;ve previously optimized&#x2014;such as ghc itself, containers, unordered-containers&#x2014;using the standard methods: ticky-ticky profiling, prof, flamegraphs, heap profiling, ghc-debug, cachegrind etc. This post, however, will be focused on setting up the patched ghc and interpreter on a NixOS system. My goals are threefold:\\n\\n1.  Give an overview of the project and project layout to lower barrier to entry for the system.\\n2.  Give step by step instructions on setting up the interpreter on a nix-based system and provide a forked github repo for nix users. This should allow nix users to just `git clone foo` and `nix-build` (spoiler: it won&rsquo;t be that easy but still not hard.)\\n3.  Popularize Csaba&rsquo;s project! It is a refreshing take on Haskell optimization and compilation.\\n\\n\\n<a id=\\"orgfeb334e\\"></a>\\n\\n# Making sense of the project\\n\\nThe external STG interpreter is part of the [GRIN compiler](https://github.com/grin-compiler) project. We are not doing anything with the GRIN compiler (yet!) and so we are only interested in [The GHC whole compiler project](https://github.com/grin-compiler/ghc-whole-program-compiler-project). The whole-compiler-project has several sub-projects that we&rsquo;ll be building and using directly:\\n\\n-   [external-stg](https://github.com/grin-compiler/ghc-whole-program-compiler-project/tree/master/external-stg): This subproject provides utilites we&rsquo;ll be using, in particular `mkfullpak`\\n-   [external-stg-interpreter](https://github.com/grin-compiler/ghc-whole-program-compiler-project/tree/master/external-stg-interpreter): This is the actual STG interpreter. The good news is that this is independent of the rest of the project and can be built just like a regular Haskell executable\\n-   [ghc-wpc](https://github.com/grin-compiler/ghc-wpc/tree/b51ab235f5c07caa5eb3dd3b40487f67f50fb838): This is a fork of `ghc-8.10.x` (I&rsquo;m not sure exactly which version it forks to be honest) which we must build in order to use the external STG interpreter. Ghc-wpc serves as a frontend for the external-stg-interpreter.\\n\\n\\n<a id=\\"org1d461dc\\"></a>\\n\\n# Building a working external STG interpreter\\n\\nThe external STG interpreter can be built like any regular haskell executable. But in order to use the interpreter we have to build `ghc-wpc`. `ghc-wpc` is necessary because it serves as a frontend for the STG interpreter. It compiles a Haskell program like normal and then dumps an enriched STG IR to file. This file is then run through a utility `gen-exe` (gen-exe is an executable built in the [external-stg-compiler](https://github.com/grin-compiler/ghc-whole-program-compiler-project/tree/master/external-stg-compiler) sub-project) which picks up the compilation pipeline from the STG IR and creates an executable like we would expect from a normal compilation pipeline.\\n\\nThe major difference between this process and the usual compiler pipeline is that `ghc-wpc` leaves enough compiler information on disk for the rest of the tooling to consume, namely, in files with a `*.o_stgbin` (this is STG IR generated at compile time), and `*.o_stgapp` (project linker and dependency information) extension. Thus, once we build this custom ghc version we can use it to build the source code we wish to analyze and begin our optimization work.\\n\\nFor the rest of this tutorial I&rsquo;ll be referencing my [fork](https://github.com/doyougnu/ghc-whole-program-compiler-project) of the `ghc-whole-compiler-project` that includes everything you need if you want to follow along, including `.nix` files for creating a `nix-shell` which will prepare a suitable environment to run the entire toolchain.\\n\\n\\n<a id=\\"orgb670539\\"></a>\\n\\n## ghc.nix\\n\\nThe usual way to build ghc using a nix based system is with the [ghc.nix](https://github.com/alpmestan/ghc.nix) project. Ghc.nix provides a `default.nix` with a suitable environment to run hadrian and build ghc. For `ghc-wpc` we&rsquo;ll need some special packages, and we need our boot compiler to be *exactly* `ghc-8.3.3`. The custom `ghc.nix` file is included in my fork, I&rsquo;ve taken the liberty to pin the nixpkgs to the right version for `ghc-8.3.3`. So let&rsquo;s begin:\\n\\nClone the forked repo:\\n\\n```bash\\n$ git clone https://github.com/doyougnu/ghc-whole-program-compiler-project.git\\n\\n$ cd ghc-whole-program-compiler-project\\n\\n$ tree -L 1\\n.\\n\u251c\u2500\u2500 dist-newstyle\\n\u251c\u2500\u2500 external-stg\\n\u251c\u2500\u2500 external-stg-compiler\\n\u251c\u2500\u2500 external-stg-interpreter\\n\u251c\u2500\u2500 ghc.nix.wpc\\n\u251c\u2500\u2500 ghc-wpc\\n\u251c\u2500\u2500 lambda\\n\u251c\u2500\u2500 mod-pak\\n\u251c\u2500\u2500 README.md\\n\u251c\u2500\u2500 shell.nix\\n\u251c\u2500\u2500 stack.yaml\\n\u2514\u2500\u2500 stack.yaml.lock\\n```\\n\\nYou&rsquo;ll find the patched `ghc.nix` included (`ghc.nix.wpc`) and a `shell.nix` for a `nix-shell`. The `shell.nix` file simply references `ghc.nix.wpc/default.nix` with the appropriate options:\\n\\n```nix\\n$ cat shell.nix\\nimport (./ghc.nix.wpc/default.nix) {\\nuseClang = true;\\nwithHadrianDeps = true;\\nwithIde   = false;\\nwithLlvm  = true;\\n}\\n```\\n\\n\\n<a id=\\"orgbb3f1d5\\"></a>\\n\\n## Building ghc-wpc\\n\\nNow we can enter a nix-shell and build `ghc-wpc`:\\n\\n```bash\\n$ pwd\\n/home/doyougnu/programming/haskell/ghc-whole-program-compiler-project\\n\\n$ nix-shell shell.nix  # or just nix-shell\\ntrace: checking if /home/doyougnu/programming/haskell/ghc-whole-program-compiler-project/hadrian/hadrian.cabal is present:  no\\nRecommended ./configure arguments (found in $CONFIGURE_ARGS:\\nor use the configure_ghc command):\\n\\n  --with-gmp-includes=/nix/store/sznfxigwvrvn6ar3nz3f0652zsld9xqj-gmp-6.2.0-dev/include\\n  --with-gmp-libraries=/nix/store/447im4mh8gmw85dkrvz3facg1jsbn6c7-gmp-6.2.0/lib\\n  --with-curses-includes=/nix/store/84g84bg47xxg01ba3nv0h418v5v3969n-ncurses-6.1-20190112-dev/include\\n  --with-curses-libraries=/nix/store/xhhkr936b9q5sz88jp4l29wljbbcg39k-ncurses-6.1-20190112/lib\\n  --with-libnuma-includes=/nix/store/bfrcskjspk9a179xqqf1q9xqafq5s8d2-numactl-2.0.13/include\\n  --with-libnuma-libraries=/nix/store/bfrcskjspk9a179xqqf1q9xqafq5s8d2-numactl-2.0.13/lib\\n  --with-libdw-includes=/nix/store/sv6f05ngaarba50ybr6fdfc7cciv6nbv-elfutils-0.176/include\\n  --with-libdw-libraries=/nix/store/sv6f05ngaarba50ybr6fdfc7cciv6nbv-elfutils-0.176/lib\\n  --enable-dwarf-unwind\\n\\n[nix-shell:~/programming/haskell/ghc-whole-program-compiler-project]$\\n```\\n\\nNow we need to `cd` into `ghc-wpc` and tweak the hadrian build.\\n\\n**MAJOR CONSTRAINT: You must build ghc-wpc with hadrian/build-stack**, if you build in any other way you&rsquo;ll run into shared object errors, see this [ticket](https://github.com/grin-compiler/ghc-whole-program-compiler-project/issues/4) for details.\\n\\nSo in order to build `ghc-wpc` with stack we&rsquo;ll have to tweak the `stack.yaml` file. **You must do this since it is not included in the fork**:\\n\\nQuick side note: To make the formatting nicer I truncate\\n`nix-shell:~/foo/bar/baz/ghc-whole-program-compiler-project` to just `...`, so\\n`nix-shell:.../ghc-wpc` is equivalent to\\n`~/path/to/ghc-whole-compiler-project/ghc-wpc`.\\n\\n```bash\\n[nix-shell:...]$ cd ghc-wpc/hadrian/\\n\\n[nix-shell:.../ghc-wpc/hadrian]$ cat stack.yaml\\nresolver: lts-15.5\\n\\npackages:\\n- \'.\'\\n- \'GHC-Cabal\'\\n\\nsystem-ghc: true\\n\\nnix:\\n   enable: true\\n   shell-file: ../../shell.nix\\n```\\n\\nThe changes are: (1) tell `stack` we are using `nix`, and (2) reference the `shell.nix` file which points to `ghc.wpc.nix` at the root of the project, i.e., `ghc-whole-program-compiler-project/shell.nix`.\\n\\nNow we should be able to begin our build, return to the root of `ghc-wpc` and run the following:\\n\\n```bash\\n[nix-shell:.../ghc-wpc/hadrian]$ cd ..\\n\\n[nix-shell:.../ghc-wpc]$ ./boot && ./configure\\n\\n[nix-shell:.../ghc-wpc]$ hadrian/build-stack -j\\n```\\n\\nand go get some coffee since this will take some time. Once it finishes you should have the `ghc-wpc` binary in `_build/stage1/bin`\\n\\n```bash\\n[nix-shell:.../ghc-wpc]$ ls -l _build/stage1/bin/\\ntotal 8592\\n-rwxr-xr-x 1 doyougnu users 1843752 Apr 29 23:01 ghc\\n-rw-r--r-- 1 doyougnu users   11082 Apr 29 23:01 ghc.dyn_o_ghc_stgapp\\n-rwxr-xr-x 1 doyougnu users  660128 Apr 29 22:50 ghc-pkg\\n-rw-r--r-- 1 doyougnu users    9977 Apr 29 22:50 ghc-pkg.dyn_o_ghc_stgapp\\n-rwxr-xr-x 1 doyougnu users 4624680 Apr 29 23:01 haddock\\n-rw-r--r-- 1 doyougnu users   16883 Apr 29 23:01 haddock.dyn_o_ghc_stgapp\\n-rwxr-xr-x 1 doyougnu users   49344 Apr 29 22:25 hp2ps\\n-rw-r--r-- 1 doyougnu users    2504 Apr 29 22:25 hp2ps.dyn_o_ghc_stgapp\\n-rwxr-xr-x 1 doyougnu users  716440 Apr 29 22:35 hpc\\n-rw-r--r-- 1 doyougnu users    9959 Apr 29 22:35 hpc.dyn_o_ghc_stgapp\\n-rwxr-xr-x 1 doyougnu users  738544 Apr 29 22:35 hsc2hs\\n-rw-r--r-- 1 doyougnu users   10264 Apr 29 22:35 hsc2hs.dyn_o_ghc_stgapp\\n-rwxr-xr-x 1 doyougnu users   58384 Apr 29 22:34 runghc\\n-rw-r--r-- 1 doyougnu users    8864 Apr 29 22:34 runghc.dyn_o_ghc_stgapp\\n```\\n\\nNotice that this build dumped `*.<way>_o_ghc_stgapp` files!\\n\\n\\n<a id=\\"org9ef4bc5\\"></a>\\n\\n## Building the stg tooling\\n\\nNow that we have a working `ghc-wpc` we need to build the rest of the project by pointing `stack` to the `ghc-wpc` binary in `ghc-wpc/_build/stage1/bin`. That is, we must change the `ghc-whole-program-compiler-project/stack.yaml` file:\\n\\n```bash\\n[nix-shell:~/programming/haskell/ghc-whole-program-compiler-project]$ cat stack.yaml\\nresolver: lts-16.13\\n\\nallow-newer: true\\n\\npackages:\\n  - \'external-stg-compiler\'\\n  - \'external-stg\'\\n\\nghc-options:\\n  \\"$everything\\": -fno-stgbin -fno-stgapp -optcxx-std=c++17\\n\\nextra-deps:\\n  - async-pool-0.9.1@sha256:4015140f896c3f1652b06a679b0ade2717d05557970c283ea2c372a71be2a6a1,1605\\n  - souffle-haskell-1.1.0\\n  - zip-1.7.0\\n\\n\\n# use custom ext-stg whole program compiler GHC\\ncompiler:     ghc-8.11.0\\nskip-ghc-check: true\\n\\nnix:\\n  enable: false\\n\\n\\n# use local GHC (for development)\\nsystem-ghc: true\\nextra-path:\\n  - /home/doyougnu/programming/haskell/ghc-whole-program-compiler-project/ghc-wpc/_build/stage1/bin\\n\\n# DEBUG INFO\\n#dump-logs: all\\n#build:\\n#  keep-tmp-files: true\\n#  cabal-verbose: true\\n```\\n\\nThe changes are: (1) set `compiler: ghc-8.11.0` (the `ghc-wpc` fork), (2) set `skip-ghc-check: true` so that stack doesn&rsquo;t complain about the ghc version, (3) set `nix.enable: false`, confusingly if you leave this as true then stack will try to use `nixpkgs` to get a ghc binary, but we want it to use our local binary so we disable this even though we&rsquo;ll still be in our original nix-shell (4) set `system-path: true` to tell stack we will be using a ghc we have on our system, and finally (5) set `extra-path: <path-to-ghc-wpc-binary>`.\\n\\nNow we can run stack and install the stg tooling:\\n\\n```bash\\n[nix-shell:...]$ stack --stack-root `pwd`/.stack-root install\\nTrouble loading CompilerPaths cache: UnliftIO.Exception.throwString called with:\\n\\nCompiler file metadata mismatch, ignoring cache\\nCalled from:\\n  throwString (src/Stack/Storage/User.hs:277:8 in stack-2.7.5-9Yv1tjrmAU3JiZWCo86ldN:Stack.Storage.User)\\n\\nWARNING: Ignoring tagged\'s bounds on template-haskell (>=2.8 && <2.17); using template-haskell-2.17.0.0.\\nReason: allow-newer enabled.\\nWARNING: Ignoring aeson\'s bounds on template-haskell (>=2.9.0.0 && <2.17); using template-haskell-2.17.0.0.\\nReason: allow-newer enabled.\\nWARNING: Ignoring th-abstraction\'s bounds on template-haskell (>=2.5 && <2.17); using template-haskell-2.17.0.0.\\nReason: allow-newer enabled.\\nWARNING: Ignoring unliftio-core\'s bounds on base (>=4.5 && <4.14); using base-4.14.0.0.\\nReason: allow-newer enabled.\\nWARNING: Ignoring souffle-haskell\'s bounds on megaparsec (>=7.0.5 && <8); using megaparsec-8.0.0.\\nstack --stack-root `pwd`/.stack-root install\\n... # bunch of output\\n...\\n...\\nCopied executables to /home/doyougnu/.local/bin:\\n- dce-fullpak\\n- ext-stg\\n- fullpak\\n- gen-exe\\n- gen-exe2\\n- gen-obj\\n- gen-obj2\\n- mkfullpak\\n- show-ghc-stg\\n\\nWarning: Installation path /home/doyougnu/.local/bin not found on the PATH environment variable.\\n```\\n\\nYou can add `~/.local/bin` to your `PATH` if you want, I&rsquo;ll just be directly referencing these binaries as we go.\\n\\n\\n<a id=\\"org4a2eaf9\\"></a>\\n\\n# Building the external-stg-interpreter\\n\\nWe are almost all done, all that is left is to build the external-stg-interpreter and run a small script that links everything together into a shared object for the interpreter. So:\\n\\n```bash\\n[nix-shell:...]$ cd external-stg-interpreter/\\n\\n[nix-shell:.../external-stg-interpreter]$ stack install\\n...  # bunch of output\\n...\\nCopied executables to /home/doyougnu/.local/bin:\\n- ext-stg\\n- ext-stg-interpreter\\n- fullpak\\n- mkfullpak\\n\\nWarning: Installation path /home/doyougnu/.local/bin not found on the PATH environment variable.\\n```\\n\\nNow we have our `ext-stg-interpreter` built! There are a few caveats I want to point out here. I&rsquo;ve modified `ghc-whole-program-compiler-project/external-stg-interpreter/stack.yaml` to load the right packages and use nix:\\n\\n```bash\\n[nix-shell:.../external-stg-interpreter]$ cat stack.yaml\\nresolver: lts-16.13\\n\\npackages:\\n  - \'.\'\\n  - \'external-stg\'\\n\\nextra-deps:\\n  - souffle-haskell-2.1.0\\n  - primitive-0.7.1.0\\n  - zip-1.7.0\\n\\nnix:\\n  enable: true\\n  packages: [ zlib, libffi, pkg-config, bzip2 ]\\n```\\n\\nNotice the `nix:` block. We could have just as easily built this using `nix` directly or using our `shell.nix` file.\\n\\n\\n<a id=\\"org1d34a2e\\"></a>\\n\\n# Linking the external-stg-interpreter\\n\\nThe only task left is to link into a shared object library called\\n`libHSbase-4.14.0.0.cbits.so`. To do that we need to use the script called, `c`,\\nin `ghc-whole-program-compiler-project/external-stg-interpreter/data`. This\\nscript is a bit of a hack, it generates the shared object file so that we can link the symbols requested by the C\\nFFI in `base`, but it populates those functions with our replacements, which do absolutely nothing. For example, we supply a fake garbage collect:\\n```c\\n// in .../external-stg-interpreter/data/cbits.so-script/c-src/fake_rts.c\\n...\\nvoid performGC(void) {\\n}\\n\\nvoid performMajorGC(void) {\\n}\\n...\\n```\\n\\nThis works because we won\'t be using the runtime system at all, we\'ll be using\\nthe external STG interpreter instead, however we still need to provide these\\nsymbols in order to link. ****MAJOR NOTE: this file must be next to any\\n\\\\*.fullpak file you&rsquo;ll be running the interpreter on**** or else\\nyou&rsquo;ll get an undefined symbol error during linking, for example:\\n\\n```bash\\n[nix-shell:.../external-stg-interpreter/data]$ ls\\ncbits.so-script  ghc-rts-base.fullpak  minigame-strict.fullpak\\n\\n### notice no .so file\\n[nix-shell:.../external-stg-interpreter/data]$ ~/.local/bin/ext-stg-interpreter ghc-rts-base.fullpak\\next-stg-interpreter: user error (dlopen: ./libHSbase-4.14.0.0.cbits.so: cannot open shared object file: No such file or directory)\\n\\n## we error\'d out because it was missing, also\\n## if you get this error then you have an old cbits.so file and need to rerun the c script\\n[nix-shell:.../external-stg-interpreter/data]$ ~/.local/bin/ext-stg-interpreter ghc-rts-base.fullpak\\next-stg-interpreter: user error (dlopen: ./libHSbase-4.14.0.0.cbits.so: undefined symbol: getProcessElapsedTime)\\n```\\n\\nTo link the interpreter we need to run `c` in the `data/cbits.so-script` sub-folder:\\n\\n```bash\\n[nix-shell:.../external-stg-interpreter]$ cd data/cbits.so-script/\\n\\n[nix-shell:.../external-stg-interpreter/data/cbits.so-script]$ ls\\nar  c  cbits-rts.dyn_o  c-src  libHSbase-4.14.0.0.cbits.so  stub-base.dyn_o\\n\\n[nix-shell:.../external-stg-interpreter/data/cbits.so-script]$ ./c\\n++ ls ar/libHSbase-4.14.0.0-ghc8.11.0.20210220.dyn_o_cbits.a ar/libHSbindings-GLFW-3.3.2.0-Jg9TvsfYUZwD0ViIP0H2Tz-ghc8.11.0.20210306.dyn_o_cbits.a ar/libHSbytestring-0.10.9.0-ghc8.11.0.20210306.dyn_o_cbits.a ar/libHScriterion-measurement-0.1.2.0-73BCI2Fnk7qE8QjjTa1xNa-ghc8.11.0.20210324.dyn_o_cbits.a ar/libHSghc-8.11.0.20210306-ghc8.11.0.20210306.dyn_o_cbits.a ar/libHSGLUT-2.7.0.15-1pzTWDEZBcYHcS36qZ2lpp-ghc8.11.0.20201112.dyn_o_cbits.a ar/libHSGLUT-2.7.0.15-1pzTWDEZBcYHcS36qZ2lpp-ghc8.11.0.20210324.dyn_o_stubs.a ar/libHShashable-1.3.0.0-Kn7aNSFvzgo2qY16wYzuCX-ghc8.11.0.20210306.dyn_o_cbits.a ar/libHSinteger-gmp-1.0.3.0-ghc8.11.0.20210220.dyn_o_cbits.a ar/libHSlambdacube-quake3-engine-0.1.0.0-7CKLP3Rqgq0PR81lhlwlR-ghc8.11.0.20210306.dyn_o_cbits.a ar/libHSmersenne-random-pure64-0.2.2.0-ExYg8DmthtrLG9JevQbt2m-ghc8.11.0.20210306.dyn_o_cbits.a ar/libHSOpenGLRaw-3.3.4.0-5vXBlmbOM3AIT7GRYfpE3o-ghc8.11.0.20201112.dyn_o_cbits.a ar/libHSprimitive-0.7.0.1-2k3g9qX0zz16vEv34R307m-ghc8.11.0.20210306.dyn_o_cbits.a ar/libHSprocess-1.6.8.2-ghc8.11.0.20210220.dyn_o_cbits.a ar/libHStext-1.2.4.0-ghc8.11.0.20210220.dyn_o_cbits.a ar/libHSunix-2.7.2.2-ghc8.11.0.20210220.dyn_o_cbits.a ar/libHSunix-2.7.2.2-ghc8.11.0.20210220.dyn_o_stubs.a ar/libHSzlib-0.6.2.1-1I6DmfbLEyTBgDZI7SbZfW-ghc8.11.0.20210306.dyn_o_stubs.a\\n++ ls stub-base.dyn_o/Blank_stub.dyn_o stub-base.dyn_o/ClockGetTime_stub.dyn_o stub-base.dyn_o/Internals_stub.dyn_o stub-base.dyn_o/RUsage_stub.dyn_o\\n++ ls cbits-rts.dyn_o/StgPrimFloat.dyn_o cbits-rts.dyn_o/TTY.dyn_o\\n++ ls c-src/fake_rts.c c-src/hack.c c-src/hschooks.c\\n+ gcc -o libHSbase-4.14.0.0.cbits.so -shared -Wl,--whole-archive ar/libHSbase-4.14.0.0-ghc8.11.0.20210220.dyn_o_cbits.a ar/libHSbindings-GLFW-3.3.2.0-Jg9TvsfYUZwD0ViIP0H2Tz-ghc8.11.0.20210306.dyn_o_cbits.a ar/libHSbytestring-0.10.9.0-ghc8.11.0.20210306.dyn_o_cbits.a ar/libHScriterion-measurement-0.1.2.0-73BCI2Fnk7qE8QjjTa1xNa-ghc8.11.0.20210324.dyn_o_cbits.a ar/libHSghc-8.11.0.20210306-ghc8.11.0.20210306.dyn_o_cbits.a ar/libHSGLUT-2.7.0.15-1pzTWDEZBcYHcS36qZ2lpp-ghc8.11.0.20201112.dyn_o_cbits.a ar/libHSGLUT-2.7.0.15-1pzTWDEZBcYHcS36qZ2lpp-ghc8.11.0.20210324.dyn_o_stubs.a ar/libHShashable-1.3.0.0-Kn7aNSFvzgo2qY16wYzuCX-ghc8.11.0.20210306.dyn_o_cbits.a ar/libHSinteger-gmp-1.0.3.0-ghc8.11.0.20210220.dyn_o_cbits.a ar/libHSlambdacube-quake3-engine-0.1.0.0-7CKLP3Rqgq0PR81lhlwlR-ghc8.11.0.20210306.dyn_o_cbits.a ar/libHSmersenne-random-pure64-0.2.2.0-ExYg8DmthtrLG9JevQbt2m-ghc8.11.0.20210306.dyn_o_cbits.a ar/libHSOpenGLRaw-3.3.4.0-5vXBlmbOM3AIT7GRYfpE3o-ghc8.11.0.20201112.dyn_o_cbits.a ar/libHSprimitive-0.7.0.1-2k3g9qX0zz16vEv34R307m-ghc8.11.0.20210306.dyn_o_cbits.a ar/libHSprocess-1.6.8.2-ghc8.11.0.20210220.dyn_o_cbits.a ar/libHStext-1.2.4.0-ghc8.11.0.20210220.dyn_o_cbits.a ar/libHSunix-2.7.2.2-ghc8.11.0.20210220.dyn_o_cbits.a ar/libHSunix-2.7.2.2-ghc8.11.0.20210220.dyn_o_stubs.a ar/libHSzlib-0.6.2.1-1I6DmfbLEyTBgDZI7SbZfW-ghc8.11.0.20210306.dyn_o_stubs.a -Wl,--no-whole-archive stub-base.dyn_o/Blank_stub.dyn_o stub-base.dyn_o/ClockGetTime_stub.dyn_o stub-base.dyn_o/Internals_stub.dyn_o stub-base.dyn_o/RUsage_stub.dyn_o cbits-rts.dyn_o/StgPrimFloat.dyn_o cbits-rts.dyn_o/TTY.dyn_o -fPIC c-src/fake_rts.c c-src/hack.c c-src/hschooks.c -lm -lgmp -ltinfo -lGL -lX11 -lXi -lXrandr -lXxf86vm -lXcursor -lXinerama -lpthread\\n```\\n\\nThis will produce `libHSbase-4.14.0.0.cbits.so` in the immediate directory:\\n\\n```bash\\n[nix-shell:.../external-stg-interpreter/data/cbits.so-script]$ ls -l\\ntotal 984\\ndrwxr-xr-x 2 doyougnu users   4096 Apr 27 14:10 ar\\n-rwxr-xr-x 1 doyougnu users    300 Apr 27 14:10 c\\ndrwxr-xr-x 2 doyougnu users   4096 Apr 27 14:10 cbits-rts.dyn_o\\ndrwxr-xr-x 2 doyougnu users   4096 Apr 27 14:10 c-src\\n-rwxr-xr-x 1 doyougnu users 986008 Apr 30 11:50 libHSbase-4.14.0.0.cbits.so    ## <----- new\\ndrwxr-xr-x 2 doyougnu users   4096 Apr 27 14:10 stub-base.dyn_o\\n```\\n\\nNow we can test our interpreter by running it on the `*.fullpak` files in `external-stg-interpreter/data`:\\n\\n```bash\\n[nix-shell:.../external-stg-interpreter/data/cbits.so-script]$ cd ..\\n\\n[nix-shell:.../external-stg-interpreter/data]$ ls\\ncbits.so-script  ghc-rts-base-call-graph-summary  ghc-rts-base-call-graph.tsv  ghc-rts-base.fullpak  libHSbase-4.14.0.0.cbits.so  minigame-strict.fullpak\\n\\n## remove the old .so file\\n[nix-shell:.../external-stg-interpreter/data]$ rm libHSbase-4.14.0.0.cbits.so\\n\\n## soft-link to the one we just built\\n[nix-shell:.../external-stg-interpreter/data]$ ln -s cbits.so-script/libHSbase-4.14.0.0.cbits.so libHSbase-4.14.0.0.cbits.so\\n\\n[nix-shell:.../external-stg-interpreter/data]$ ls -l\\ntotal 79220\\ndrwxr-xr-x 6 doyougnu users     4096 Apr 30 11:50 cbits.so-script\\n-rw-r--r-- 1 doyougnu users       48 Apr 30 11:47 ghc-rts-base-call-graph-summary\\n-rw-r--r-- 1 doyougnu users    28238 Apr 30 11:47 ghc-rts-base-call-graph.tsv\\n-rw-r--r-- 1 doyougnu users 22450708 Apr 27 14:10 ghc-rts-base.fullpak\\nlrwxrwxrwx 1 doyougnu users       43 Apr 30 11:55 libHSbase-4.14.0.0.cbits.so -> cbits.so-script/libHSbase-4.14.0.0.cbits.so  ### <---- new\\n-rw-r--r-- 1 doyougnu users 58630129 Apr 27 14:10 minigame-strict.fullpak\\n\\n[nix-shell:.../external-stg-interpreter/data]$ ~/.local/bin/ext-stg-interpreter ghc-rts-base.fullpak\\nhello\\nhello\\nssHeapStartAddress: 53522\\nssTotalLNECount: 69\\nssClosureCallCounter: 360\\nexecuted closure id count: 114\\ncall graph size: 150\\n\\n[nix-shell:.../external-stg-interpreter/data]$ ls -l\\ntotal 79220\\ndrwxr-xr-x 6 doyougnu users     4096 Apr 30 11:50 cbits.so-script\\n-rw-r--r-- 1 doyougnu users       48 Apr 30 11:56 ghc-rts-base-call-graph-summary    ### <---- interpreter output\\n-rw-r--r-- 1 doyougnu users    28238 Apr 30 11:56 ghc-rts-base-call-graph.tsv        ### <---- interpreter output\\n-rw-r--r-- 1 doyougnu users 22450708 Apr 27 14:10 ghc-rts-base.fullpak\\nlrwxrwxrwx 1 doyougnu users       43 Apr 30 11:55 libHSbase-4.14.0.0.cbits.so -> cbits.so-script/libHSbase-4.14.0.0.cbits.so\\n-rw-r--r-- 1 doyougnu users 58630129 Apr 27 14:10 minigame-strict.fullpak\\n```\\n\\nAnd it works, we have two new files, `<foo>-call-graph-summary` and `<foo>-call-graph.tsv` which we can analyze to inspect the behavior of our program (more on this later).\\n\\n\\n<a id=\\"org2daa4b8\\"></a>\\n\\n# The whole setup process on a demo\\n\\nThat was a rather involved example, to make clear the dependencies and steps required to run this on your own code the rest of this tutorial will run the interpreter on two of Csaba&rsquo;s demo&rsquo;s from his skillshare talk. First let&rsquo;s grab the code:\\n\\n```bash\\n$ pwd\\n/home/doyougnu/programming/haskell\\n\\n$ git clone https://github.com/grin-compiler/ext-stg-interpreter-presentation-demos.git\\n\\n$ ls\\next-stg-interpreter-presentation-demos ghc-whole-program-compiler-project ..\\n```\\n\\nNow we&rsquo;ll run the first demo which is a simply fold over a list:\\n\\n```bash\\n$ nix-shell ghc-whole-program-compiler-project/shell.nix\\ntrace: checking if /home/doyougnu/programming/haskell/hadrian/hadrian.cabal is present:  no\\nRecommended ./configure arguments (found in $CONFIGURE_ARGS:\\nor use the configure_ghc command):\\n\\n  --with-gmp-includes=/nix/store/sznfxigwvrvn6ar3nz3f0652zsld9xqj-gmp-6.2.0-dev/include\\n  --with-gmp-libraries=/nix/store/447im4mh8gmw85dkrvz3facg1jsbn6c7-gmp-6.2.0/lib\\n  --with-curses-includes=/nix/store/84g84bg47xxg01ba3nv0h418v5v3969n-ncurses-6.1-20190112-dev/include\\n  --with-curses-libraries=/nix/store/xhhkr936b9q5sz88jp4l29wljbbcg39k-ncurses-6.1-20190112/lib\\n  --with-libnuma-includes=/nix/store/bfrcskjspk9a179xqqf1q9xqafq5s8d2-numactl-2.0.13/include\\n  --with-libnuma-libraries=/nix/store/bfrcskjspk9a179xqqf1q9xqafq5s8d2-numactl-2.0.13/lib\\n  --with-libdw-includes=/nix/store/sv6f05ngaarba50ybr6fdfc7cciv6nbv-elfutils-0.176/include\\n  --with-libdw-libraries=/nix/store/sv6f05ngaarba50ybr6fdfc7cciv6nbv-elfutils-0.176/lib\\n  --enable-dwarf-unwind\\n\\n[nix-shell:~/programming/haskell]$ cd ext-stg-interpreter-presentation-demos/demo-01-tsumupto/\\n\\n[nix-shell:~/programming/haskell/ext-stg-interpreter-presentation-demos/demo-01-tsumupto]$ ../../ghc-whole-program-compiler-project/ghc-wpc/_build/stage1/bin/ghc -O2 tsumupto.hs\\n[1 of 1] Compiling Main             ( tsumupto.hs, tsumupto.o )\\nLinking tsumupto ...\\n$ cd ext-stg-interpreter-presentation-demos/demo-01-tsumupto\\n\\n$ ls\\ntsumupto  tsumupto.hi  tsumupto.hs  tsumupto.o  tsumupto.o_ghc_stgapp  tsumupto.o_modpak\\n```\\n\\nNote, that we have two new files: `*.o_ghc_stgapp` and `.o_modpak` as a result of building with `ghc-wpc`. If you try to run this from outside the nix-shell you&rsquo;ll get an error about missing `mkmodpak`:\\n\\n```bash\\n$ ../../ghc-whole-program-compiler-project/ghc-wpc/_build/stage1/bin/ghc -O2 tsumupto.hs\\n[1 of 1] Compiling Main             ( tsumupto.hs, tsumupto.o )\\nghc: could not execute: mkmodpak\\n```\\n\\nNow that we have those files we can run the interpreter, but first though we need to make a `*.fullpak` file from the `*.o_ghc_stgapp` file and create a symbolic link to `libHSbase-4.14.0.0.cbits.so`:\\n\\n```bash\\n## make the fullpack file\\n$ ~/.local/bin/mkfullpak tsumupto.o_ghc_stgapp\\nall modules: 259\\napp modules: 113\\napp dependencies:\\n... # bunch of output\\n...\\nmain                                                         Main\\ncreating tsumupto.fullpak\\n\\n## create the link to the shared object file\\n$ ln -s ../../ghc-whole-program-compiler-project/external-stg-interpreter/data/cbits.so-script/libHSbase-4.14.0.0.cbits.so libHSbase-4.14.0.0.cbits.so\\n\\n## the final directory should look like this\\n$ ls\\nlibHSbase-4.14.0.0.cbits.so  tsumupto  tsumupto.fullpak  tsumupto.hi  tsumupto.hs  tsumupto.o  tsumupto.o_ghc_stgapp  tsumupto.o_modpak\\n```\\n\\nAnd now we can run the interpreter:\\n\\n```bash\\n$ ~/.local/bin/ext-stg-interpreter tsumupto.fullpak\\n50005000\\nssHeapStartAddress: 44082\\nssTotalLNECount: 43\\nssClosureCallCounter: 30275\\nexecuted closure id count: 112\\ncall graph size: 146\\n```\\n\\nThe first line is the output of the program and the rest are diagnostics that the interpreter outputs. More importantly we should have a tab-separated csv file and call graph file in our local directory after running the interpreter:\\n\\n```bash\\n$ ls -l\\ntotal 23876\\nlrwxrwxrwx 1 doyougnu users      114 Apr 30 12:21 libHSbase-4.14.0.0.cbits.so -> ../../ghc-whole-program-compiler-project/external-stg-interpreter/data/cbits.so-script/libHSbase-4.14.0.0.cbits.so\\n-rwxr-xr-x 1 doyougnu users  9442648 Apr 30 12:12 tsumupto\\n-rw-r--r-- 1 doyougnu users       53 Apr 30 12:23 tsumupto-call-graph-summary   ### <---- interpreter output\\n-rw-r--r-- 1 doyougnu users    27490 Apr 30 12:23 tsumupto-call-graph.tsv       ### <---- interpreter output\\n-rw------- 1 doyougnu users 14922366 Apr 30 12:19 tsumupto.fullpak\\n-rw-r--r-- 1 doyougnu users     1769 Apr 30 12:12 tsumupto.hi\\n-rw-r--r-- 1 doyougnu users      207 Apr 28 22:56 tsumupto.hs\\n-rw-r--r-- 1 doyougnu users     4488 Apr 30 12:12 tsumupto.o\\n-rw-r--r-- 1 doyougnu users     8817 Apr 30 12:12 tsumupto.o_ghc_stgapp\\n-rw------- 1 doyougnu users     9803 Apr 30 12:12 tsumupto.o_modpak\\n```\\n\\nWhich can be loaded into `gephi` for closer inspection of the call graph of our program. Be sure to watch the rest of the demo in Csaba&rsquo;s talk for this part! For now we&rsquo;ll be going over using `gephi` and these files in our next blog post in this series, stay tuned!\\n\\n\\n<a id=\\"org8193a1a\\"></a>\\n\\n# Summary\\n\\n\\n<a id=\\"org940ba90\\"></a>\\n\\n## File Descriptions\\n\\n-   `foo.modpak`: A zip file which contains the Core, STG, CMM, source code, and assembly for the module `foo`\\n-   `foo.fullpak`: A zip file which contains the same information as `modpack` but for every module of the program rather than just module `foo`.\\n-   `foo.o_ghc_stgapp`: a yaml like file that contains:\\n    -   the module&rsquo;s dependencies including package dependencies\\n    -   a bunch of file paths for shared objects of the libraries\\n    -   the flags the module was built with\\n-   `libHSbase-4.14.0.0.cbits.so`: shared object file created by `ext-stg-interpreter/data/cbits.so-script.c`. Required to be in the same directory as `ext-stg-interpreter` will be invoked.\\n\\n\\n<a id=\\"org8e9f409\\"></a>\\n\\n## Step-by-Step guide for running the interpreter on your code\\n\\n1.  Build your project with `ghc-wpc/_build/stage1/bin` by directly invoking that `ghc` (as I did in the demo-01 project) or by pointing stack to it with `system-ghc` and `extra-path` in `stack.yaml`, or by passing `-w <path-to-ghc-wpc-binary` with cabal.\\n2.  Generate the `foo.fullpak` file with `mkfullpak foo.o_ghc_stgapp`\\n3.  Soft-link to `libHSbase-4.14.0.0.cbits.so` in the directory you will run the interpreter in. This file must be present when you run the interpreter!\\n4.  Now run the interpreter on `project.fullpak`\\n5.  Analyze `foo-call-graph-summary` and `foo-call-graph.tsv` with whatever tools make sense to you\\n\\n## Footnotes\\n\\n[^1]: This isn&rsquo;t completely true, there is the `RuntimeRep` type controls\\n  exactly this and the levity polymorphism work by [Richard\\n  Eisenberg](https://richarde.dev/). See [this\\n  video](https://www.youtube.com/watch?v=Mb_B-j8ePfc) for examples on using these\\n  features. We do plan to include a more thorough and real world example on using\\n  levity polymorphism for better performance in the [haskell optimization\\n  handbook](https://github.com/haskellfoundation/tech-proposals/pull/26)."},{"id":"2022-04-28-on-the-inlining-of-integer-and-natural-operations","metadata":{"permalink":"/2022-04-28-on-the-inlining-of-integer-and-natural-operations","source":"@site/blog/2022-04-28-on-the-inlining-of-integer-and-natural-operations-bot8CUQvoe-import.md","title":"On the inlining of Integer and Natural operations","description":"In this post I discuss the inlining of Integer and Natural operations in Haskell. It\u2019s a promising performance work I\u2019ve been conducting six months ago, which was blocked by an independent issue, but that I will likely resume soon as the issue has been fixed in the meantime.","date":"2022-04-28T00:00:00.000Z","formattedDate":"April 28, 2022","tags":[{"label":"ghc","permalink":"/tags/ghc"}],"readingTime":4.135,"truncated":false,"authors":[{"name":"Sylvain Henry","title":"Haskell DevX Engineer @ IOG","email":"sylvain.henry@iohk.io","key":"sylvain"}],"frontMatter":{"slug":"2022-04-28-on-the-inlining-of-integer-and-natural-operations","title":"On the inlining of Integer and Natural operations","authors":["sylvain"],"tags":["ghc"],"custom_edit_url":null},"prevItem":{"title":"Setting up Csaba\'s External STG Interpreter","permalink":"/2022-05-02-setup-ext-stg-interp"},"nextItem":{"title":"GHC March 2022 Update","permalink":"/2022-04-19-ghc-march-2022-update"}},"content":"In this post I discuss the inlining of Integer and Natural operations in Haskell. It\u2019s a promising performance work I\u2019ve been conducting six months ago, which was blocked by an independent issue, but that I will likely resume soon as the issue has been fixed in the meantime.\\n\\n---\\n\\n\\nTo follow this post, you must know that `Natural` numbers are represented as follows in `ghc-bignum`:\\n\\n```haskell\\n-- | Natural number\\n--\\n-- Invariant: numbers <= WORD_MAXBOUND use the `NS` constructor\\ndata Natural\\n   = NS !Word#\\n   | NB !BigNat#\\n```\\n\\nSmall naturals are represented with a `Word#` and large ones with a `BigNat#` (a `ByteArray#`).\\n\\nNow consider the following simple example using Natural:\\n\\n```haskell\\n-- | Add 2 to a Word. Use Natural to avoid Word overflow\\nfoo :: Word -> Natural\\nfoo x = fromIntegral x + 2\\n```\\n\\nThere are only small naturals involved: `fromIntegral x` is small because `x` is a `Word`, and `2` is small. We could hope that GHC would use `Word#` primops to implement this and would allocate a `Natural` heap object for the result *only*. However it\u2019s not what happens currently, even in GHC HEAD. In the following STG dump, we can see that a `Natural` heap object is allocated for `x` before calling `naturalAdd` (`let` bindings in STG reflect heap allocations):\\n\\n```haskell\\nfoo1 = NS! [2##];\\n\\nfoo =\\n    \\\\r [x_sXn]\\n        case x_sXn of {\\n        W# x#_sXp ->\\n        let { sat_sXq = NS! [x#_sXp]; } in  naturalAdd sat_sXq foo1;\\n        };\\n```\\n\\nLet\u2019s look at `naturalAdd`:\\n\\n```haskell\\n-- | Add two naturals\\nnaturalAdd :: Natural -> Natural -> Natural\\n{-# NOINLINE naturalAdd #-}\\nnaturalAdd (NS x) (NB y) = NB (bigNatAddWord# y x)\\nnaturalAdd (NB x) (NS y) = NB (bigNatAddWord# x y)\\nnaturalAdd (NB x) (NB y) = NB (bigNatAdd x y)\\nnaturalAdd (NS x) (NS y) =\\n   case addWordC# x y of\\n      (# l,0# #) -> NS l\\n      (# l,c  #) -> NB (bigNatFromWord2# (int2Word# c) l)\\n```\\n\\nWe are clearly in the last case where both arguments are small. It seems beneficial to allow this function to be inlined. If we did we would get:\\n\\n```javascript\\nfoo =\\n    \\\\r [x_s158]\\n        case x_s158 of {\\n        W# x#_s15a ->\\n        case addWordC# [x#_s15a 2##] of {\\n        (#,#) l_s15c ds_s15d ->\\n        case ds_s15d<TagProper> of ds1_s15e {\\n          __DEFAULT ->\\n              case int2Word# [ds1_s15e] of sat_s15f {\\n              __DEFAULT ->\\n              case bigNatFromWord2# sat_s15f l_s15c of ds2_s15g {\\n              __DEFAULT -> NB [ds2_s15g];\\n              };\\n              };\\n          0# -> NS [l_s15c];\\n        };\\n        };\\n        };\\n```\\n\\nwhich produces much better assembly code, especially if there is no carry:\\n\\n```\\n    addq $2,%rax       ; add 2 to a machine word\\n\\tsetc %bl           ; test the carry.\\n\\tmovzbl %bl,%ebx    ; it could be done\\n\\ttestq %rbx,%rbx    ; more efficiently\\n\\tjne _blk_c17c      ; with \\"jc\\"\\n_blk_c17i:\\n\\tmovq $NS_con_info,-8(%r12) ; alloc NS datacon value\\n\\tmovq %rax,(%r12)           ; with the addition result as payload.\\n\\tleaq -7(%r12),%rbx         ; make it the first argument\\n\\taddq $8,%rbp               ; and then\\n\\tjmp *(%rbp)                ; call continuation\\n...\\n```\\n\\nSo why aren\u2019t we always inlining `naturalAdd`? We even explicitly disallow it with a `NOINLINE` pragma. The reason is that `naturalAdd` and friends are involved in constant-folding rules.\\n\\nFor example, consider:\\n\\n```haskell\\nbar :: Natural -> Natural\\nbar x = x + 2\\n\\nbaz = bar 0x12345678913245678912345679123456798\\n```\\n\\nCurrently we get the following Core:\\n\\n```haskell\\nbar1 = NS 2##\\n\\nbar = \\\\ x_aHU -> naturalAdd x_aHU bar1\\n\\nbaz = NB 99114423092485377935703335253042771879834\\n```\\n\\nYou can see that `baz`  is a constant thanks to constant-folding.\\n\\nHowever if we let `naturalAdd` inline we get:\\n\\n```haskell\\nbaz\\n  = case bigNatAddWord# 99114423092485377935703335253042771879832 2##\\n    of ds_d11H\\n    { __DEFAULT ->\\n    NB ds_d11H\\n    }\\n```\\n\\n`baz` is no longer a constant.\\n\\nA solution would be to add constant-folding rules for `BigNat#` functions, such as `bigNatAddWord#`. This is exactly what we have started doing in [#20361](https://gitlab.haskell.org/ghc/ghc/-/issues/20361). Our new plan is:\\n\\n* Make `BigNat#` operation `NOINLINE` and add constant-folding rules for them\\n* Make Integer/Natural operations `INLINEABLE` (expose their unfolding)\\n* Hence rely on constant-folding for `Word#/Int#/BigNat#` to provide constant folding for `Integer` and `Natural`\\n\\nThe good consequences of this plan are:\\n\\n* Less allocations when bignum operations are inlined and some of the arguments are known to be small/big or fully known (constant).\\n* `Integer` and `Natural` are less magical: you can implement your own similar types and expect the same performance without having to add new rewrite rules\\n\\nThere were some unforeseen difficulties with this plan though:\\n\\n\\n1. Some of the rewrite rules we need involve unboxed values such as `BigNat#` and `Word#` and the weren\u2019t supported. Luckily, this has been recently fixed ([#19313](https://gitlab.haskell.org/ghc/ghc/-/issues/19313)) by removing the \u201capp invariant\u201d ([#20554](https://gitlab.haskell.org/ghc/ghc/-/issues/20554)). Thanks Joachim! That\u2019s the reason why we could resume this work now.\\n2. Some unfoldings (RHSs) become bigger due to the inlining of bignum operations. Hence they may not themselves be inlined further due to inlining thresholds even if it would be beneficial. A better inlining heuristic would fix this (see [#20516](https://gitlab.haskell.org/ghc/ghc/-/issues/20516)). It will likely be the topic of the next post."},{"id":"2022-04-19-ghc-march-2022-update","metadata":{"permalink":"/2022-04-19-ghc-march-2022-update","source":"@site/blog/2022-04-19-ghc-march-2022-update-jeDstmSW5A-import.md","title":"GHC March 2022 Update","description":"JS Backend","date":"2022-04-19T00:00:00.000Z","formattedDate":"April 19, 2022","tags":[{"label":"ghc","permalink":"/tags/ghc"}],"readingTime":2.4,"truncated":false,"authors":[{"name":"Sylvain Henry","title":"Haskell DevX Engineer @ IOG","email":"sylvain.henry@iohk.io","key":"sylvain"}],"frontMatter":{"slug":"2022-04-19-ghc-march-2022-update","title":"GHC March 2022 Update","authors":["sylvain"],"tags":["ghc"],"custom_edit_url":null},"prevItem":{"title":"On the inlining of Integer and Natural operations","permalink":"/2022-04-28-on-the-inlining-of-integer-and-natural-operations"},"nextItem":{"title":"haskell.nix March Update","permalink":"/2022-04-08-haskell-nix-march-update"}},"content":"## JS Backend\\n\\nIn March the team focused on porting more GHCJS code to GHC head.\\n\\n* Most of us are new to GHCJS\u2019s codebase so we are taking some time to better understand it and to better document it as code gets integrated into GHC head.\\n* Development process: initially we had planned to integrate features one after the others into GHC head. However it was finally decided that features would be merged into a [wip/javascript-backend](https://gitlab.haskell.org/ghc/ghc/-/commits/wip/javascript-backend) branch first and then later merged into GHC head. After trying this approach we decided to work directly into another branch: [wip/js-staging](https://gitlab.haskell.org/ghc/ghc/-/commits/wip/js-staging) . Opening merge requests that can\u2019t be tested against a branch that isn\u2019t GHC head didn\u2019t bring any benefit and slowed us too much.\\n* Documentation: we wrote a document comparing the different approaches to target JavaScript/WebAssembly [ https://gitlab.haskell.org/ghc/ghc/-/wikis/javascript](https://gitlab.haskell.org/ghc/ghc/-/wikis/javascript)\\n* RTS: some parts of GHCJS\u2019s RTS are generated from Haskell code, similarly to code generated with the genapply program in the C RTS. This code has been ported to GHC head. As JS linking---especially linking with the RTS---will only be performed by GHC in the short term, we plan to make it generate this code dynamically at link time.\\n* Linker: most of GHCJS\u2019s linker code has been adapted to GHC head. Because of the lack of modularity of GHC, a lot of GHC code was duplicated into GHCJS and slightly modified. Now that both codes have diverged we need to spend some time making them converge again, probably by making the Linker code in GHC more modular.\\n* Adaptation to GHC head: some work is underway to replace GHCJS\u2019s Objectable type-class with GHC\u2019s Binary type-class which serves the same purpose. Similarly a lot of uses of Text have been replaced with GHC\u2019s ShortText or FastString.\\n* Template Haskell: GHCJS has its own TH runner which inspired GHC\u2019s external interpreter (\u201cIserv\u201d) programs. We have been exploring options to port TH runner code as an Iserv implementation. The Iserv protocol uses GADTs to represent its messages which requires more boilerplate code to convert them into JS because we can\u2019t automatically derive aeson instances for them.\\n* Plugins: we have an MR adding support for \u201cexternal static plugins\u201d to GHC [!7377](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7377). Currently it only supports configuring plugins *via* environment variables. We have been working on adding support for command-line flags instead.\\n* Testsuite: we have fixed GHC\u2019s build system so that it can run GHC\u2019s testsuite when GHC is built as a cross-compiler ([!7850](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7850)). There is still some work to do (tracked in [#21292](https://gitlab.haskell.org/ghc/ghc/-/issues/21292)) to somehow support tests that *run* compiled programs: with cross-compilers, target programs can\u2019t be directly executed by the host architecture.\\n\\n## Misc\\n\\n* [Performance book](https://github.com/haskellfoundation/tech-proposals/pull/26): some time was spent on the infrastructure (CI) and on switching the format of the book to ReStructured Text\\n* Modularity: some time was spent discussing GHC\u2019s design and refactoring (c.f. [!7442](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7442) and [#20927](https://gitlab.haskell.org/ghc/ghc/-/issues/20927))."},{"id":"2022-04-08-haskell-nix-march-update","metadata":{"permalink":"/2022-04-08-haskell-nix-march-update","source":"@site/blog/2022-04-08-haskell-nix-march-update-XOLP1OBCuw-import.md","title":"haskell.nix March Update","description":"Changes","date":"2022-04-08T00:00:00.000Z","formattedDate":"April 8, 2022","tags":[{"label":"nix","permalink":"/tags/nix"}],"readingTime":1.99,"truncated":false,"authors":[],"frontMatter":{"slug":"2022-04-08-haskell-nix-march-update","title":"haskell.nix March Update","authors":[],"tags":["nix"],"custom_edit_url":null},"prevItem":{"title":"GHC March 2022 Update","permalink":"/2022-04-19-ghc-march-2022-update"},"nextItem":{"title":"GHC February 2022 Update","permalink":"/2022-03-09-ghc-february-2022-update"}},"content":"## Changes\\n\\n* To cross compile Haskell code for windows a `wine` process must be used to evaluate Template Haskell code at compile time.  Some times this code needs DLLs to be present for the Template Haskell code to run.  We had been maintaining a list of DLLs manually ([#1400](https://github.com/input-output-hk/haskell.nix/pull/1400) for instance added `secp256k1`).  A more general solution ([#1405](https://github.com/input-output-hk/haskell.nix/pull/1405)) was found that uses the `pkgsHostTarget` environment variable to obtain a list of all the packages dependencies.  Then the DLLs from the are made available to the `wine` process running the Template Haskell code.  This should make more libraries build correctly while reducing unnecessary dependencies.\\n* The way Haskell.nix cleans source trees has changed with [#1403](https://github.com/input-output-hk/haskell.nix/pull/1403), [#1409](https://github.com/input-output-hk/haskell.nix/pull/1409) and [#1418](https://github.com/input-output-hk/haskell.nix/pull/1418).  When using Nix `>=2.4` source in the store is now filtered in the same way it is locally.  This has a couple of key advantages:\\n  * It makes it less likely that results on CI systems (where the source is likely to be in the store) will differ from results for local builds (where the source is in a cloned git repository).\\n  * Potential for reducing load on CI.  Although more work may be needed, this kind of filtering combined with the experimental content addressing features of Nix reduce the required rebuilds.\\n* In the past rather cryptic error messages were given when an attempt was made to use an old version of GHC on a platform Haskell.nix did not support it.  In some cases Haskell.nix would even attempt to build GHC and only fail after some time.  Better error messages are now given right away when an attempt is made to use a GHC version that is not supported for a particular platform [#1411](https://github.com/input-output-hk/haskell.nix/pull/1411)\\n\\n## Version Updates\\n\\n* GHC 9.2.2 was added [#1394](https://github.com/input-output-hk/haskell.nix/pull/1394)\\n\\n## Bug fixes\\n\\n* `gitMinimal` replaces `git` to reduce the dependency tree of `cabalProject` functions [#1387](https://github.com/input-output-hk/haskell.nix/pull/1387)\\n* Less used of `allowSubstitutes=false` [#1389](https://github.com/input-output-hk/haskell.nix/pull/1389)\\n* Fixed `aarch64-linux` builds by using correct boot compiler [#1390](https://github.com/input-output-hk/haskell.nix/pull/1390)\\n* `icu-i18n` package mapping added to make `text-icu` build [#1395](https://github.com/input-output-hk/haskell.nix/pull/1395)\\n* Fixes needed for newer `nixpkgs` versions\\n  * Use list for `configureFlags` [#1396](https://github.com/input-output-hk/haskell.nix/pull/1396)\\n  * The spdx json file is in a `.json` output [#1397](https://github.com/input-output-hk/haskell.nix/pull/1397)\\n  * `gdk_pixbuf` is now `gdk-pixbuf` [#1398](https://github.com/input-output-hk/haskell.nix/pull/1398)\\n* Replaced deprecated NixOS binary cache settings in docs [#1410](https://github.com/input-output-hk/haskell.nix/pull/1410)\\n* Enable static build of `secp256k1` on musl [#1413](https://github.com/input-output-hk/haskell.nix/pull/1413)\\n\\nFinally, we\u2019d like to thank all the awesome contributors, who make\xa0`haskell.nix`\xa0a thriving open source project!\xa0:heart:"},{"id":"2022-03-09-ghc-february-2022-update","metadata":{"permalink":"/2022-03-09-ghc-february-2022-update","source":"@site/blog/2022-03-09-ghc-february-2022-update-bnE9FHoNRc-import.md","title":"GHC February 2022 Update","description":"JS backend","date":"2022-03-09T00:00:00.000Z","formattedDate":"March 9, 2022","tags":[{"label":"ghc","permalink":"/tags/ghc"}],"readingTime":1.87,"truncated":false,"authors":[{"name":"Sylvain Henry","title":"Haskell DevX Engineer @ IOG","email":"sylvain.henry@iohk.io","key":"sylvain"}],"frontMatter":{"slug":"2022-03-09-ghc-february-2022-update","title":"GHC February 2022 Update","authors":["sylvain"],"tags":["ghc"],"custom_edit_url":null},"prevItem":{"title":"haskell.nix March Update","permalink":"/2022-04-08-haskell-nix-march-update"},"nextItem":{"title":"2021 GHC update","permalink":"/2022-03-01-2021-ghc-update"}},"content":"## JS backend\\n\\nThis month we worked on adapting code from GHCJS to merge into GHC head. We also started discussing the implementation process publicly and especially with our colleagues at Well-Typed.\\n\\n* Ticket about adapting GHCJS\u2019 code into a proper JS backend for GHC has been opened \\\\[[#21078](https://gitlab.haskell.org/ghc/ghc/-/issues/21078)\\\\]. Feedback was very positive!\\n* There were discussions about the process and an agreement to target GHC 9.6 release \\\\[[email on ghc-devs](https://mail.haskell.org/pipermail/ghc-devs/2022-February/020580.html), [wiki page](https://gitlab.haskell.org/ghc/ghc/-/wikis/javascript-backend)\\\\]\\n* `deriveConstants` is a program used to generate some header file included in the rts package. While it is mainly useful for native targets, we had to make it support Javascript targets \\\\[[!7585](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7585)\\\\]\\n* Javascript is going to be the first official target platform supported by GHC that has its own notion of managed heap objects. Hence we may need a new `RuntimeRep` to represent these values for Haskell codes interacting with JS codes via FFI. We opened [!7577](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7577) into which we tried to make this new `RuntimeRep` non JS specific so that it could be reused for future backends targeting other managed platforms (e.g. CLR, JVM). It triggered a lot of discussions summarized in [#21142](https://gitlab.haskell.org/ghc/ghc/-/issues/21142).\\n* GHCJS\u2019s code generator was ported to GHC head \\\\[[!7573](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7573)\\\\]. In its current state, we can generate Javascript unoptimised code -- the optimiser hasn\u2019t been ported yet -- by compiling a module with `-c -fjavascript`. It required many changes, not only to adapt to changes between GHC 8.10 and GHC head but also to avoid adding new package dependencies. It was also an opportunity to refactor and to document the code, which is still a work in progress.\\n* GHC doesn\u2019t use any lens library, hence to port the code generator we had to replace lenses with usual record accessors. It turned out that `case` alternatives in STG lacked them because they were represented with a triple. We took the opportunity to introduce a proper record type for them  [!7652](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7652)\\n\\n## Plutus-apps JS demo\\n\\n* We improved the proof of concept JavaScript library for generating Plutus transactions with a given set of constraints and lookups, exposing functionality from the `plutus-ledger-constraints` package. \\\\[[Report](https://github.com/hamishmack/plutus-apps/blob/1f331225853f502807aab370f82ec975bdec38ee/plutus-pab/mktx/README.md)\\\\]\\n\\n## Reporting\\n\\n* we wrote a blog post about the work we have done in 2021 as it wasn\u2019t covered anywhere else: <https://engineering.iog.io/2022-03-01-2021-ghc-update>"},{"id":"2022-03-01-2021-ghc-update","metadata":{"permalink":"/2022-03-01-2021-ghc-update","source":"@site/blog/2022-03-01-2021-ghc-update-g8gkJay36G-import.md","title":"2021 GHC update","description":"IOG is committed to improving Haskell developer experience, both by sponsoring the Haskell Foundation and by directly founding a team committed to this task: the Haskell DX team.","date":"2022-03-01T00:00:00.000Z","formattedDate":"March 1, 2022","tags":[{"label":"ghc","permalink":"/tags/ghc"}],"readingTime":8.415,"truncated":false,"authors":[{"name":"Sylvain Henry","title":"Haskell DevX Engineer @ IOG","email":"sylvain.henry@iohk.io","key":"sylvain"}],"frontMatter":{"slug":"2022-03-01-2021-ghc-update","title":"2021 GHC update","authors":["sylvain"],"tags":["ghc"],"custom_edit_url":null},"prevItem":{"title":"GHC February 2022 Update","permalink":"/2022-03-09-ghc-february-2022-update"},"nextItem":{"title":"haskell.nix February Update","permalink":"/2022-03-01-haskell-nix-february-update"}},"content":"IOG is committed to improving Haskell developer experience, both by [sponsoring the Haskell Foundation](https://iohk.io/en/blog/posts/2020/11/04/iohk-sponsors-new-haskell-foundation) and by directly founding a team committed to this task: the Haskell DX team.\\n\\nThe team now tries to provide regular (monthly) updates about its work. This post is a bit longer because it covers all of 2021 which has not been covered anywhere else.\\n\\n## Code generation\\n\\n* Added a new backend for AArch64 architectures, especially to support Apple\u2019s M1. Previously AArch64 was only supported via the LLVM based backend which is much slower. \\\\[[!5884](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5884)\\\\]\\n* Added support for Apple\u2019s M1 calling convention. In GHC 9.2.1 it implied making lifted sized types (e.g. `Word8`, `Int16`...) use their unlifted counterparts (e.g. `Word8#`, `Int16#`...); in GHC 8.10.7 \u2013 a minor release \u2013\xa0 a less invasive but more fragile solution was implemented \\\\[[commit](https://gitlab.haskell.org/ghc/ghc/-/commit/c49250d88915db6acf88d2574db827cc2c4fa080)\\\\].\\n* Fixed a very old GHC issue \\\\[[#1257](https://gitlab.haskell.org/ghc/ghc/-/issues/1257)\\\\] by making GHCi support unboxed values \\\\[[!4412](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/4412)\\\\]: ByteCode is now generated from STG instead of directly from Core. It allows more Haskell codes to be supported by HLS and it even allows GHC code to be loaded into GHCi \\\\[[link](https://mail.haskell.org/pipermail/ghc-devs/2021-October/020345.html)\\\\].\\n* Fixed a bug in the Cmm sinking pass that led to register corruption at runtime with the C backend. Even if we don\u2019t use the C backend, fixing this avoided spurious errors in CI jobs using it \\\\[[#19237](https://gitlab.haskell.org/ghc/ghc/-/issues/19237),[!5755](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5755/)\\\\]\\n* Fixed a register clobbering issue for 64-bit comparisons generated with the 32-bit x86 NCG backend \\\\[[commit](https://gitlab.haskell.org/ghc/ghc/-/commit/ecd6d14215eb40ac441c075e432ddaa0237f3c72)\\\\].\\n* Fixed generation of switches on sized literals in StgToCmm \\\\[[!6211](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6211)\\\\]\\n* Fixed LLVM shifts \\\\[[#19215](https://gitlab.haskell.org/ghc/ghc/-/issues/19215),[!4822](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/4822)\\\\]\\n\\n## Linker\\n\\n* Fixed an off-by-one error in the MachO (Darwin) linker \\\\[[!6041](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6041/)\\\\]. The fix is simple but the debugging session was epic!\\n* Fix to avoid linking plugin units unconditionally with target code, which is wrong in general but even more so when GHC is used as a cross-compiler: plugins and target code aren\u2019t for the same platform \\\\[[#20218](https://gitlab.haskell.org/ghc/ghc/-/issues/20218),[!6496](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6496)\\\\]\\n\\n## Cross-compilation\\n\\n* With John Ericson (Obsidian Systems) we finally made GHC independent of its target \\\\[[!6791](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6791),[!6539](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6539)\\\\]. It means that there is no need to rebuild GHC to make it target another platform, so it now becomes possible to add support for a `--target=...` command-line flag \\\\[[#11470](https://gitlab.haskell.org/ghc/ghc/-/issues/11470)\\\\]. It also means that a cross-compiling GHC could build plugins for its host platform in addition to building code for its target platform.\\n* A side-effect of the previous bullet is that primops\u2019 types are now platform independent. Previously some of them would use Word64 on 32-bit architectures and Word on 64-bit architectures: now Word64 is used on every platform. A side-effect of this side-effect is that we had to make Word64 as efficient as Word: it now benefits from the same optimizations (constant folding [#19024](https://gitlab.haskell.org/ghc/ghc/-/issues/19024), etc.). On 32-bit platforms, it reduced allocations by a fair amount in some cases: e.g. -25.8% in T9203 test and -11.5% when running haddock on base library \\\\[[!6167](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6167)\\\\]. We hope it will benefit other 32-bit architectures such as JavaScript or WebAssembly.\\n* GHC built as a cross-compiler doesn\u2019t support compiler plugins \\\\[[#14335](https://gitlab.haskell.org/ghc/ghc/-/issues/14335)\\\\]. We have been working on refactoring GHC to make it support two separate environments in a given compiler session \u2013 one for target code and another for the plugin/compiler code. The implementation in \\\\[[!6748](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6748)\\\\] conflicts quite a lot with the support of multiple home-units that was added at about the same time. GHC needs to be refactored a lot more to correctly support this approach, so instead we implemented a different approach to load plugins which is more low-level and bypasses the issue \\\\[[#20964](https://gitlab.haskell.org/ghc/ghc/-/issues/20964), [!7377](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7377)\\\\].\\n* We made GHC consider the target platform instead of the host platform in guessOutputFile \\\\[[!6116](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6116)\\\\]\\n* Use target platform instead of host platform to detect literal overflows \\\\[[#17336](https://gitlab.haskell.org/ghc/ghc/-/issues/17336),[!4986](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/4986)\\\\]\\n\\n## GHCJS\\n\\n* We updated GHCJS to use GHC 8.10.7 \\\\[[branch](https://github.com/ghcjs/ghcjs/tree/ghc-8.10)\\\\]\\n* We worked on making GHCJS\u2019s codebase more suitable for integration into GHC: reducing the number of dependencies, avoiding the use of Template Haskell, reusing GHC\u2019s build system, etc. There is now a GHCJS integrated into a GHC 8.10.7 fork \\\\[[branch](https://github.com/ghcjs/ghc/tree/ghc-8.10-ghcjs)\\\\].\\n* This experience led us to plan the realization of a JS backend into GHC head based on GHCJS. More information about this topic in our next report.\\n* We worked on making GHC\u2019s testsuite pass with GHCJS, triaging tests that legitimately fail on a JS platform from tests revealing real GHCJS issues. **\\\\[LINK\\\\]**\\n\\n## Windows\\n\\n* We seemed to be the first to try to build GHC on Windows with the updated GNU autotools 2.70 and this release made a breaking change to the way auxiliary files (config.guess, config.sub) were handled, breaking GHC\u2019s build ([#19189](https://gitlab.haskell.org/ghc/ghc/-/issues/19189#note_332168)). The root cause of the issue couldn\u2019t be easily solved so we modified GHC\u2019s build system to avoid the use of these auxiliary files, bypassing the issue. Most GHC devs won\u2019t ever notice that something was broken to begin with when they will update their GNU toolchain on Windows. \\\\[[!4768](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/4768),[!4987](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/4987),[!5065](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5065/)\\\\]\\n* Fixed cross-compilation of GHC from Linux to Windows using Hadrian \\\\[[#20657](https://gitlab.haskell.org/ghc/ghc/-/issues/20657),[!6945](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6945),[!6958](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6958)\\\\]\\n\\n## Numeric\\n\\n* Fixed Natural to Float/Double conversions to align with the method used for Integer to Float/Double and added missing rewrite rules \\\\[[!6004](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6004/)\\\\]\\n* Made most bignum literals be desugared into their final form in HsToCore stage instead of CoreToStg stage to ensure that Core optimizations were applied correctly to them \\\\[[#20245](https://gitlab.haskell.org/ghc/ghc/-/issues/20245),[!6376](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6376)\\\\]\\n* Some constant folding rules were missing and were added:\\n  * bitwise `and` primops when applied to a full mask (e.g. 0xFF for a 8-bit word). \\\\[[#20448](https://gitlab.haskell.org/ghc/ghc/-/issues/20448),[!6629](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6629)\\\\]\\n  * `negate` primops [#20347](https://gitlab.haskell.org/ghc/ghc/-/issues/20347),[!6535](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6535)\\n  * `timesInt2#` primop [#20374](https://gitlab.haskell.org/ghc/ghc/-/issues/20374),[!6531](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6531)\\n  * `ctz#/clz#/popCnt#` [#20376](https://gitlab.haskell.org/ghc/ghc/-/issues/20376),[!6532](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6532)\\n  * missing rewrite rule to make the implementation of `nat2Word#` efficient \\\\[[#15547](https://gitlab.haskell.org/ghc/ghc/-/issues/15547),[!6847](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6847)\\\\]\\n  * rules for `Natural` \\\\[[#15821](https://gitlab.haskell.org/ghc/ghc/-/issues/15821),[!4837](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/4837)\\\\]\\n* Allowed some ghc-bignum operations to inline to get better performance, while still managing to keep constant-folding working \\\\[[#19641](https://gitlab.haskell.org/ghc/ghc/-/issues/19641),[!6677](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6677),[!6696](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6696),[!6306](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6306)\\\\]. There is some work left to do (cf [#20361](https://gitlab.haskell.org/ghc/ghc/-/issues/20361)) but it is blocked by [#19313](https://gitlab.haskell.org/ghc/ghc/-/issues/19313) which in turn is blocked by [#20554](https://gitlab.haskell.org/ghc/ghc/-/issues/20554) which should be fixed soon ([!6865](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6865), thanks Joachim!).\\n* The ubiquitous `fromIntegral` function used to have many associated rewrite rules to make it fast (avoiding heap allocation of a passthrough Integer when possible) that were difficult to manage due to the combinatorial number of needed rules ([#19907](https://gitlab.haskell.org/ghc/ghc/-/issues/19907), [#20062](https://gitlab.haskell.org/ghc/ghc/-/issues/20062)). We found a way to remove all these rules ([!5862](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5862)).\\n\\n## Technical debt & modularity\\n\\n* Made several component of the compiler independent of `DynFlags` (parsed command-line flags):\\n  * TmpFS (dealing with temporary files) \\\\[[!6186](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6186)\\\\]\\n  * Diagnostic options \\\\[[!6043](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6043)\\\\]\\n  * Tracing functions \\\\[[!5970](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5970)\\\\]\\n  * Logger \\\\[[!4757](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/4757)\\\\]\\n  * Logger & Parser \\\\[[!5845](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5845)\\\\]\\n  * Hooks \\\\[[!4812](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/4812)\\\\]\\n* Made the handling of \u201cpackage imports\u201d less fragile \\\\[[!6586](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6586)\\\\] and refactored some code related to dependencies and recompilation avoidance \\\\[[!6528](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6528),[!6346](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6346)\\\\].\\n* Abstracted plugin related fields from HscEnv \\\\[[!7175](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7175)\\\\]\\n* Made a home-unit optional in several places \\\\[[!7013](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7013/)\\\\]: the home-unit should only be required when compiling code, not when loading code (e.g. when loading plugins in cross-compilers [#14335](https://gitlab.haskell.org/ghc/ghc/-/issues/14335)).\\n* Made GHC no longer expose the (wrong) selected ghc-bignum backend with `ghc --info`. ghc-bignum now exposes a backendName function for this purpose \\\\[[#20495](https://gitlab.haskell.org/ghc/ghc/-/issues/20495),[!6903](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6903)\\\\]\\n* Moved `tmpDir` from Settings to `DynFlags` \\\\[[!6297](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6297/)\\\\]\\n* Removed use of `unsafePerfomIO` in `getProgName` \\\\[[!6137](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6137/)\\\\]\\n* Refactored warning flags handling \\\\[[!5815](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5815)\\\\]\\n* Made assertions use normal functions instead of CPP \\\\[[!5693](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5693)\\\\]\\n* Made the interpreter more independent of the driver \\\\[[!5627](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5627)\\\\]\\n* Replaced `ptext . sLit` with `text` \\\\[[!5625](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5625)\\\\]\\n* Removed broken \u201cdynamic-by-default\u201d setting \\\\[[#16782](https://gitlab.haskell.org/ghc/ghc/-/issues/16782),[!5467](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5467)\\\\]\\n* Abstracted some components from the compiler session state (`HscEnv`):\\n  * unit-related fields into a new `UnitEnv`datatype \\\\[[!5425](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5425)\\\\]\\n  * `FinderCache` and `NameCache`\\\\[[!4951](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/4951)\\\\]\\n  * Loader state \\\\[[!5287](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5287)\\\\]\\n* Removed the need for a home unit-id to initialize an external package state (EPS) \\\\[[!5043](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5043)\\\\]\\n* Refactored `-dynamic-too` handling \\\\[[#19264](https://gitlab.haskell.org/ghc/ghc/-/issues/19264),[!4905](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/4905)\\\\]\\n\\n## Performance\\n\\n* Made `divInt#, modInt# and divModInt#` branchless and inlineable \\\\[[#18067](https://gitlab.haskell.org/ghc/ghc/-/issues/18067),[#19636](https://gitlab.haskell.org/ghc/ghc/-/issues/19636),[!3229](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/3229)\\\\]\\n* Fixed Integral instances for Word8/16/32 and `showWord` to use `quotRemWordN` \\\\[[!5891](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5891),[!5846](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5846/)\\\\]\\n* Improved performance of occurrence analysis \\\\[[#19989](https://gitlab.haskell.org/ghc/ghc/-/issues/19989),[!5977](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5977)\\\\]\\n* Fixed unnecessary pinned allocations in `appendFS` \\\\[[!5989](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5989/)\\\\]\\n* Added a rewrite rules for string literals:\\n  * Concatenation of string literals \\\\[[#20174](https://gitlab.haskell.org/ghc/ghc/-/issues/20174),[#16373](https://gitlab.haskell.org/ghc/ghc/-/issues/16373),[!6259](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6259)\\\\]\\n  * `(++) . unpackCString# \u21d2 unpackAppendCString#` leading to a 15% reduction in compilation time on a specific example. \\\\[[!6619](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6619)\\\\]\\n  * Compute SDoc literal size at compilation time \\\\[[#19266](https://gitlab.haskell.org/ghc/ghc/-/issues/19266), [!4901](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/4901)\\\\]\\n* Fix for Dwarf strings generated by the NCG that were unnecessarily retained in the FastString table \\\\[[!6621](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6621)\\\\]\\n* Worked on improving inlining heuristics by taking into account applied constructors at call sites \\\\[[#20516](https://gitlab.haskell.org/ghc/ghc/-/issues/20516),[!6732](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6732)\\\\]. More work is needed though.\\n* Fixed [#20857](https://gitlab.haskell.org/ghc/ghc/-/issues/20857) by making the Id cache for primops used more often \\\\[[!7241](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7241)\\\\]\\n* Replaced some avoidable uses of `replicateM . length` with more efficient code \\\\[[!7198](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7198)\\\\]. No performance gain this time but the next reader of this code won\u2019t have to wonder if fixing it could improve performance.\\n* Made `exprIsCheapX` inline for modest but easy perf improvements \\\\[[!7183](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7183)\\\\]\\n* Removed an allocation in the code used to write text on a Handle (used by putStrLn, etc.) \\\\[[!7160](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7160)\\\\]\\n* Replaced inefficient list operations with more efficient `Monoid ([a],[b])` operations in the driver \\\\[[!7069](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7069)\\\\], leading to 1.9% reduction in compiler allocations in MultiLayerModules test.\\n* Disabled some callstack allocations in non-debug builds \\\\[[!6252](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6252/)\\\\]\\n* Made file copy in GHC more efficient \\\\[[!5801](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5801)\\\\]\\n* Miscellaneous pretty-printer enhancements \\\\[[!5226](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5226)\\\\]\\n* Type tidying perf improvements with strictness \\\\[[#14738](https://gitlab.haskell.org/ghc/ghc/-/issues/14738),[!4892](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/4892)\\\\]\\n\\n## RTS\\n\\n* Fixed issues related to the RTS\u2019s ticker\\n  * Fixed some races \\\\[[#18033](https://gitlab.haskell.org/ghc/ghc/-/issues/18033),[#20132](https://gitlab.haskell.org/ghc/ghc/-/issues/20132),[!6201](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6201)\\\\]\\n  * Made the RTS open the file descriptor for its timer (`timerfd`) on Linux synchronously to avoid weird interactions with Haskell code manipulating file descriptors \\\\[[#20618](https://gitlab.haskell.org/ghc/ghc/-/issues/20618),[!6902](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6902)\\\\].\\n* Moved GHC\u2019s global variables used to manage Uniques into the RTS to fix plugin issues \\\\[[#19940](https://gitlab.haskell.org/ghc/ghc/-/issues/19940),[!5900](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5900)\\\\]\\n\\n## Build system / CI\\n\\n* Fixed Hadrian output to display warnings and errors after the multi screen long command lines \\\\[[#20490](https://gitlab.haskell.org/ghc/ghc/-/issues/20490),[!6690](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6690)\\\\]\\n* Avoided the installation of a global `platformConstants` file; made GHC load constants from the RTS unit instead, allowing it to be reinstalled with different constants \\\\[[!5427](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5427)\\\\]\\n* Made `deriveConstants` output its file atomically \\\\[[#19684](https://gitlab.haskell.org/ghc/ghc/-/issues/19684),[!5520](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5520)\\\\]\\n* Made compression with `xz` faster on CI \\\\[[!5066](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5066)\\\\]\\n* Don\u2019t build extra object with `-no-hs-main` \\\\[[#18938](https://gitlab.haskell.org/ghc/ghc/-/issues/18938),[!4974](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/4974)\\\\]\\n* Add `hi-boot` dependencies with `ghc -M` \\\\[[#14482](https://gitlab.haskell.org/ghc/ghc/-/issues/14482),[!4876](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/4876)\\\\]\\n\\n## Misc\\n\\n* Stack: fixed interface reading in `hi-file-parser` to support GHC 8.10 and 9.0 \\\\[[PR](https://github.com/commercialhaskell/hi-file-parser/pull/2), [Stack#5134](https://github.com/commercialhaskell/stack/issues/5134)\\\\]\\n* Enhanced pretty-printing of coercions in Core dumps \\\\[[!4856](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/4856)\\\\]"},{"id":"2022-03-01-haskell-nix-february-update","metadata":{"permalink":"/2022-03-01-haskell-nix-february-update","source":"@site/blog/2022-03-01-haskell-nix-february-update-wDy26Ro4GN-import.md","title":"haskell.nix February Update","description":"Documentation","date":"2022-03-01T00:00:00.000Z","formattedDate":"March 1, 2022","tags":[{"label":"nix","permalink":"/tags/nix"}],"readingTime":1.275,"truncated":false,"authors":[],"frontMatter":{"slug":"2022-03-01-haskell-nix-february-update","title":"haskell.nix February Update","authors":[],"tags":["nix"],"custom_edit_url":null},"prevItem":{"title":"2021 GHC update","permalink":"/2022-03-01-2021-ghc-update"},"nextItem":{"title":"GHC January 2022 update","permalink":"/2022-02-01-ghc-january-2022-update"}},"content":"## Documentation\\n\\n* A tutorial has been added on [building DWARF-enabled executables](https://outline.zw3rk.com/share/d461004d-1f2f-4d7a-95f2-4e20acb18cac) on linux systems.  There was also a related fix for building DWARF executables in a nix shell ([#1385](https://github.com/input-output-hk/haskell.nix/pull/1385))\\n\\n## Changes\\n\\n* Support for external Hackage repositories was improved by [#1370](https://github.com/input-output-hk/haskell.nix/pull/1370). We can now use an extra package repository just by adding a `repository` block to the `cabal.project` file.  This makes it easy to make use of an extra hackage databases such as [hackage.head](https://ghc.gitlab.haskell.org/head.hackage/) and [hackage-overlay-ghcjs](https://github.com/input-output-hk/hackage-overlay-ghcjs).  A `sha256` for the repository it can be added as a comment in the `repository` block or by including it in the `sha256map` argument.\\n\\n## Version Updates\\n\\n* nix-tools was updated to use the Cabal 3.6.2 and hnix 0.16 [nix-tools#113](https://github.com/input-output-hk/nix-tools/pull/113)\\n* Nixpkgs pins were bumped [#1371](https://github.com/input-output-hk/haskell.nix/pull/1371)\\n* Update booting on aarch64 linux to ghc 8.8.4 [1325](https://github.com/input-output-hk/haskell.nix/pull/1325) and [1374](https://github.com/input-output-hk/haskell.nix/pull/1374)\\n\\n## Bug fixes\\n\\n* Allow linking pcre statically with musl [#1363](https://github.com/input-output-hk/haskell.nix/pull/1363)\\n* Add gpiod to system nixpkgs map [#1359](https://github.com/input-output-hk/haskell.nix/pull/1359)\\n* Add poppler-cpp to png-config Nixpkgs map [#1373](https://github.com/input-output-hk/haskell.nix/pull/1373)\\n* Use the same logic that cabal-install uses for determining the path of a packages `.tar.gz` in a repository  [nix-tools#114](https://github.com/input-output-hk/nix-tools/pull/114)\\n* Fix libnuma dependency in rts.conf [1342](https://github.com/input-output-hk/haskell.nix/commit/18ebf60137dd2ff1be7363eb46f67ebfa366d1dd)\\n* Fix when \\"materialized\\" dir is deep [#1376](https://github.com/input-output-hk/haskell.nix/pull/1376)\\n* Prefer local building for `git-ls-files` [#1378](https://github.com/input-output-hk/haskell.nix/pull/1378) and [#1381](https://github.com/input-output-hk/haskell.nix/issues/1381)\\n* Fix stack cache generator `sha256` is a string not a lambda [#1383](https://github.com/input-output-hk/haskell.nix/pull/1383)\\n* Only pass `--index-state` to `cabal` when asked [#1384](https://github.com/input-output-hk/haskell.nix/pull/1384)\\n* Pass `enableDWARF` to `makeConfigFiles` to fix `-g3` support in `nix-shell` [#1385](https://github.com/input-output-hk/haskell.nix/pull/1385)\\n\\nFinally, we\u2019d like to thank all the awesome contributors, who make\xa0`haskell.nix`\xa0a thriving open source project!\xa0:heart:"},{"id":"2022-02-01-ghc-january-2022-update","metadata":{"permalink":"/2022-02-01-ghc-january-2022-update","source":"@site/blog/2022-02-01-ghc-january-2022-update-jTlkXUxJSn-import.md","title":"GHC January 2022 update","description":"Hopefully 2022 should be the year GHC will get a JavaScript backend without relying on GHCJS. This month the team has been busy planning the work that needs to be done to get there!","date":"2022-02-01T00:00:00.000Z","formattedDate":"February 1, 2022","tags":[{"label":"ghc","permalink":"/tags/ghc"}],"readingTime":0.9,"truncated":false,"authors":[{"name":"Sylvain Henry","title":"Haskell DevX Engineer @ IOG","email":"sylvain.henry@iohk.io","key":"sylvain"}],"frontMatter":{"slug":"2022-02-01-ghc-january-2022-update","title":"GHC January 2022 update","authors":["sylvain"],"tags":["ghc"],"custom_edit_url":null},"prevItem":{"title":"haskell.nix February Update","permalink":"/2022-03-01-haskell-nix-february-update"},"nextItem":{"title":"haskell.nix January Update","permalink":"/2022-02-01-haskell-nix-january-update"}},"content":"Hopefully 2022 should be the year GHC will get a JavaScript backend without relying on GHCJS. This month the team has been busy planning the work that needs to be done to get there!\\n\\n## Cross-compilation\\n\\n* GHCJS has been [updated](https://github.com/ghcjs/ghc/tree/ghc-8.10-ghcjs) to reduce the gap with GHC 8.10.7 codebase to the point that GHC\u2019s build system is used to build GHCJS\\n* Internal work planning for the integration of GHCJS into GHC\\n* A different approach to load plugins into cross-compilers has been implemented \\\\[[#20964](https://gitlab.haskell.org/ghc/ghc/-/issues/20964), [!7377](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7377)\\\\]\\n* GHCJS has been exercised to showcase compilation of some Plutus applications\\n\\n## Modularity\\n\\n* A few \u201csubsystems\u201d of GHC have been made more modular and reusable by making them independent of the command-line flags (`DynFlags`) \\\\[[#17957](https://gitlab.haskell.org/ghc/ghc/-/issues/17957), [!7158](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7158), [!7199](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7199), [!7325](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7325)\\\\]. This work resulted in a 10% reduction in call sites to `DynFlags` and has now removed all references to `DynFlags` up to the `CoreToStg` pass, which is almost the entire backend of GHC.\\n\\n## Performance\\n\\n* Jeffrey wrote a new HF [proposal](https://github.com/haskellfoundation/tech-proposals/pull/26) about writing a Haskell Optimization handbook and has started working on it"},{"id":"2022-02-01-haskell-nix-january-update","metadata":{"permalink":"/2022-02-01-haskell-nix-january-update","source":"@site/blog/2022-02-01-haskell-nix-january-update-vNau7aVn4Q-import.md","title":"haskell.nix January Update","description":"January 2022","date":"2022-02-01T00:00:00.000Z","formattedDate":"February 1, 2022","tags":[{"label":"nix","permalink":"/tags/nix"}],"readingTime":1.215,"truncated":false,"authors":[],"frontMatter":{"slug":"2022-02-01-haskell-nix-january-update","title":"haskell.nix January Update","authors":[],"tags":["nix"],"custom_edit_url":null},"prevItem":{"title":"GHC January 2022 update","permalink":"/2022-02-01-ghc-january-2022-update"}},"content":"## **January 2022**\\n\\nThis month we merged some very significant improvements to the support for compiling for Android and iOS based AArch64 devices.\xa0 When the build system is also AArch64 template haskell can often be run locally.\xa0 This will make targeting mobile devices from AArch64 builders much easier.\\n\\nA long running branch containing bug fixes for cross compilation to JavaScript with GHCJS was merged.\xa0 One nice feature included is better support for adding bindings to C code compiled with emscripten.\xa0 In some cases it can be as easy as adding a single JavaScript file to the package with wrappers for the C functions.\\n\\n#### Changes\\n\\n* Much improved AArch64 support including Template Haskell (#1316)\\n* Improved GHCJS and support for calling C code compiled with emscripten (#1311)\\n* The environment variables LANG and LOCALE_ARCHIVE are no longer set in shells allowing the users prefered settings to persist (#1341).\\n* source-repo-override argument added for cabal projects to allow the location of source-repository-package packages to be replaced (#1354)\\n\\n#### Version Updates\\n\\n* GHC 9.0.2 was added to the available GHC versions (#1338)\\n* The nixpkgs pins for 21.05, 21.11 and unstable were all updated (#1334).\\n* Remaining uses of cabal 3.4 were updated to 3.6.2 (#1328)\\n\\n#### Bug fixes\\n\\n* Dwarf build of ghc 9.2.1 now skipped on hydra to work around 4GB hydra limit (#1333)\\n* Removed use of propagatedBuildInputs in ghc derivation (#1318).\\n* Caching of the check-hydra CI script was fixed (#1340)"}]}')}}]);