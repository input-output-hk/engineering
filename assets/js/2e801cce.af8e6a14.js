"use strict";(self.webpackChunkengineering_iog_io=self.webpackChunkengineering_iog_io||[]).push([[9450],{6029:function(e){e.exports=JSON.parse('{"blogPosts":[{"id":"2023-01-26-ghc-update","metadata":{"permalink":"/2023-01-26-ghc-update","source":"@site/blog/2023-01-26-ghc-update-2023-01-26.md","title":"GHC DevX Update 2023-01-26","description":"This is the second biweekly update of the IOG GHC DevX team.","date":"2023-01-26T00:00:00.000Z","formattedDate":"January 26, 2023","tags":[{"label":"ghc","permalink":"/tags/ghc"},{"label":"ghc-update","permalink":"/tags/ghc-update"}],"readingTime":6.225,"truncated":false,"authors":[{"name":"Sylvain Henry","title":"Haskell DevX Engineer @ IOG","email":"sylvain.henry@iohk.io","key":"sylvain"},{"name":"Jeffrey M. Young","title":"Haskell DevX Engineer @ IOG","url":"https://iog.io/en/","key":"doyougnu"},{"name":"Luite Stegeman","title":"Haskell DevX Engineer @ IOG","email":"luite.stegeman@iohk.io","key":"luite"},{"name":"Joshua Meredith","title":"Haskell DevX Engineer @ IOG","url":"https://iog.io/en/","key":"josh"}],"frontMatter":{"slug":"2023-01-26-ghc-update","title":"GHC DevX Update 2023-01-26","authors":["sylvain","doyougnu","luite","josh"],"tags":["ghc","ghc-update"]},"nextItem":{"title":"One step forward, an easier interoperability between Rust and Haskell","permalink":"/2023-01-26-hs-bindgen-introduction"}},"content":"This is the second biweekly update of the IOG GHC DevX team.\\nYou can find the previous one [here](https://engineering.iog.io/2023-01-12-ghc-update).\\n\\n## JavaScript backend\\n\\n### Template Haskell\\n\\nSylvain continued his work on the implementation of Template Haskell for the JS\\nbackend. He factorized the code from `iserv` and `libiserv` into the `ghci`\\nlibrary. This makes it easy for GHC to load and run the external interpreter\\nserver (`iserv`) that ends up compiled into JavaScript in a NodeJS instance. He\\nmodified GHC to avoid creating ByteCode objects (which are unsupported by the JS\\nbackend) and to instead compile and link JavaScript code.\\n\\nTemplate Haskell basically works with the JavaScript backend now, except for a few\\ncorner cases (such as one-shot mode), but these should be fixed in the coming\\ndays/weeks.\\n\\nLuite modified Sylvain\'s JavaScript code to fix support for Darwin and Windows. If you\\nwant to test it, a draft merge request has been opened:\\nhttps://gitlab.haskell.org/ghc/ghc/-/merge_requests/9779\\n\\n### JavaScript backend in the browser tutorial\\n\\nJosh published a tutorial about using code produced by the JavaScript backend in a web\\npage:\\nhttps://engineering.iog.io/2023-01-24-javascript-browser-tutorial\\n\\n\\n### Cabal support for js-sources\\n\\nSylvain added tests to his patch that adds cabal support for the `js-sources`\\nstanza when GHC is used as a compiler (and not only when GHCJS is used as a\\ncompiler), allowing the patch to be merged:\\nhttps://github.com/haskell/cabal/pull/8636\\n\\nhttps://github.com/haskell/cabal/issues/8639 is still open though so be careful\\nif you try to use `js-sources`, they still don\'t work in some cases.\\n\\n\\n### JavaScript backend CI\\n\\nThe [JavaScript backend\\nCI](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/9552) has been an\\nongoing saga for the last month, and has been a blocking item for JavaScript\\nBackend development. Thankfully it is close to being merged. This week, Jeff\\nrebased the CI to discover that recent\\n[changes](https://gitlab.haskell.org/ghc/ghc/-/commit/d31fcbca6cf4bc166904cfd25696503401ad631d)\\nremoved `nodejs` (the `node` that is bundled with emscripten) from the CI\\ncontainers `$PATH`. So Jeff patched the CI images to add `node`. Now the CI runs\\nand has discovered two new bugs even before being merged. All that is left is to\\nbump some submodules and the CI will be ready to land in GHC HEAD.\\n\\n\\n### FileStat\\n\\nJosh opened an MR to match the layout of the JavaScript `fileStat` with the\\nlayout of the equivalent struct defined in Emscripten\'s `stat.h`. This is needed\\nto ensure that hsc2hs features work correctly with this data type. Hsc2hs features\\ncan peek at memory locations directly without using accessor functions, and the\\nmemory locations are taken from the header file, hence the requirement to match\\nthese layouts.\\n\\nThis MR only touches JavaScript files, so we\'re waiting on the approval of the\\nJS CI before continuing. For more information, see\\nhttps://gitlab.haskell.org/ghc/ghc/-/issues/22573\\n\\n### JavaScript RTS refactor\\n\\nJosh refactored parts of the GHC.StgtoJS.Rts.Rts module to remove special cases\\nfrom one of the n-argument JavaScript RTS functions, and combined these cases\\ninto a general case. Thus, simplifying the Rts module\'s code.\\n\\nJosh also improved the caching in the JavaScript Backend for commonly used names\\nin the generated JavaScript ASTs. Previously, names such as `x1` would require\\nallocation _for each_ use: first by allocating a `String`, which was then\\nconverted to a GHC `FastString`, which was finally wrapped in a JavaScript AST\\ndata constructor. Now, these names are captured in a static CAF\'d `Array` and\\neach reference was replaced with a lookup to the corresponding slot in the\\narray. This avoids the extra allocations and ensures these names are shared.\\n\\nFor the full set of refactors, see:\\nhttps://gitlab.haskell.org/ghc/ghc/-/issues/22822\\n\\n### JavaScript EDSL\\n\\nJeff began work on a new eDSL to replace the existing DSL the JavaScript Backend\\ninherited from GHCJS. This solves a [design\\nproblem](https://gitlab.haskell.org/ghc/ghc/-/issues/22736). The existing DSL in\\nthe JavaScript Backend is used for two things: (1) to write the JavaScript\\nBackend\'s garbage collector, runtime system and other low level bits; (2) as a\\ntarget for optimizations; (3) as the source for code generation. This becomes\\nproblematic because the existing DSL tries to do so much that it ends up not\\nbeing particularly good at (1), (2) and (3).\\n\\nThe fix is to separate concerns by writing a new DSL for (1). The DSL is Type\\nSafe and based on the [Sunroof\\ncompiler](https://github.com/ku-fpg/sunroof-compiler) (Thanks Andy Gill et al.\\nfor your labor!). Then, we\'ll compile the new DSL to the existing GHCJS DSL.\\nThis way we can slowly begin to replace JavaScript Backend code module by\\nmodule, thus gaining type safety while still continuing other work. The end game\\nof this project is to eventually remove the GHCJS DSL entirely and then compile\\nour new DSL to a better intermediate representation that is explicitly crafted\\nto make optimizations easier.\\n\\n### Blog posts\\n\\nLuite has been working on new blog posts about internals of the GHC JavaScript\\nbackend and a strategy guide for debugging the generated JavaScript code. These\\nwill be published in the coming weeks.\\n\\n### JavaScript backend configuration issue in a Docker image\\n\\nSylvain debugged a configuration issue of GHC with the JavaScript backend (see\\n[#22814](https://gitlab.haskell.org/ghc/ghc/-/issues/22814)).\\nThe recommended way to configure is to use the following command line:\\n\\n```\\nemconfigure ./configure --target=js-unknown-ghcjs\\n```\\n\\nwhere `emconfigure` is provided by the Emscripten project and sets appropriate\\nenvironment variables (CC, LD, AR...).\\n\\nHowever in some cases it seems like these variables are set as follows:\\n\\n```\\nCC=emcc\\nLD=emcc\\n...\\n```\\n\\nin which case GHC\'s `configure` script will silently ignores them... and uses\\nthe C compiler for the host platform instead (x86-64, aarch64...). As the C\\ncompiler is only used for the CPP pass, it results in some inscrutable errors.\\nIn [#22814](https://gitlab.haskell.org/ghc/ghc/-/issues/22814) the error is due\\nto `CSize` being inferred as a 64-bit type while it should be 32-bit for the\\nJavaScript platform, leading to CSize values being passed as 2 arguments in FFI\\ncalls while the callee expects 1.\\n\\nCalling `configure` with the right environment variables fixes the issue:\\n\\n```\\n./configure CC=$(which emcc) LD=$(which emcc) --target=js-unknown-ghcjs\\n```\\n\\n\\n### Discussion about JavaScript backend maturity\\n\\nQuite some time was spent discussing users\' expectations about the JavaScript and WASM backends.\\nWe would like to make it very clear that even if GHCJS has been here for a long time,\\nthe JavaScript backend doesn\'t yet have the same level of maturity.\\n\\nBugs, missing features, and sub-par performance are to be expected in the 9.6 release.\\nWe encourage adventurous users to try out this release and send us feedback, but it\'s\\nbest to exercise caution before relying on it for production.\\n\\n## Compiler performance\\n\\n### More-strict `break`\\n\\nJosh did more investigation into the performance difference that introducing\\nsome strictness into the `break` function would make. The STG and microbenchmarks\\nare very promising, but using the \\"compile cabal\\" benchmark, there doesn\'t seem\\nto be a noticable time difference caused by the change. In terms of memory, it\\nseems to reduce GC copying, but slightly increase overall allocations and total\\nmemory usage.\\n\\nThere\'s pathological cases in using a strict break by default - for example in the\\n`lines` function. Because of this, it\'s likely that this optimization would have\\nthe most benefit if applied in isolated cases in GHC, if any pathological lazy\\ncases are found.\\n\\n## Misc\\n\\n### Cross-compilation from Linux/Darwin to Windows\\n\\nTicket [#22805](https://gitlab.haskell.org/ghc/ghc/-/issues/22805) reminded Sylvain that he had made [MR !9310](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/9310) more than two months ago to fix the same issue: cross-compilation from Linux/Darwin to Windows. The MR has now been updated, tested, reviewed, and merged.\\n\\n### Hadrian rules to build the Sphinx-based docs\\n\\nSylvain started working on adding a chapter about the JavaScript in GHC\'s Users Guide.\\nThe first step was to fix Hadrian\'s build rules for the Users Guide ([MR !9795](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/9795))"},{"id":"2023-01-26-hs-bindgen-introduction","metadata":{"permalink":"/2023-01-26-hs-bindgen-introduction","source":"@site/blog/2023-01-26-hs-bindgen-introduction.md","title":"One step forward, an easier interoperability between Rust and Haskell","description":"TL;DR: This blog post intends to sum up the why and how of cargo-cabal and hs-bindgen. If you\u2019re looking for usage walkthroughs and code examples, check out project READMEs on GitHub!","date":"2023-01-26T00:00:00.000Z","formattedDate":"January 26, 2023","tags":[{"label":"cabal","permalink":"/tags/cabal"},{"label":"rust","permalink":"/tags/rust"},{"label":"bindgen","permalink":"/tags/bindgen"}],"readingTime":10.825,"truncated":false,"authors":[{"name":"Yvan Sraka","title":"Rust DevX Engineer @ IOG","email":"yvan.sraka@iohk.io","key":"yvan"}],"frontMatter":{"slug":"2023-01-26-hs-bindgen-introduction","title":"One step forward, an easier interoperability between Rust and Haskell","authors":["yvan"],"tags":["cabal","rust","bindgen"]},"prevItem":{"title":"GHC DevX Update 2023-01-26","permalink":"/2023-01-26-ghc-update"},"nextItem":{"title":"Using GHC\'s JavaScript Backend in the Browser","permalink":"/2023-01-24-javascript-browser-tutorial"}},"content":"**TL;DR:** This blog post intends to sum up the why and how of [`cargo-cabal`](https://github.com/yvan-sraka/cargo-cabal) and [`hs-bindgen`](https://github.com/yvan-sraka/hs-bindgen). If you\u2019re looking for usage walkthroughs and code examples, check out project READMEs on GitHub!\\n\\n> **N.B.** quoted paragraphs in this article give straightforward motivation regarding some systems programming basic concepts. Feel free to skip them if you know you\u2019re likely to be already comfortable with them ;)\\n\\n## Context\\n\\nAt IOG we maintain large [Haskell](https://www.haskell.org) codebases and we would like to interface them with some libraries written in [Rust](https://www.rust-lang.org).\\n\\nRust is a system programming language known for its strong static typing guarantees, which make it similar to Haskell (even if a bit less expressive). However, unlike Haskell, Rust does not have a GC (Garbage Collector) and uses a compile-time memory management strategy. This mechanism is encoded through its type system with the concepts of _\u201cownership\u201d_ and _\u201clifetime\u201d_ of values, which can complicate the writing of programs but unlock smaller runtime costs footprint. Rust is becoming increasingly popular in the systems programming and embedded systems domains, and it is also used in areas such as cryptography, where performance and correctness are critical.\\n\\nOne typical use case concerns cryptographic primitives which must be very performant. The first use case that I\xf1igo Querejeta Azurmendi (Cardano Lead Cryptography Engineer) brought me consisted in replacing a cryptographic library used by [`cardano-base`](https://github.com/input-output-hk/cardano-base). Namely, replacing [`cryptonite`](https://github.com/input-output-hk/cardano-crypto/blob/develop/cbits/cryptonite_sha512.h), a library written in Haskell and C, with [`sha3`](https://crates.io/crates/sha3), a Rust library (or \\"crate\\").\\n\\n> **Why FFI (Foreign Function Interface)?**\\n>\\n> Solving the [interoperability](https://docs.rust-embedded.org/book/interoperability/) problem means:\\n>\\n> 1. designing a protocol that allows two codes written with different languages and using different runtime systems to communicate ;\\n> 2. designing tools and methods to build, to bundle, and to distribute such polyglot code bases (what developers fear most).\\n>\\n> As our main criterion is performance, we want a solution with a minimal overhead. In particular, we want to avoid the use of any solution that relies on syscalls (like I/Os) and on costly data (de)serialization.\\n>\\n> It leads us to exclude solutions such as IPC (Inter-Process Communication), e.g., using [Google Protobuf](https://developers.google.com/protocol-buffers) over a [Unix Domain Socket](https://en.wikipedia.org/wiki/Unix_domain_socket).\\n>\\n> FFI looks like the right choice: no syscall, a foreign function call just behaves as a jump in memory and there is no extra data (de)serialization involved. The price to pay for this performance is that using the FFI requires special care to low-level calling conventions and memory management of the two involved systems. But we will come back to this topic later!\\n>\\n> **To go further:** you can learn more about how to use FFI in Rust by reading the [_The Rustonomicon_](https://doc.rust-lang.org/nomicon/ffi.html) (Unsafe Rust guide) dedicated section, or the dedicated [_Rust FFI Omnibus_](http://jakegoulding.com/rust-ffi-omnibus/) tutorial. The ANSSI (French government security agency) also writes about it in [_Secure Rust Guidelines_](https://anssi-fr.github.io/rust-guide/07_ffi.html) guide, and _Rust Embedded_ book has an [Interoperability with C](https://docs.rust-embedded.org/book/interoperability/rust-with-c.html) chapter. On the Haskell side, you way want to take a look at [GHC wiki](https://wiki.haskell.org/GHC/Using_the_FFI) or read the dedicated [_Real-World Haskell_](https://book.realworldhaskell.org/read/interfacing-with-c-the-ffi.html) chapter!\\n\\nFFI is a feature that\'s already offered by both `rustc` (Rust compiler) and `ghc` (Haskell compiler). It allows calling a Rust function from Haskell code (and vice versa). Both programming languages define an `extern` keyword that allows users to declare a function symbol that will only be resolved at [linking](https://doc.rust-lang.org/reference/linkage.html) step. N.B. mangling of the function should also be disabled, in Rust it requires decorating functions with [`#[no_mangle]`](https://doc.rust-lang.org/reference/abi.html#the-no_mangle-attribute) attribute.\\n\\nSo, what\'s lacking in Haskell ecosystem? Let\'s take a look at what kind of integration other languages offer with Rust:\\n\\n* From **C** to Rust [`rust-bindgen`](https://github.com/rust-lang/rust-bindgen) ;\\n* From Rust to **C** [`c-bindgen`](https://github.com/eqrion/cbindgen) and Rust to **ECMAScript**, [`wasm-bindgen`](https://github.com/rustwasm/wasm-bindgen) ;\\n* Both from and to Rust with **C++** [`cxx`](https://github.com/dtolnay/cxx) and **Python** [`PyO3`](https://github.com/PyO3/pyo3).\\n\\nThis list isn\'t exhaustive but give you a hint, all these projects are about generating bindings (bindgen)!\\n\\n> **Why bindgen (bindings code generation)?**\\n>\\n> Let\'s sum it up by: _\\"A good FFI is an FFI that you don\'t write \u2026\\"_\\n>\\n> FFI are like a blind spot in your type system. Writing them manually is both frankly painful and really dangerous, as your compiler will not warn you about non-matching interfaces.\\n>\\n> Binding generation comes to the rescue by considerably reducing the room for human errors. As a bonus, it also makes maintainers\' life easier thanks to a smaller and more readable code base.\\n\\n## Example\\n\\nLet\'s start with a minimal example: automatically generating bindings allowing Haskell codes to call a given Rust function. It is simply done by annotating the Rust function as follows:\\n\\n```rust\\nuse hs_bindgen::*;\\n\\n#[hs_bindgen(greetings :: CString -> IO ())]\\nfn greetings(name: &str) {\\n    println!(\\"Hello, {name}!\\");\\n}\\n```\\n\\n\u2026 it will be expanded to (you can try yourself with [`cargo expand`](https://github.com/dtolnay/cargo-expand)):\\n\\n```rust\\nuse hs_bindgen::*;\\n\\nfn greetings(name: &str) {\\n    println!(\\"Hello, {name}!\\");\\n}\\n\\n#[no_mangle] // Mangling makes symbol names more difficult to predict.\\n             // We disable it to ensure that the resulting symbol is really `__c_greetings`.\\nextern \\"C\\" fn __c_greetings(__0: *const core::ffi::c_char) -> () {\\n    // `traits` module is `hs-bindgen::hs-bindgen-traits`\\n    // n.b. do not forget to import it, e.g., with `use hs-bindgen::*`\\n    traits::ReprC::from(greetings(traits::ReprRust::from(__0),))\\n}\\n```\\n\\n\u2026 and will also generate the following Haskell code:\\n\\n```haskell\\n-- This file was generated by `hs-bindgen` crate and contains C FFI bindings\\n-- wrappers for every Rust function annotated with `#[hs_bindgen]`\\n\\n{-# LANGUAGE ForeignFunctionInterface #-}\\n\\n-- Why not rather using `{-# LANGUAGE CApiFFI #-}` language extension?\\n--\\n-- * Because it\'s GHC specific and not part of the Haskell standard:\\n--   https://ghc.gitlab.haskell.org/ghc/doc/users_guide/exts/ffi.html ;\\n--\\n-- * Because the capabilities it gave (by rather works on top of symbols of a C\\n--   header file) can\'t work in our case. Maybe we want a future with an\\n--   {-# LANGUAGE RustApiFFI #-} language extension that would enable us to\\n--   work on top of a `.rs` source file (or a `.rlib`, but this is unlikely as\\n--   this format has purposely no public specification).\\n\\n{-# OPTIONS_GHC -Wno-unused-imports #-}\\n\\nmodule Greetings (greetings) where\\n\\nimport Data.Int\\nimport Data.Word\\nimport Foreign.C.String\\nimport Foreign.C.Types\\nimport Foreign.Ptr\\n\\nforeign import ccall unsafe \\"__c_greetings\\" greetings :: CString -> IO (())\\n```\\n\\nIn Rust, [`extern`](https://doc.rust-lang.org/book/ch19-01-unsafe-rust.html#using-extern-functions-to-call-external-code) is an alias to `extern \\"C\\"` that stands for \u201cuse the C call convention\u201d rather than `extern \\"Rust\\"` that use the Rust one, which is the default implicitly used.\\n\\n> **Why C ABI (Application Binary Interface)?**\\n>\\n> First, GHC currently doesn\'t know anything about Rust calling convention, while it does about C\'s one: C\'s calling convention is the [_lingua franca_](https://en.wikipedia.org/wiki/Mediterranean_Lingua_Franca) of `rustc`/`ghc`.\\n> \\n> Additionally, the Rust [ABI](https://doc.rust-lang.org/reference/items/external-blocks.html#abi) (call-convention and types [memory layout](https://cheats.rs/#memory-layout)) isn\u2019t stable. That means that it\u2019s specified internally but could be broken by any `rustc` minor release, building a software on top of it is by definition a \u201chack\u201d \u2026 If we think it\u2019s worth it, we would have to perform our bindgen against a given `rustc` version (and that would be really laborious to maintain). So, do not fear the C ABI because, at least, it is stable!\\n>\\n> **To go further:** I invite you to read *[\u201cRust does not have a stable ABI\u201d](https://viruta.org/rust-stable-abi.html)* by Federico Mena Quintero: a blog post discussing how much the absence of Rust stable ABI isn\'t a big deal in the context of GTK development. Highlighting that *[\u201cHow Swift Achieved Dynamic Linking Where Rust Couldn\'t\u201d](https://faultlore.com/blah/swift-abi/)* by Aria Beingessner isn\'t so far from [`GObject` Introspection](https://gi.readthedocs.io/en/latest/) strategy!\\n\\n## Implementation\\n\\nThe previous code example highlighted that we rely on two constructs: an attribute procedural macro [`#[hs_bindgen]`](https://github.com/yvan-sraka/hs-bindgen), and (internally) `ReprRust` and `ReprC` traits.\\n\\n> **Why use a Rust macro?**\\n>\\n> Binding code generation could have been achieved using an external tool, e.g., `cbindgen` parses Rust code (before macro expansion) and deduces C function signatures.\\n>\\n> But instead we decided to define a custom macro (like `cxx`, `wasm-bindgen`, and `PyO3` do), and so we require the user to depend on a custom crate.\\n>\\n> The reason is that we want generated bindings to always match the source code used for their generation. By using a macro we enforce binding generation during the build process and bindings can\'t get out-of-sync.\\n>\\n> **To go further:** `cbindgen` has a major limitation in that it does not understand Rust\'s module system or namespacing. As mentioned in its [documentation](https://github.com/eqrion/cbindgen/blob/master/docs.md#writing-your-c-api), this means that if `cbindgen` sees that it needs the definition for `MyType` and there exists two things in your project with the type name `MyType`, it won\'t know what to do. Rather, using the framework implemented here for `hs-bindgen` would allow us to provide a better `c-bindgen` implementation.\\n\\n`ReprRust` and `ReprC` traits respectively ensure that the arguments and return value of exposed function respect a set of given safety rules. As a recall, Rust\'s traits are similar to Haskell\'s typeclasses: it\u2019s a way to define a contract for a type, specifying a set of methods that the type must implement. This allows for generic programming, where a function or data structure can operate on any type that implements the given set of traits.\\n\\nWrapping user types by these traits have several benefits:\\n\\n* Unsupported types are nicely reported as _\u201cthe trait `ReprRust<T>` is not implemented for `U`\u201d_ error (that suggest other types that the trait implement to the user);\\n\\n* The user can extensively always implement these traits for arbitrary types ;\\n\\n* Provided traits implementation for `std` types take care of memory management ;\\n\\n* Traits improve a lot of ergonomics by implicitly and safely casting a given type to an FFI-safe one.\\n\\n> **What\'s an FFI-safe type?**\\n>\\n> `rustc` will complain if a function prefixed by `extern` keyword use as arguments types that are not FFI-safe. FFI-safe types guarantee that a type has a [specified layout](https://doc.rust-lang.org/reference/type-layout.html) (memory representation) by e.g. having a [`#[repr(C)]`](https://doc.rust-lang.org/nomicon/other-reprs.html#reprc) compiler attribute, for the given C call convention.\\n\\n**To go further:** the memory management strategy is freeing the value is the role of the receiver (which has \u201cownership\u201d of it). This means that values returned by Rust functions aren\'t [`dropped`](https://doc.rust-lang.org/std/ops/trait.Drop.html) by Rust but rather should be [`freed`](https://hackage.haskell.org/package/base/docs/Foreign-Marshal-Alloc.html) on the Haskell side!\\n\\n**EDIT:*** Thanks to community feedbacks from Merijn Verstraaten, I just released `hs-bindgen` v0.8.0 that now generates `safe` Haskell foreign imports by default! You can still generate `unsafe` bindings simply by prefixing a function name like `#[hs_bindgen(unsafe NAME :: TYPE)]` in Rust attribute macro. I invite you to read *[\u201cFFI safety and GC\u201d](https://frasertweedale.github.io/blog-fp/posts/2022-09-23-ffi-safety-and-gc.html)* by Fraser Tweedale or GHC\'s users guide to understand the differences between Haskell `unsafe`/`safe` keywords.\\n\\n## DevX\\n\\n[`cargo-cabal`](https://github.com/yvan-sraka/cargo-cabal) is a CLI tool that helps you, in one simple command, turn a Rust crate into a Haskell Cabal library!\\n\\nI was heavily inspired by the developer experience that offers [`wasm-pack`](https://rustwasm.github.io/docs/wasm-pack/) or [`maturin`](https://github.com/PyO3/maturin): launched in any Rust project folder. These tools help the user interactively tweak their `Cargo.toml` package file and generate the build files needed by Node.js `npm` or Python `setuptools`.\\n\\nWhat `cargo-cabal` actually does is:\\n\\n* Ask the user to add `crate-type = [\\"staticlib\\"]` (or `\\"cdylib\\"`, dynamic libraries require an extra [`build.rs`](https://github.com/yvan-sraka/cargo-cabal/blob/main/src/build.rs) file that is generated by `cargo-cabal`) to their `Cargo.toml` file;\\n\\n* Generate a custom `X.cabal` linking `rustc` output as `extra-librairies`, and either a ([`naersk`](https://github.com/nix-community/naersk) and [`haskell.nix`](https://github.com/input-output-hk/haskell.nix) based) `flake.nix` or a [`Setup.lhs`](https://github.com/yvan-sraka/cargo-cabal/blob/main/src/Setup.lhs) Cabal build script (to work around this [issue](https://github.com/haskell/cabal/issues/2641)).\\n\\n**To go further:** `stack` isn\'t supported yet, but we could easily imagine a `cargo-stack` binary that just wraps a `cargo-cabal --stack` CLI option!\\n\\n## What\'s next?\\n\\n[`cargo-cabal`](https://github.com/yvan-sraka/cargo-cabal) and [`hs-bindgen`](https://github.com/yvan-sraka/hs-bindgen) combined are less than 1000 LoC, they also support Rust `#[no_std]` code, and I would be glad to keep them as [KISS](https://en.wikipedia.org/wiki/KISS_principle) and modular as possible. But there is still room for improvements, e.g., by adding trait implementations for more Rust `std` types, or possibly supporting `async` functions with [`async-ffi`](https://github.com/oxalica/async-ffi)?!\\n\\nFurthermore, It\u2019s also nice to give a sneak peek on what others do for comparison: **OCaml** [allows extensions to be written directly in Rust with no C stubs](https://docs.rs/ocaml), this work was supported from the [OCaml Software Foundation](http://ocaml-sf.org/) and you can find [a basic example project here](http://github.com/zshipko/ocaml-rust-starter). It offers [safe OCaml/Rust interoperability](https://github.com/simplestaking/ocaml-interop), meaning utilities to convert ADTs (Algebraic Data Types) and functions using them.\\n\\nIt would be delightful to get as far as having custom preludes in Haskell binding code, that offers Rust type layout in Haskell. For example, Rust [slices](https://doc.rust-lang.org/book/ch04-03-slices.html) are not an existing concept in C but could be easily represented as an FFI-safe struct.\\n\\nFinally, it\u2019s worth mentioning that there are also proposals to improve the interface between Haskell programs requiring Rust libraries, including this Cabal [RFC](https://github.com/haskell/cabal/issues/7906). As a reminder, the implementation proposed here does not provide support for Haskell dependencies in Rust project yet, but there is a previous [unmaintained attempt](https://github.com/mgattozzi/curryrs) by Michael Gattozzi to bring Haskell runtime support to Rust binaries. We should also keep a close look on the Rust RFC that offers to introduce a `#[repr(interop)]` attribute: [Experimental feature gate proposal `interoperable_abi`](https://github.com/rust-lang/rust/pull/105586).\\n\\nI would like to thank [@doyougnu](https://github.com/doyougnu), [@hsyl20](https://github.com/hsyl20), [@govanify](https://github.com/govanify), and [@iquerejeta](https://github.com/iquerejeta) for their reviews and for their helpful suggestions.\\n\\nThanks for reading, feel free to experiment with this proof of concept and to provide feedback on GitHub!"},{"id":"2023-01-24-javascript-browser-tutorial","metadata":{"permalink":"/2023-01-24-javascript-browser-tutorial","source":"@site/blog/2023-01-24-javascript-browser-tutorial.md","title":"Using GHC\'s JavaScript Backend in the Browser","description":"In a previous","date":"2023-01-24T00:00:00.000Z","formattedDate":"January 24, 2023","tags":[{"label":"ghc","permalink":"/tags/ghc"},{"label":"javascript","permalink":"/tags/javascript"},{"label":"cross-compilation","permalink":"/tags/cross-compilation"}],"readingTime":8.105,"truncated":false,"authors":[{"name":"Sylvain Henry","title":"Haskell DevX Engineer @ IOG","email":"sylvain.henry@iohk.io","key":"sylvain"},{"name":"Jeffrey M. Young","title":"Haskell DevX Engineer @ IOG","url":"https://iog.io/en/","key":"doyougnu"},{"name":"Luite Stegeman","title":"Haskell DevX Engineer @ IOG","email":"luite.stegeman@iohk.io","key":"luite"},{"name":"Joshua Meredith","title":"Haskell DevX Engineer @ IOG","url":"https://iog.io/en/","key":"josh"}],"frontMatter":{"slug":"2023-01-24-javascript-browser-tutorial","title":"Using GHC\'s JavaScript Backend in the Browser","authors":["sylvain","doyougnu","luite","josh"],"tags":["ghc","javascript","cross-compilation"]},"prevItem":{"title":"One step forward, an easier interoperability between Rust and Haskell","permalink":"/2023-01-26-hs-bindgen-introduction"},"nextItem":{"title":"GHC DevX Update 2023-01-12","permalink":"/2023-01-12-ghc-update"}},"content":"In a previous\\n[post](https://engineering.iog.io/2022-12-13-ghc-js-backend-merged) we\\nintroduced GHC\'s new JavaScript backend, which allows the compilation of Haskell\\ncode into JavaScript. This is the first tutorial in a new series about the\\nJavaScript backend. In this post, we\'ll build GHC as\\na JavaScript cross-compiler and run a trivial Haskell program in the browser.\\n\\nWe plan to write more of those blog post in the coming weeks and\\nmonths as we add new features (e.g. support for \\"foreign exports\\" that will\\nallow JavaScript code to call into Haskell code, support for Template Haskell,\\netc.). For now it relies on our \\"insider\\" knowledge (e.g. how the FFI works)\\nthat isn\'t well documented elsewhere. We do plan to add a chapter about the\\nJavaScript backend in GHC\'s user guide, but for now your best chance is to look\\nat GHCJS\'s documentation or at the source code.\\n\\nPlease note: this is a technology preview of the in-development JavaScript backend\\nfor GHC. Not all Haskell features are implemented, and bugs are expected. It is\\ncurrently rather complicated for JavaScript code to call into Haskell code (\\"foreign\\nexports\\" aren\'t implemented). GHC isn\'t a multi-target compiler yet, so a GHC executable\\nbuilt for a native platform (Linux/x86-64, Windows/x86-64, Darwin/AArch64...) as currently distributed (via ghcup, Stack, binary distributions, etc.) won\'t be able to produce JavaScript. Official prebuilt binary distributions are likely to remain\\nunavailable until GHC gains multi-target support - requiring the JavaScript backend\\nto be built from source even after the backend matures.\\nThat\'s why we start this post with the required steps to build yourself\\na GHC compiler capable of producing JavaScript.\\n\\n## Building GHC as a Cross Compiler to JavaScript\\n\\n### Installing Dependencies\\n\\nFirst we need to install all the typical dependencies for GHC plus `Emscripten`,\\nso our final list is:\\n\\n* GHC version 9.2 or later\\n* Cabal\\n* Alex\\n* Happy\\n* Emscripten to configure with\\n* (Optional) NodeJS to run JavaScript locally\\n\\n\\nLet\'s take these in order, a standard GHC distribution with Cabal is needed so we can boot our new compiler.\\nWe recommend using  GHCUP\\n([https://www.haskell.org/ghcup/install/](https://www.haskell.org/ghcup/install/)),\\nor your system\'s package manager to install the this. \\n\\nWe need Alex and Happy to build GHC, these can be installed through Cabal:\\n\\n```\\ncabal install alex happy -j\\n```\\n\\nWe need Emscripten during the `configure` step of the build. `Emscripten` should be available in most package managers, but you can also build and install it from source:\\n\\n```\\ngit clone https://github.com/emscripten-core/emsdk.git\\ncd emsdk\\n./emsdk install latest\\n./emsdk activate latest\\nsource ./emsdk_env.sh\\n```\\n\\nAfter installing Emscripten, `emconfigure` should be available on your system\\npath. Use `which emconfigure` to check that it is on your `$PATH`. If you built\\nfrom source, then the output should point to a location within the emsdk git\\nproject like so:\\n\\n```\\n$ which emconfigure\\n/path/to/emsdk/upstream/emscripten/emconfigure\\n```\\n\\nFor more detailed installation instructions, see [https://emscripten.org/docs/getting_started/downloads.html](https://emscripten.org/docs/getting_started/downloads.html). \\n\\nThat\'s all we need to build GHC as a cross compiler. NodeJS can be installed via your system\'s package manager if you want to run the JavaScript programs locally. We\'ll assume it\'s in your `$PATH` for the rest of the blog post.\\n\\n\\n### Building GHC\\n\\nWith all the dependencies installed, we can clone GHC HEAD and build the cross compiler:\\n```\\ngit clone https://gitlab.haskell.org/ghc/ghc.git --recursive\\n```\\nYou should notice quite a few submodules being cloned as well as the main repo; expect this to take a while. Once this has completed, navigate to the `ghc` directory and run the following configuration commands:\\n```\\ncd ghc\\n./boot\\nemconfigure ./configure --target=js-unknown-ghcjs\\n```\\n\\n`emconfigure ./configure --target=js-unknown-ghcjs` will finish by outputting a screen that looks like:\\n```\\n----------------------------------------------------------------------\\nConfigure completed successfully.\\n\\n   Building GHC version  : 9.5.20221219\\n          Git commit id  : 761c1f49f55afc9a9f290fafb48885c2033069ed\\n\\n   Build platform        : x86_64-unknown-linux\\n   Host platform         : x86_64-unknown-linux\\n   Target platform       : js-unknown-ghcjs\\n\\n   Bootstrapping using   : /home/josh/.ghcup/bin/ghc\\n      which is version   : 9.4.2\\n      with threaded RTS? : YES\\n\\n   Using (for bootstrapping) : gcc\\n   Using clang               : /home/josh/emsdk/upstream/emscripten/emcc\\n      which is version       : 15.0.0\\n      linker options         :\\n   Building a cross compiler : YES\\n   Unregisterised            : NO\\n   TablesNextToCode          : YES\\n   Build GMP in tree         : NO\\n   hs-cpp       : /home/josh/emsdk/upstream/emscripten/emcc\\n   hs-cpp-flags : -E -undef -traditional -Wno-invalid-pp-token -Wno-unicode -Wno-trigraphs\\n   ar           : /home/josh/emsdk/upstream/emscripten/emar\\n   ld           : /home/josh/emsdk/upstream/emscripten/emcc\\n   nm           : /home/josh/emsdk/upstream/bin/llvm-nm\\n   objdump      : /usr/bin/objdump\\n   ranlib       : /home/josh/emsdk/upstream/emscripten/emranlib\\n   otool        : otool\\n   install_name_tool : install_name_tool\\n   windres      :\\n   dllwrap      :\\n   genlib       :\\n   Happy        : /home/josh/.cabal/bin/happy (1.20.0)\\n   Alex         : /home/josh/.cabal/bin/alex (3.2.7.1)\\n   sphinx-build :\\n   xelatex      :\\n   makeinfo     :\\n   git          : /usr/bin/git\\n   cabal-install : /home/josh/.cabal/bin/cabal\\n\\n   Using LLVM tools\\n      clang : clang\\n      llc   : llc-14\\n      opt   : opt-14\\n\\n   HsColour was not found; documentation will not contain source links\\n\\n   Tools to build Sphinx HTML documentation available: NO\\n   Tools to build Sphinx PDF documentation available: NO\\n   Tools to build Sphinx INFO documentation available: NO\\n----------------------------------------------------------------------\\n```\\n\\nIf everything is correct, you\'ll see that the `Target platform` is set to\\n`js-unknown-ghcjs`, and the build tools will be set to their\\nEmscripten counterparts: `ar` becomes `emar`, `nm` becomes `llvm-nm`, etc.\\n\\nFinally, to build GHC:\\n```\\n./hadrian/build --bignum=native -j --docs=none\\n```\\n\\nExpect this to take around a half hour or longer. If all goes well you should see:\\n```\\n/--------------------------------------------------------\\\\\\n| Successfully built library \'ghc\' (Stage1, way p).      |\\n| Library: _build/stage1/compiler/build/libHSghc-9.5_p.a |\\n| Library synopsis: The GHC API.                         |\\n\\\\--------------------------------------------------------/\\n| Copy package \'ghc\'\\n# cabal-copy (for _build/stage1/lib/package.conf.d/ghc-9.5.conf)\\n| Run GhcPkg Recache Stage1: none => none\\n| Copy file: _build/stage0/bin/js-unknown-ghcjs-ghc => _build/stage1/bin/js-unknown-ghcjs-ghc\\nBuild completed in 1h00m\\n```\\n\\nTake note of `_build/stage1/bin/js-unknown-ghcjs-ghc` path. This is the GHC executable that we\'ll use to compile to JavaScript. To make life easier on ourselves we can alias it:\\n\\n```\\nalias ghc-js=`pwd`/_build/stage1/bin/js-unknown-ghcjs-ghc\\n```\\n\\n## First Haskell to JavaScript Program\\n\\nNow that we have a version of GHC that can output JavaScript, let\'s compile a Haskell program and run it with NodeJS. Make a file named \\"HelloJS.hs\\", with the following contents:\\n\\n```haskell\\n-- HelloJS.hs\\nmodule Main where\\n\\nmain :: IO ()\\nmain = putStrLn \\"Hello, JavaScript!\\"\\n```\\n\\nNow we can compile it using the alias we defined earlier:\\n```\\nghc-js HelloJS.hs\\n```\\n\\nYou should see the following output, and a `HelloJS` executable.\\n\\n```\\n[1 of 2] Compiling Main             ( HelloJS.hs, HelloJS.o )\\n[2 of 2] Linking HelloJS.jsexe\\n```\\n\\nIf you have NodeJS is on your `Path`, then this executable can be run just like any other command line program:\\n\\n```\\n./HelloJS\\nHello, JavaScript!\\n```\\n\\nNotice that a directory called `HelloJS.jsexe` was created. This directory\\ncontains all the final JavaScript code, including a file named `all.js`, and a\\nminimal `index.html` HTML file that wraps `all.js`. For now, we\'ll only care\\nabout `all.js` and return to `index.html` later. `all.js` _is_ the payload of our\\n`HelloJS` exectuable. The executable is simply a copy of `all.js`, with a call\\nto `node` added to the top. We could have equivalently run our program with:\\n\\n```\\nnode HelloJS.jsexe/all.js\\n```\\n\\n## Haskell in the Browser\\n\\nWe saw in the previous example that GHC\'s JavaScript backend allows us to write\\nHaskell and run the output JavaScript with NodeJS. This produces a portable\\nexecutable, but otherwise doesn\'t enable anything we couldn\'t do before; GHC can\\nalready compile Haskell to run on most platforms! So let\'s do something novel,\\nand run Haskell in the browser.\\n\\nIn this example, we\'ll use Haskell to draw a simple SVG circle to our browser window. Put the following code in a file named `HelloBrowser.hs`:\\n\\n```haskell\\n-- HelloBrowser.hs\\nmodule Main where\\n\\nimport Foreign.C.String\\n\\nforeign import javascript \\"((arr,offset) => document.body.innerHTML = h$decodeUtf8z(arr,offset))\\"\\n  setInnerHtml :: CString -> IO ()\\n\\ncircle :: String\\ncircle = \\"<svg width=300 height=300><circle cx=50% cy=50% r=50%></circle></svg>\\"\\n\\nmain :: IO ()\\nmain = withCString circle setInnerHtml\\n```\\n\\nNotice that we\'ve encountered a Haskell feature that\'s only available in the\\nJavaScript backend: JavaScript foreign imports. This feature allows our Haskell\\nprogram to call JavaScript functions. In our example we use this feature to call\\na JavaScript [arrow\\nfunction](https://262.ecma-international.org/13.0/#prod-ArrowFunction) that\\nupdates the `body` of the page with our HTML snippet containing a drawing of a\\ncircle. Alternatively, we could have set the foreign import to a function symbol\\nlike so:\\n\\n```\\nforeign import javascript \\"setInnerHTML\\"\\n  setInnerHtml :: CString -> IO ()\\n```\\n\\nwhere `setInnerHTML` is defined in a `.js` file that is then loaded\\nby passing the JavaScript file to GHC along with the Haskell sources.\\n\\nNext, we can compile our program to JavaScript, again with our built GHC:\\n\\n```\\nghc-js HelloBrowser.hs\\n```\\n\\nOr `ghc-js HelloBrowser.hs foo.js` if `setInnerHTML` is defined in `foo.js`.\\n\\n\\nRecall the `index.html` file inside the `HelloBrowser.jsexe` directory. This HTML\\nfile has our compiled JavaScript already included, so if you open it in your\\nbrowser, you\'ll find it loads our SVG circle in the top-left of the page!\\n\\n![Example webpage screenshot](/img/browser-screenshot.png)\\n\\n`index.html` contains the minimal HTML code required to load the generated JavaScript code. It simply loads the `all.js` file mentioned above with the following `script` tag that you can reuse in your own HTML files:\\n```html\\n<script language=\\"javascript\\" src=\\"all.js\\" defer><\/script>\\n```\\n\\nAs the JS backend still lacks support for some FFI features (foreign exports, foreign \\"wrapper\\" imports...), JavaScript codes can\'t easily interact with Haskell codes. It reduces the amount of advanced/interesting examples we can present for now. We\'ll publish new blog posts illustrating these features when they will be implemented.\\n\\n## Conclusion\\n\\nIn this post, we\'ve seen how to build a first Haskell program to run in the browser using a preview of GHC\'s in-development JavaScript backend. This program used \\"foreign imports\\" to make a JavaScript function available within the Haskell code, which allows a limited interaction between Haskell and the browser. We also saw the structure of the outputs of the JavaScript backend, in the `.jsexe` directory, and how this allows our Haskell program to be invoked by a custom HTML wrapper. This was all enabled by building a version of GHC from source, with the build process having been configured with Emscripten to produce a GHC exectuable that targets JavaScript."},{"id":"2023-01-12-ghc-update","metadata":{"permalink":"/2023-01-12-ghc-update","source":"@site/blog/2023-01-12-ghc-update-2023-01-12.md","title":"GHC DevX Update 2023-01-12","description":"Starting in 2023 we\u2013the IOG GHC DevX team\u2013are going to provide biweekly updates","date":"2023-01-12T00:00:00.000Z","formattedDate":"January 12, 2023","tags":[{"label":"ghc","permalink":"/tags/ghc"},{"label":"ghc-update","permalink":"/tags/ghc-update"}],"readingTime":2.895,"truncated":false,"authors":[{"name":"Sylvain Henry","title":"Haskell DevX Engineer @ IOG","email":"sylvain.henry@iohk.io","key":"sylvain"},{"name":"Jeffrey M. Young","title":"Haskell DevX Engineer @ IOG","url":"https://iog.io/en/","key":"doyougnu"},{"name":"Luite Stegeman","title":"Haskell DevX Engineer @ IOG","email":"luite.stegeman@iohk.io","key":"luite"},{"name":"Joshua Meredith","title":"Haskell DevX Engineer @ IOG","url":"https://iog.io/en/","key":"josh"}],"frontMatter":{"slug":"2023-01-12-ghc-update","title":"GHC DevX Update 2023-01-12","authors":["sylvain","doyougnu","luite","josh"],"tags":["ghc","ghc-update"]},"prevItem":{"title":"Using GHC\'s JavaScript Backend in the Browser","permalink":"/2023-01-24-javascript-browser-tutorial"},"nextItem":{"title":"JavaScript backend merged into GHC","permalink":"/2022-12-13-ghc-js-backend-merged"}},"content":"Starting in 2023 we\u2013the IOG GHC DevX team\u2013are going to provide biweekly updates\\nabout our work. This is the first edition.\\n\\n## JS backend\\n\\n### JS backend in the browser tutorial\\n\\nWe are working on a draft of a JS backend tutorial about using it to build a\\nsimple web application: https://github.com/input-output-hk/engineering/pull/24\\n\\nPublication is expected next week.\\n\\n### Cabal support for js-sources\\n\\nSylvain made a patch to add cabal support for the `js-sources` stanza when\\nGHC is used as a compiler (and not only when GHCJS is used as a compiler):\\nhttps://github.com/haskell/cabal/pull/8636\\n\\nIt\u2019s missing tests and then it should be ready to be merged.\\n\\n### JS backend CI\\n\\nJeff worked on adding a proper CI job that runs the full testsuite\\nwith the JS backend. Cf ticket\\n[#22128](https://gitlab.haskell.org/ghc/ghc/-/issues/22128) and merge request\\n[!9552](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/9552).\\n\\nHe had to fix some unexpected test passes (!) with the JS backend due to an\\nimprecise `req_smp` predicate used by the testsuite. More details on\\n[#22630](https://gitlab.haskell.org/ghc/ghc/-/issues/22630) and\\n[!9568](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/9568).\\n\\n### JS backend: Template Haskell\\n\\nLuite and Sylvain started implementing support for Template Haskell (TH) with\\nthe JS backend.\\n\\nSylvain reimplemented support for running an adapted version of the\\nTHRunner.js script from GHCJS. He also refactored the JS linker and\\nimplemented incremental linking.\\n\\nThe next step is to link and to run an instance of the external interpreter code\\nthat implements the Template Haskell protocol (execution of the `Q` monad)\\nadapted to run in JavaScript. GHCJS used to have its own duplicated code for\\nthis but for maintenance concerns it\u2019s much better to reuse the external\\ninterpreter code.\\n\\n## GHCi\\n\\n### GHCi: sized primitive types (Word8#, etc.)\\n\\nLuite implemented support for sized primitive types in GHCi. Cf\\n[!8822](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/8822).\\n\\n### GHCi: \u201cprim\u201d calling convention\\n\\nLuite implemented support for the \u201cprim\u201d calling convention in GHCi. Cf\\n[!9026](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/9026)\\n\\n## Compiler performance\\n\\n### Jeff\\n\\nEach of these improves allocations between 0.2 - 0.7% depending on the input\\n(improvements by a thousand cuts):\\n\\n- **GHC.Foreign improved Strictness**: An Attempt to remove lazy IO and SAT an\\n  argument that is only used for a debug message. Got a review from Andreas.\\n  Want to try to 2 more improvements then ready to merge.\\n  [!9644](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/9644)\\n\\n- **InfoTableProv: ShortText \u2192 ShortByteString**: Post review from Ben I made some\\n  improvements that preserved type safety and still recovered most of the\\n  performance improvements. Ready to merge\\n  [!9637](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/9637)\\n\\n- **GHC.Unit.State**: swapped use of Data.Map for GHC.Unique.UniqMap and expanded\\n  UniqMap API. Results in progress (need to patch Haddock) and still\\n  experimental. The idea here is to use a data structure that no longer needs to\\n  balance on insertions because Unit.State performs a lot of merges on these\\n  maps.\\n\\n- **GHC.Utils.Binary.foldGet\u2019 removed lazy IO and lazy accumulator**: merged\\n  [!9538](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/9538)\\n\\n### Josh\\n\\n- **Stricter break**: we noticed in a ticky profile that `GHC.List.break` allocates\\n  3 thunks and 1 datacon per list element returned the first part of the list.\\n  If this list is fully evaluated later, we can allocate only 1 datacon per list\\n  element instead. Preliminary results bootstrapping GHC with this change look\\n  very promising.\\n\\n- **FastMutInt (Binary)**: Josh started reviving Sylvain\u2019s MR\\n  [!7246](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7246) about\\n  bundling more than one `Int#` in a `FastMutInt` for performance. He tried to\\n  make a proof of concept generalisation of 2-FastMutInt into n-FastMutInts\\n  (using GHC type level Natural). The types don\u2019t really recurse in a convenient\\n  way (Int -> (\u2026 -> IO ())) so it would probably introduce more complexity than\\n  the problem is worth. Now, he\u2019s just implementing the original patch with the\\n  fixes and documentation."},{"id":"2022-12-13-ghc-js-backend-merged","metadata":{"permalink":"/2022-12-13-ghc-js-backend-merged","source":"@site/blog/2022-12-13-ghc-js-backend-merged.md","title":"JavaScript backend merged into GHC","description":"A new JavaScript backend was","date":"2022-12-13T00:00:00.000Z","formattedDate":"December 13, 2022","tags":[{"label":"ghc","permalink":"/tags/ghc"},{"label":"javascript","permalink":"/tags/javascript"},{"label":"cross-compilation","permalink":"/tags/cross-compilation"}],"readingTime":19.44,"truncated":false,"authors":[{"name":"Sylvain Henry","title":"Haskell DevX Engineer @ IOG","email":"sylvain.henry@iohk.io","key":"sylvain"},{"name":"Jeffrey M. Young","title":"Haskell DevX Engineer @ IOG","url":"https://iog.io/en/","key":"doyougnu"},{"name":"Luite Stegeman","title":"Haskell DevX Engineer @ IOG","email":"luite.stegeman@iohk.io","key":"luite"},{"name":"Joshua Meredith","title":"Haskell DevX Engineer @ IOG","url":"https://iog.io/en/","key":"josh"},{"name":"Moritz Angermann","title":"Head of DevX @ IOG","url":"https://iog.io/en/","key":"moritz"}],"frontMatter":{"slug":"2022-12-13-ghc-js-backend-merged","title":"JavaScript backend merged into GHC","authors":["sylvain","doyougnu","luite","josh","moritz"],"tags":["ghc","javascript","cross-compilation"]},"prevItem":{"title":"GHC DevX Update 2023-01-12","permalink":"/2023-01-12-ghc-update"},"nextItem":{"title":"Model-Based Testing with QuickCheck","permalink":"/2022-09-28-introduce-q-d"}},"content":"A new JavaScript backend was\\n[merged](https://gitlab.haskell.org/ghc/ghc/-/commit/cc25d52e0f65d54c052908c7d91d5946342ab88a)\\ninto GHC on November 30th, 2022! This means that the next release of GHC will be\\nable to emit code that runs in web browsers without requiring any extra tools,\\nenabling Haskell for both front-end and back-end web applications.\\n\\nIn this post, we, the GHC DevX team at [IOG](https://iohk.io/), describe the\\nchallenges we faced bringing GHCJS to GHC, how we overcame those challenges, and\\nwhat\'s left to do. This post is rather long so we\'ve provided these links in\\ncase you would like to skip ahead:\\n\\n[Take me to the future of GHCJS](#ghcjs)  \\n[Tell me what to expect](#expectations)  \\n[Show me the product roadmap](#roadmap)  \\n[Tell me how I can help](#contributing)  \\n[Just show me how to hello world! (Skip to build instructions)](#build)\\n\\n## Why JavaScript? Or, the Big Picture.\\n\\nTo put it simply, the number of users on the internet is as low as it will ever\\nbe _right now_, and it is almost guaranteed that those users use JavaScript. At\\ntime of writing, JavaScript holds 97.3% of client-side programming [market\\nshare](https://w3techs.com/technologies/details/cp-javascript) (not to mention\\nmarket share of front-end technologies). Furthermore, JavaScript is not going to\\ndisappear anytime soon. As more and more interactivity is pushed onto the\\ninternet, JavaScript will become more entrenched because of backwards\\ncompatibility, network effects and the amount of capital already devoted to it.\\nJavaScript, like C and\\n[COBOL](https://cacm.acm.org/news/244370-cobol-programmers-are-back-in-demand-seriously/fulltext?mobile=false)\\nwill be with us for the foreseeable future. This makes JavaScript an attractive\\ntarget; it provides portability, allows us to capitalize on the massive\\ninvestments in the language and platform, and essentially eliminates the risk\\nthat the we build our technology atop a disappearing or deprecating foundation.\\n\\nWebAssembly is a promising target as well, and [Tweag](https://www.tweag.io/)\\nhas just merged a [WebAssembly\\nbackend](https://www.tweag.io/blog/2022-11-22-wasm-backend-merged-in-ghc/) into\\nGHC (great work and congrats!). WebAssembly is not as ubiquitous as\\nJavaScript yet, and has a harder time interacting with JavaScript directly.\\nHence, we believe that the WebAssembly and JavaScript backends provide different\\nstrengths, and it is to the Haskell community\'s benefit to have and support\\nboth code generation paths in GHC for different use cases and requirements.\\n\\n## Why Haskell?\\n\\nJavaScript has many problems ranging from the\\n[downstream](https://www.codeproject.com/Articles/182416/A-Collection-of-JavaScript-Gotchas)\\n[effects](https://wtfjs.com/) of early [design\\ndecisions](https://dl.acm.org/doi/pdf/10.1145/3386327) (that inhibit programmer\\nproductivity and are subtle bug generators), to ecosystem [security\\nissues](https://lwn.net/Articles/681410/), to [fundamental\\nissues](https://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/)\\nwith asynchronous and concurrent programming.\\n\\nThese issues are problematic for our product domain. At IOG, a central\\nengineering requirement is to create a code base that has a high degree of\\ncorrectness. Haskell makes this easy; or to get a little technical, the\\ncombination of Strong Static Hindley-Milner based typing allows us to write\\nperformant, correct, and maintainable code. In addition to this, many of the\\nproblems that occur in JavaScript are simply not expressible because of\\nHaskell\'s type system and concurrency offerings.\\n\\nThere are, of course, competitors: [PureScript](https://www.purescript.org/)\\ntargets Javascript and provides a programmer experience close to Haskell\'s. The\\nbenefit of using Haskell instead is code sharing: we can write the front-end of a\\nweb app in Haskell that compiles to JavaScript and the back-end in Haskell that\\ncompiles to machine code. In particular, the (de)serialization code (e.g.\\nfrom/to JSON) is shared and cannot get out of sync between the front-end and the\\nback-end.\\n\\n## Why a GHC backend?\\n\\nHaskell is a language driven by its implementation in GHC. GHC development is\\nvery active and GHC does not define a stable interface for compiler backends\\nthat are independently maintained, which means that maintaining an out-of-tree\\nbackend is costly.\\n\\nThe maintenance burden is not hypothetical; our teammate Luite Stegeman has been\\ndeveloping a fork of GHC that emits JavaScript, called GHCJS, for close to 10\\nyears and has experienced the pain first hand. Any changes to upstream GHC had\\nto be adapted to the customized fork or GHCJS would fall behind. And fall behind\\nit did: at the time of writing, GHCJS has stuck to using GHC 8.10, lagging\\nbehind by three major releases and counting.\\n\\nSimilarly, the [Eta](https://github.com/typelead/eta) compiler&mdash;which is\\ntargeting the JVM&mdash;faced the same issues and appears to be discontinued\\n(compatibility with GHC 7.10.3\'s Haskell from 2015 is mentioned).\\n\\nCompounding the issue, the normal Haskell toolchain was not designed for an\\nedge case like GHCJS. So GHCJS required that the normal tooling, e.g., Cabal and\\nStack, could distinguish between GHC and GHCJS compilers. This\\nmeant that the GHCJS developers had to maintain the GHC fork, develop GHCJS, and\\npatch or contribute to Cabal and Stack. Simply put, the maintenance burden was\\nmuch too high per developer. Examples of differences between GHCJS and GHC:\\n- GHCJS had a double version&mdash;its own version and the version of GHC it was\\n  based on&mdash;and build tools had to deal with both\\n- GHCJS used non-standard file extension (e.g. `.js_o` and `.js_a` for objects\\n  and static libraries respectively) and custom file formats (still true for\\n  `.o` but no longer true for `.a`)\\n\\nSo instead of spending engineering time and energy _responding_ to ecosystem\\nchanges and maintenance, the DevX team decided the best course of action was to\\nenhance GHC\'s cross-compilation support and add a proper JavaScript backend\\nbased on GHCJS. We feel that this adds value to the entire Haskell ecosystem,\\nkeeps the JavaScript backend in sync with GHC, provides a better user experience\\nfor all, reduces maintenance costs, and greatly improves the backends in GHC in\\ngeneral. By implementing support for a JavaScript backend in GHC, we also\\nimprove GHC\'s support for cross-compilation (and testing cross-compilers), which\\nis directly applicable to the WebAssembly, iOS, and Android backends in GHC.\\n\\n## Is GHCJS Dead? {#ghcjs}\\n\\nNot yet! As it stands, the JavaScript backend doesn\'t provide all the features\\nprovided by GHCJS. In particular it doesn\'t support Template Haskell and we\'ve\\nremoved the extended GHCJS FFI syntax to refine its design. See our roadmap\\nbelow for more details.\\n\\nNevertheless GHCJS is unlikely to be updated to use a GHC version more recent\\nthan 8.10.x. So from our point of view it is in maintenance mode until the\\nJavaScript backend totally subsumes its features. New maintainers who want to\\ncontinue the development of GHCJS until its feature set has been fully subsumed\\nby mainline GHC are of course welcome.\\n\\n\\n## What is Missing From GHCJS? {#expectations}\\n\\nThe JavaScript backend borrows a lot of code from GHCJS, but not all of it.\\nHere are the main differences between GHCJS and the JavaScript backend:\\n\\n1. GHCJS was stuck on GHC version 8.10 while the JavaScript backend follows GHC HEAD.\\n\\n2. GHCJS\'s incremental linking support (\\"base\\" bundles) hasn\'t been ported. This\\n   feature required too many changes (such as adding new command-line flags) and\\n   would have been backend-specific. This might be implemented in the future if\\n   it proves to be useful for the newer Template Haskell implementation, for example.\\n\\n3. GHCJS\'s JavaScript code optimizer hasn\'t been ported. The code was trying to\\n   do too much all at once and consequently was fragile and slow. We plan to\\n   work on an intermediate representation between STG and JavaScript to perform\\n   the same optimizations with better performance, maintainability, and\\n   reliability.\\n\\n4. GHCJS\'s compactor (link time optimizations) code hasn\'t been ported. Some\\n   optimizations have been reimplemented (e.g. global renaming of local\\n   identifiers), but some other are lacking (e.g. compacting initialization code).\\n   We plan to work on this as part of a larger effort on refactoring the code\\n   generator, the linker, and some aspects of the runtime system.\\n   More details are available in [GHC issue #22352](https://gitlab.haskell.org/ghc/ghc/-/issues/22352).\\n\\n5. GHCJS\'s hacky support for plugins hasn\'t been ported.\\n   Instead we implemented a new way to load plugins from shared libraries that\\n   works in any GHC cross-compiler. See\\n   [#20964](https://gitlab.haskell.org/ghc/ghc/-/issues/20964) and\\n   [!7377](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7377).\\n   \\n   The common and convenient approach to load plugins still isn\'t supported by\\n   GHC when it is used as a cross-compiler (see\\n   [#14335](https://gitlab.haskell.org/ghc/ghc/-/issues/14335) for more\\n   details).\\n\\n6. GHCJS\'s support for Template Haskell hasn\'t been ported. GHCJS had its own implementation\\n   of an external interpreter (THRunner) which has been used as an inspiration\\n   to implement GHC\'s external interpreter (IServ).\\n   While serving the same purpose, IServ is quite different from\\n   THRunner and can\'t be directly used as a substitute for it.\\n   Retrofitting THRunner into Iserv is our next priority. More details on\\n   https://engineering.iog.io/2022-05-17-javascript-template-haskell-external-interpreter\\n\\n7. GHCJS supported an extended FFI import syntax allowing Javascript code to be\\n   inlined (the FFI import string supports templates of Javascript code with\\n   placeholders for arguments). This hasn\'t been ported because adding a\\n   JavaScript parser to GHC was difficult and complex, and the imported code\\n   made no safety guarantees whatsoever. For now, only JavaScript function calls\\n   are supported.\\n\\n8. Any command-line flag introduced by GHCJS has not been ported. We didn\'t make\\n   any change to GHC\'s command line in this work except for adding a `-ddump-js`\\n   flag. Other options will be added later as needed.\\n\\n9. The JavaScript backend itself hasn\'t been optimized and we even removed some\\n   undocumented uses of NFData from GHCJS\'s code. We intend to optimize\\n   the JavaScript backend in a principled way (e.g. by first gathering evidence\\n   with profiling).\\n\\n\\n## What\'s on the JS Backend\'s Roadmap? {#roadmap}\\n\\nOur top priorities are:\\n\\n- Implementing Template Haskell support.\\n- Reducing generated JavaScript code size.\\n- Modernizing the generated JavaScript code. The code generator adapted from\\n  GHCJS does not use more modern JavaScript features such as fat-arrows (`=>`),\\n  `symbols` and `let` bindings. We aim for the JavaScript backend to emit\\n  JavaScript that comports with [ECMA-262](https://tc39.es/ecma262/).\\n- Enhancing the run-time performance of the generated code\\n\\n## What has Improved Compared to GHCJS?\\n\\nOr, why did it take you so long to port a stripped GHCJS into GHC? While it may\\nseem like such a task should be relatively quick&mdash;especially in a language\\nwith such a good refactoring story like Haskell&mdash;there were numerous road\\nblocks that we needed to remove before adding the backend. In particular, here\\nwere the troublesome bits:\\n\\n#### Removing the Use of External Libraries\\n\\nGHCJS used libraries that aren\'t already dependencies of GHC, such as `text`, `lens`,\\n`attoparsec`, and `aeson`. As we didn\'t want to add new dependencies to GHC, we\'ve\\nrefactored the code to avoid them. Examples:\\n\\n- we\'ve replaced `Text` with GHC\'s `ShortText` (which provides a similar API)\\n  and finally with GHC\'s `FastString` in most cases (which is usually more\\n  performant).\\n- we\'ve replaced a lot of lens-heavy code with its non-lens equivalents, because\\n  GHC does not use lenses itself, and a design requirement was to stay within\\n  existing code conventions.\\n- we\'ve replaced `pretty` with GHC\'s pretty-printer (`SDoc`, etc.).\\n- we\'ve replaced `binary` with GHC\'s `Binary` instances.\\n\\nGHCJS used to provide its own `base` and `prim` libraries: `ghcjs-base` and\\n`ghcjs-prim`. We\'ve merged those into the existing `base` and `ghc-prim`\\nlibraries.\\n\\n#### Reusing GHC\'s Build System: Hadrian\\n\\nGHCJS has a reputation for being complex to build. It relied on custom build\\nscripts to deal with the GHC fork it uses. The JavaScript backend however is as\\neasy to build as any other GHC. It doesn\'t require any wrapper script, only the\\n`emconfigure` tool provided by the\\n[Emscripten](https://emscripten.org/docs/getting_started/downloads.html)\\nproject.\\n\\nWith a fresh checkout of the GHC source tree, you can now build a GHC with the\\nJavaScript backend with just these commands:\\n\\n```\\n> ./boot\\n> emconfigure ./configure --target=js-unknown-ghcjs\\n> ./hadrian/build --bignum=native -j\\n```\\n\\nNote that if this doesn\'t work, up to date instructions and troubleshootings can\\nbe found on https://gitlab.haskell.org/ghc/ghc/-/wikis/javascript-backend\\n\\nThe Hadrian build system has been adapted to support Cabal\'s `js-sources`\\nstanzas that are to support user-provided `.js` files. Both the `rts` and `base`\\npackages required this feature.\\n\\n#### Support for Running GHC\'s Test Suite\\n\\nGHC\'s entire test suite can now run and check the JavaScript backend! We had to\\ntweak Hadrian to make this possible (to make Hadrian cross-compiler aware), but\\nthe test suite has already found some bugs that we have since fixed.\\n\\nHowever, in order to merge for the GHC 9.6 release we had to disable many tests\\nbecause of missing features (Template Haskell, Haskell Program Coverage (HPC),\\ncompact regions, etc.) or because the generated code would time out (not\\nsurprising given the missing optimizer and compactor).\\n\\nBut in the process of disabling those tests we\'ve laid a good path forward.\\nWe\'ve added more precise properties to the test suite, which indicate the\\nrequired features to run each test. So when we implement some feature, it will\\nbe painless to re-enable all its tests. In addition, failing tests now have\\nproper tickets in GHC\'s [issue tracker](https://gitlab.haskell.org/ghc/ghc/-/issues/?sort=created_date&state=opened&label_name%5B%5D=javascript&first_page_size=100).\\n\\nWe\'ve spent some time trying to run the test suite on CI but this work wasn\'t\\nready in time to be included in the initial commit with the rest of the backend.\\nFor now, only some basic testing is done on CI: compiling a non trivial program\\nthat uses the GHC library into JavaScript and executing it.\\nNevertheless, we have a merge request in the works so that future contributions\\nshould be properly validated by running the test suite on CI soon.\\n\\nFor the time being, the following command will run the\\ntest suite locally:\\n\\n> ./hadrian/build --bignum=native -j2 test\\n\\nWe use `-j2` to avoid running too many tests in parallel as this could allocate\\ntoo much memory and fail, which isn\'t surprising as the JavaScript backend\\nhasn\'t been optimized for memory usage yet.\\n\\n\\n#### Upgrading from GHC 8.10 to GHC 9.6\\n\\nThe latest version of GHCJS is based on a fork of GHC 8.10.7. We spent a\\nsignificant amount of time adapting the code generator to support GHC HEAD. In\\npractice this meant:\\n  - Adding support for new primops, especially sized primitives.\\n  - Adapting to `ghc-bignum` changes.\\n  - Adapting to internal changes.\\n  - Fixing support for polymorphism in kinds.\\n  - Fixing support for unlifted newtypes.\\n  - Fixing support for unboxed sums.\\n  - Many other fixes...\\n\\n#### Fixing Some Performance Issues\\n\\nAs we haven\'t ported GHCJS\'s Compactor, output size was predictably incredibly\\nlarge. So we\'ve spent time re-implementing a crucial piece of the\\nCompactor&mdash;renaming and shortening of local variables&mdash;using a different\\napproach. Our new approach ended up being faster than GHCJS\'s compactor. For the\\nGHC devs out there, as we first replaced the `Text` type with the `FastString`\\ntype, the newer Compactor can now replace a `FastString`-based identifier with a\\nnew identifier derived from the `FastString`\'s `Unique` in constant time.\\n\\n#### Removal of Custom File Extensions and Support for JavaScript Pragmas\\n\\nGHCJS used the `.js.pp` file extension to identify JavaScript files that needed\\nto be passed through CPP before being valid JavaScript. Adding support for this\\nextension in both Hadrian and GHC proved to be more work than just adding\\nsupport for JavaScript pragmas. So we decided to do the latter; similarly to\\nHaskell extension pragmas, you can now write `//#OPTIONS: CPP` in your\\nJavaScript files to enable the CPP pass, and the file extension is always `.js`.\\n\\nWhile we\'re on the topic of file extensions, technically `.js` files don\'t have\\nto be compiled into `.o` files (contrary to C/C++/Haskell/etc. files) at all.\\nHowever, build systems (Hadrian, Cabal...) and compilers (GHC) expect this. So\\nfor consistency with other backends, we\'ve added a fake compilation pass for\\n`.js` files too. They are now renamed into `.o` files with a `//JAVASCRIPT`\\nheader added to distinguish them from object files produced by the JavaScript\\nbackend (and from Emscripten, in the future).\\n\\n#### Cleanup and Documentation {#blogs}\\n\\nGHC provides some utilities (pretty-printer, binary serialization, string\\ninterning, etc.) that GHCJS did not make use of. So we adapted the GHCJS code to\\nexploit these utilities, keep the JavaScript backend similar to other backends,\\nand for better performance.\\n\\nThree of us (out of four) were totally new to GHCJS\'s code base.\\nWe strived to grok the code and to make it understandable by adding\\na lot of comments and refactoring. \\nThroughout this process we logged our learning in our engineering blog\\nto explain some (sadly not all) technical details about GHCJS\'s internals:\\n\\n- https://engineering.iog.io/2022-05-17-javascript-template-haskell-external-interpreter/\\n- https://engineering.iog.io/2022/05/24/april-GHCJS-Objectable-vs-GHC-Binary/\\n- https://engineering.iog.io/2022-07-18-lightweight-threads-on-JavaScript/\\n- https://engineering.iog.io/2022-07-20-js-backend-prim-types/\\n- https://engineering.iog.io/2022-07-26-the-ghcjs-linker/\\n- https://engineering.iog.io/2022-08-18-js-backend-ffi/\\n- https://engineering.iog.io/2022-09-23-ghcjs-heap-representation/\\n\\n#### Plugin Support in Cross-Compilers\\n\\nGHC doesn\'t support plugins when built as a cross-compiler (cf\\n[#14335](https://gitlab.haskell.org/ghc/ghc/-/issues/14335)). This is because it\\ncannot yet support two environments at once: one for the target code (JavaScript\\ncode here) and one for the host (e.g. native x86 or AArch64 code for the\\nplugin). We\'ve spent a lot of time making it more modular (see the [Modularizing\\nGHC](https://hsyl20.fr/home/files/papers/2022-ghc-modularity.pdf) white paper we\\npublished earlier this year and Sylvain\'s [lightning\\ntalk](https://youtu.be/OHGH5HLOCEM) at HIW 2022) but there is a lot more to do\\nto achieve this (cf\\n[#17957](https://gitlab.haskell.org/ghc/ghc/-/issues/17957)).\\n\\nGHCJS used a fragile hack to support plugins: at plugin loading time it would\\nsubstitute the plugin unit with another corresponding one from another package\\ndatabase (For the non-GHC devs out there interested in GHC Units see this\\n[note](https://gitlab.haskell.org/ghc/ghc/-/blob/master/compiler/GHC/Unit.hs)).\\nThis was fragile because it could violate GHC\'s single environment assumptions.\\n\\nGHCJS\'s hack did not get ported. Nevertheless we have implemented a new way for\\nGHC to load plugins directly from libraries instead of packages\\n([#20964](https://gitlab.haskell.org/ghc/ghc/-/issues/20964)/[!7377](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7377)).\\nThis method doesn\'t require GHC to load module interfaces for the plugin and its\\ndependencies, hence workarounds GHC\'s limitations.\\n\\n## What About Libraries Using C Sources?\\n\\nLibraries that use C sources (`c-sources` Cabal stanza) aren\'t supported by the\\nJavaScript backend. In the future we plan to use Emscripten to compile C sources\\nand then to generate some adapter code for them, but this isn\'t done yet.\\n\\nFor now, there are two ways to fix libraries that use C sources.\\nThe C code can either be rewritten in Javascript, or it can be rewritten in\\nHaskell.\\nThen it is possible to use Cabal predicates (e.g. `arch(js)`) to select between\\nthe different versions.\\n\\nWe do have a preference for writing pure Haskell versions because it is more\\nfuture proof.\\nFor example if someone adds some new backends for Lua, Java, CLR, etc. then the\\nHaskell version can be directly compiled by that backend and there is no extra work.\\nIn contrast, if the C source is rewritten in JavaScript, then it would need to\\nbe rewritten _for each_ backend.\\n\\nThat is the approach we\'ve taken when we wrote the `ghc-bignum` library.\\n`Ghc-bignum` provides a \\"native\\" implementation written in Haskell that is\\nfunctionally equivalent to the GMP based implementation. Of course, besides\\nbeing more future proof the Haskell version is just more pleasant to write than\\nthe Javascript version.\\n\\nNote that GHCJS came with a \\"shim\\" library where a shim is JavaScript source\\ncode specifically for some package. For example, GHCJS provided shims for\\npackages like `text`, `process`, and `hashable`. We do not intend the JavaScript\\nbackend to provide shims so these JavaScript sources will have to be upstreamed\\nor reimplemented in Haskell.\\n\\nNote that the linking behavior is different due to the interpreted nature of\\nJavascript. In the JavaScript backend, we can link with libraries using foreign\\nimports _even if_ the imported functions don\'t exist. Instead of failing at link\\ntime (which is what usually happens with native code) a JavaScript exception is\\nraised only when and if the imported function is called.\\n\\n## How to Help? {#contributing}\\n\\nWe have now reached our first milestone; anyone can easily build and test the\\nJavaScript backend, and anyone can open bug reports or offer patches for the\\nJavaScript backend on GHC\'s GitLab.\\n\\nFor those who offered their help this year: thank you! Until now it was\\ndifficult to split the work into independent tasks (one fix led to a new\\nfailure, which led to an architectural issue, etc.) and it was difficult to\\ncoordinate with people outside of our team. However, we\'re now in a much better\\nposition to discuss suggestions and to test/review patches in the spirit of open\\nsource.\\n\\n## tl;dr Just Tell Me How to Say Hello World {#build}\\n\\nYou need:\\n\\n  - [Emscripten](https://emscripten.org/docs/getting_started/downloads.html)\\n    version 3.14 or better. Be sure that your emscripten is bundled with either\\n    LLVM 15 or an up to date, patched LLVM 14.\\n  - [Nodejs](https://nodejs.org/en/), latest stable version. Only if you want to\\n    run the compiled JavaScript with node.\\n  \\nMost Linux distributions will have the necessary LLVM patches. If you\'re on NixOS,\\nyou\'ll need to use `llvm_git` and hope for the best. [This\\nfork](https://github.com/doyougnu/ghc.nix) of `ghc.nix` will also be useful to\\nyou.\\n\\n#### Checkout the GHC source\\n\\n```\\ngit clone --recurse-submodules https://gitlab.haskell.org/ghc/ghc.git\\ncd ghc # ensure you are in the ghc source tree for the following commands\\n```\\n\\n#### Update the submodules\\n\\n```\\ngit submodule update --init --recursive\\n```\\n\\n#### Boot and Configure for JavaScript\\n\\n```\\n./boot && emconfigure ./configure --target=js-unknown-ghcjs\\n```\\n\\nYou should see `configure` finish and report something similar:\\n```\\n----------------------------------------------------------------------\\nConfigure completed successfully.\\n\\n   Building GHC version  : 9.5.20220819\\n          Git commit id  : 08c3c4783c72d3173d79ccda2ac282e2d3e04e34\\n\\n   Build platform        : x86_64-unknown-linux\\n   Host platform         : x86_64-unknown-linux\\n   Target platform       : js-unknown-ghcjs\\n\\n   Bootstrapping using   : /nix/store/4bkmkc7c98m4qyszsshnw9iclzzmdn4n-ghc-9.2.3-with-packages/bin/ghc\\n      which is version   : 9.2.3\\n      with threaded RTS? : YES\\n\\n   Using (for bootstrapping) : /nix/store/yzs8390walgk2rwl6i5li2g672hdn0kv-gcc-wrapper-11.3.0/bin/cc\\n   Using clang               : /nix/store/p894nlicv53firllwgrfxfi51jzckh5l-emscripten-3.1.15/bin/emcc\\n      which is version       : 15.0.0\\n      linker options         : \\n   Building a cross compiler : YES\\n   Unregisterised            : NO\\n   TablesNextToCode          : YES\\n   Build GMP in tree         : NO\\n   hs-cpp       : /nix/store/p894nlicv53firllwgrfxfi51jzckh5l-emscripten-3.1.15/bin/emcc\\n   hs-cpp-flags : -E -undef -traditional -Wno-invalid-pp-token -Wno-unicode -Wno-trigraphs\\n   ar           : /nix/store/p894nlicv53firllwgrfxfi51jzckh5l-emscripten-3.1.15/bin/emar\\n   ld           : /nix/store/p894nlicv53firllwgrfxfi51jzckh5l-emscripten-3.1.15/bin/emcc\\n   nm           : /nix/store/0dp0bfg9sncg7bjy389zwyg2gskknm6b-emscripten-llvm-3.1.15/bin/llvm-nm\\n   objdump      : /nix/store/zgvxnf9047rdd8g8kq2zxxm9k6kfqf8b-binutils-2.38/bin/objdump\\n   ranlib       : /nix/store/p894nlicv53firllwgrfxfi51jzckh5l-emscripten-3.1.15/bin/emranlib\\n   otool        : otool\\n   install_name_tool : install_name_tool\\n   windres      : \\n   dllwrap      : \\n   genlib       : \\n   Happy        : /nix/store/ijdmyaj6i6hgx5ll0lxxgcm9b0xn8nma-happy-1.20.0/bin/happy (1.20.0)\\n   Alex         : /nix/store/qzgm2m7p7xc0fnyj4vy3jcmz8pvbg9p7-alex-3.2.6/bin/alex (3.2.6)\\n   sphinx-build : /nix/store/27dk5i52465a4azjr2dqmrhyc0m4lpf2-python3.9-sphinx-4.5.0/bin/sphinx-build\\n   xelatex      : /nix/store/8jc2258h4nqzqjy303zzkssd3ip675pf-texlive-combined-2021/bin/xelatex\\n   makeinfo     : /run/current-system/sw/bin/makeinfo\\n   git          : /nix/store/vsr2cn15h7cbwd5vqsam2ab2jzwfbyf9-git-2.36.0/bin/git\\n   cabal-install : /nix/store/cjmd2qv1b5pdw4lxh1aw4xwwy4ibnb2p-cabal-install-3.6.2.0/bin/cabal\\n\\n   Using LLVM tools\\n      clang : clang\\n      llc   : llc\\n      opt   : opt\\n\\n   HsColour was not found; documentation will not contain source links\\n\\n   Tools to build Sphinx HTML documentation available: YES\\n   Tools to build Sphinx PDF documentation available: YES\\n   Tools to build Sphinx INFO documentation available: YES\\n----------------------------------------------------------------------\\n```\\n\\nBe sure to verify that `ar`, `ld`, `nm` and friends point to the emscripten\\nversions, i.e., the output shows `<tool> : <some-path>-emscripten-<tool>`.\\n\\n#### Build the JavaScript backend\\n```\\n./hadrian/build --bignum=native -j\\n```\\n\\n#### Now Compile Hello World\\n```hs\\nmodule Main where\\n\\nmain :: IO ()\\nmain = putStrLn \\"Hello JS!\\"\\n```\\n\\n```\\n$ <path-to-ghc-root-dir>/_build/ghc-stage1 -fforce-recomp Main.hs\\n$ ./Main\\n$ Hello JS!\\n```\\n\\nUnder the hood `Main` is just a JavaScript program written as a script with\\n`nodejs` as the interpreter. This means you can treat the compiled program like\\nany other JavaScript program: loading it into JavaScript tooling or hack on it\\nby hand. This also means that all compiled programs, such as `Main`, are\\nhuman-readable, for example here are the first ten lines:\\n\\n```js\\n$ head Main\\n#!/usr/bin/env node\\nvar h$currentThread = null;\\nvar h$stack = null;\\nvar h$sp = 0;\\nvar h$initStatic = [];\\nvar h$staticThunks = {};\\nvar h$staticThunksArr = [];\\nvar h$CAFs = [];\\nvar h$CAFsReset = [];\\nvar h$regs = [];\\n```\\n\\nThe program begins with a shebang instructing the operating system to send the\\nrest of the file to `nodejs`. The remaining lines are our actual program, which\\nstarts with global variables that the runtime system, garbage collector, and\\nscheduler need. Now human-readable is not the same as easy to understand, for\\nexample here is the logic that implements a `Maybe`:\\n\\n```js\\nfunction h$baseZCGHCziMaybeziJust_con_e() { return h$rs() };\\nfunction h$baseZCGHCziMaybeziJust_e() {\\nvar h$$13be2042 = h$r2;\\nh$r1 = h$c1(h$baseZCGHCziMaybeziJust_con_e, h$$13be2042);\\nreturn h$rs();\\n};\\nfunction h$baseZCGHCziMaybeziNothing_con_e() { return h$rs() };\\n```\\n\\nIf you would like to understand this code and how the JavaScript backend works\\nin general please see [our other blog posts](#blogs). In any case, we invite you\\nto try it out, hack, and be merry!\\n\\n\\n## Acknowledgements\\nWe want to thank Jan Hrcek, and David Thrane Christiansen for their time, labor,\\ncomments, and suggestions on drafts of this blog post."},{"id":"2022-09-28-introduce-q-d","metadata":{"permalink":"/2022-09-28-introduce-q-d","source":"@site/blog/2022-09-28-introduce-q-d.md","title":"Model-Based Testing with QuickCheck","description":"quickcheck-dynamic is a library jointly developed by Quviq and IOG, whose purpose is to leverage QuickCheck to test stateful programs against a Model. In other words, it\'s a Model-Based Testing tool. This article wants to be a gentle introduction to the use of quickcheck-dynamic for Model-Based Testing. It describes the overall approach, how the library works, and how it\'s being applied within IOG to improve the reach of our testing efforts.","date":"2022-10-04T00:00:00.000Z","formattedDate":"October 4, 2022","tags":[{"label":"testing quickcheck","permalink":"/tags/testing-quickcheck"}],"readingTime":14.09,"truncated":false,"authors":[{"name":"Arnaud Bailly","title":"Technical Architect @ IOG","email":"arnaud.bailly@iohk.io","key":"arnaud"}],"frontMatter":{"slug":"2022-09-28-introduce-q-d","title":"Model-Based Testing with QuickCheck","date":"October 4, 2022","authors":["arnaud"],"tags":["testing quickcheck"]},"prevItem":{"title":"JavaScript backend merged into GHC","permalink":"/2022-12-13-ghc-js-backend-merged"},"nextItem":{"title":"GHCJS heap representation","permalink":"/2022-09-23-ghcjs-heap-representation"}},"content":"[quickcheck-dynamic](https://github.com/input-output-hk/quickcheck-dynamic) is a library jointly developed by Quviq and IOG, whose purpose is to leverage [QuickCheck](https://hackage.haskell.org/package/QuickCheck) to test stateful programs against a _Model_. In other words, it\'s a [_Model-Based Testing_](https://en.wikipedia.org/wiki/Model-based_testing) tool. This article wants to be a gentle introduction to the use of quickcheck-dynamic for Model-Based Testing. It describes the overall approach, how the library works, and how it\'s being applied within IOG to improve the reach of our testing efforts.\\n\\n## Background\\n\\nTesting stateful or rather effectful code using QuickCheck is not new: In particular, techniques to test _Monadic_ code with QuickCheck have been introduced in [Claessen & Hughes, 2002](https://dl.acm.org/doi/10.1145/636517.636527). `quickcheck-dynamic` is based on a state-machine approach originally implemented by Quviq in closed-source [Erlang version of QuickCheck](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.148.6554&rep=rep1&type=pdf) and put to use to test various systems as explained in John Hughes\' [paper](https://publications.lib.chalmers.se/records/fulltext/232550/local_232550.pdf).\\n\\nIOG already has had experience with state-machine based testing in the Consensus [Storage layer](https://github.com/input-output-hk/ouroboros-network/blob/nfrisby/old-benchmark-ledger-ops/ouroboros-consensus-test/README.md#L1) using [quickcheck-state-machine](https://hackage.haskell.org/package/quickcheck-state-machine) library, but this was not widespread practice across the various teams.\\n\\nWhen IOG started working on the Plutus Smart Contracts language and application framework, Quviq\'s consultancy was sought after to help test the platform and build tools for future Smart Contract implementors. This effort lead to the development of a custom library for testing smart contracts based on quickcheck-dynamic\'s state-machine model and dynamic logic language adapted from Erlang QuickCheck.\\n\\nAs quickcheck-dynamic matured, it attracted interest from other teams willing to invest into model-based testing and reuse existing effort. This finally lead to publication of the library as an independent package on [Hackage](https://hackage.haskell.org/package/quickcheck-dynamic), independently of the Plutus framework, in the hope it will be useful to a wider audience.\\n\\n## Use Cases\\n\\n### Example: Thread Registry\\n\\nThe library comes with a complete example defining a model and reference implementation for a _Thread Registry_. It\'s inspired by a similar example in Erlang from a couple of papers:\\n  * [How well are your requirements tested?](https://publications.lib.chalmers.se/records/fulltext/232552/local_232552.pdf)\\n  * and [Understanding Formal Specifications through Good Examples](https://mengwangoxf.github.io/Papers/Erlang18.pdf)\\n\\nThe tests here use IOG\'s concurrent execution simulator library [io-sim](https://github.com/input-output-hk/io-sim) to speed-up testing.\\n\\n### Lockstep Testing\\n\\nEdsko de Vries wrote a [nice blog post](https://well-typed.com/blog/2022/09/lockstep-with-quickcheck-dynamic/) to compare `quickcheck-dynamic` with [quickcheck-state-machine](https://hackage.haskell.org/package/quickcheck-state-machine), another library to write model-based tests on top of QuickCheck. This blog post introduces [quickcheck-lockstep](https://github.com/well-typed/quickcheck-lockstep) which provides _lockstep-style_ testing on top of quickcheck-dynamic.\\n\\nLockstep-style testing is a special case of Model-Based Testing whereby what\'s tested at each execution step of a test sequence is the equivalence up to some observability function, of the return values expected by the _Model_ and the one provided by the _Implementation_. In other words, if we consider each step in the state-machine as a transition that, given some input and a starting state, produces some output and possibly a new state, then lockstep-style testing checks equivalence of the _output traces_ from the model and the implementation.\\n\\nThe quickcheck-lockstep library provides generic implementations for most of the methods of the `StateModel` typeclass and dedicated type-classes to relate the Model and the Implementation.\\n\\n### Plutus Contracts\\n\\nWithin IOG, the quickcheck-dynamic testing approach was initially applied to provide a testing framework for Smart Contracts developers within the Plutus Application Backend. The Plutus documentation contains a [detailed tutorial](https://plutus-apps.readthedocs.io/en/latest/plutus/tutorials/contract-models.html) on how to model smart contracts and tests them using underlying _Emulator_.\\n\\nWhile the _Contract Model_ is a specialised library dedicated to Smart contracts modeling and testing, the underlying principles are similar:\\n* Define a `ContractModel` with some state and actions representing the system behaviour,\\n* Define a `perform`  function that describes how the model\'s actions translate to real world calls to a Contract\'s _endpoints_,\\n* then test the contracts implementation using properties written in the _Dynamic Logic_ language provided by the framework.\\n\\nOn top of quickcheck-dynamic, the _Contract Model_ provides machinery to simplify definition of a model in the case of Plutus smart contracts and running tests against a set of _Wallets. More importantly, it predefines critical properties that all Smart Contracts should validate, like the [No Locked Funds](https://github.com/input-output-hk/plutus-apps/blob/main/plutus-contract/src/Plutus/Contract/Test/ContractModel/Internal.hs#L1719) or the more subtle [Double Satisfaction](https://github.com/input-output-hk/plutus-apps/blob/main/plutus-contract/src/Plutus/Contract/Test/ContractModel/DoubleSatisfaction.hs) property. Smart contracts are somewhat infamous for being subject to subtle coding errors leading into loopholes which attackers can abuse to steal currencies from innocent users, because of the intrisic complexity of programming in a highly distributed and asynchronous model.\\n\\nThe Model-Based Testing approach supported by quickcheck-dynamic gives developers the tools to explore the state space in a much more systematic way.\\n\\n### Hydra\\n\\n[Hydra](https://hydra.family) is a so-called _Layer 2_ solution for Cardano that aims at increasing the throughput and latency of Cardano transactions by moving most of the traffic out of the main chain (_Layer 1_) and into smaller networks. The _Hydra Head_ protocol is described in great details in a [research paper](https://eprint.iacr.org/2020/299.pdf).\\n\\nAt its core, Hydra is a state machine whose transitions are Layer 1 transactions, as depicted in the following picture:\\n\\n![Hydra State Machine](https://hydra.family/head-protocol/assets/images/hydra-head-lifecycle-b8449385e9041a214bf8c6e52830de3c.svg)\\n\\nWhile the overall state machine appears relatively simple on the surface, the actual protocol is actually quite complex, involving cryptographic signatures and _Plutus Smart Contracts_ to ensure the safety of the protocol. This safety is formally expressed in the paper as _properties_ that are proven against an _Adversary Environment_ whose capabilities are well-defined.\\n\\nIn order to guarantee the implementation provides those safety properties, the Hydra team has developed a diversified palette of testing techniques, including the use of quickcheck-dynamic. While the careful Test-Driven Development approach taken gives reasonable confidence most use cases and issues are covered, hopes are high that such a model is able to explore more corner cases and reveal subtle issues in the protocol implementation.\\n\\nWhat was sought after is to be able to define and test Hydra Head security properties against the real implementation. As a first example the team tackled to get a feel of how quickcheck-dynamic could used, here one of the properties from the original paper is stated:\\n\\n> \u2022 Conflict-Free Liveness (Head):\\n>\\n> In presence of a network adversary, a conflict-free execution satisfies the following condition:\\n> For any transaction tx input via (new,tx), tx \u2208 T i\u2208[n] Ci eventually holds.\\n\\nThis property and similar ones are encoded as a _Dynamic Logic_ expressions, and a suitable Model of a Hydra network is defined as an instance of `StateModel` from which test sequences representing User actions are generated.\\n\\nHydra is a distributed system where nodes are interconnected through a network layer, and each node needs to be connected to a cardano-node in order to preserve the security of the protocol. While testing an actual \\"cluster\\" of hydra and cardano nodes is definitely possible, and certainly desirable at some point in order to strengthen confidence in the whole system, it would also be very slow: Spinning up processes, establishing network connections, producing blocks on a chain, all take seconds if not minutes which makes any signficant exploration of the model state space practically infeasible.\\n\\nGenerated test traces are run within the [IOSim](https://github.com/input-output-hk/hydra-poc/blob/master/hydra-node/test/Hydra/ModelSpec.hs#L220) monad which allows testing 100s of traces within seconds.\\n\\nOf course, this means we won\'t be using real TCP/IP networking stack nor connection to a real Cardano node and chain to create a Hydra network, but this is actually not a liability but an asset. By [mocking](https://abailly.github.io/posts/mocking-good-idea.html) the interfaces Hydra nodes use to communicate with other nodes and Cardano network, we are able to control the behaviour of the communication layer and _inject faults_ representing some _Adversary_: Reordering or dropping messages, tampering the data, delaying requests...\\n\\n## Principles\\n\\nWe\'ll use the latter example to illustrate quickcheck-dynamic\'s principles and give the reader an intuition on the four steps that need to be defined in order to use it: Defining a test _Model_, stating how the model relates to the _Implementation_, expressing _Properties_ and, last but not least, checking properties.\\n\\n### Defining a Model\\n\\nIn quickcheck-dynamic, a _Model_ is some type, a representation of the expected state of the system-under-test, for which there exists an instance of the [StateModel class](https://github.com/input-output-hk/quickcheck-dynamic/blob/abailly-iohk/blog-post/quickcheck-dynamic/src/Test/QuickCheck/StateModel.hs#L56) which sets the building blocks needed to generate and validate test sequences.\\n\\nIn the case of Hydra, the Model is a `IdealWorld` data type that control the Head parties and maintains a `GlobalState` which reflects the expected Head state:\\n\\n```haskell\\ndata IdealWorld = IdealWorld\\n  { hydraParties :: [(SigningKey HydraKey, CardanoSigningKey)]\\n  , hydraState :: GlobalState\\n  }\\n```\\n\\nWe won\'t bother the reader with details of the `GlobalState` which basically encode the states as depicted in the state-machine picture hereabove in the form of an Algebraic Data-Type.\\n\\nAs the old saying from Alfred Korzybski goes, \\"The map is not the territory\\", hence to be useful a _Model_ should abstract away irrelevant details for the purpose of testing. Furthermore, it\'s perfectly fine to use different models to test different aspects of the same implementation.\\n\\nWhile the real Hydra layer two ledger does support a myriad of possible Cardano transactions, our model at hand is simpler and only uses _Two Party Payment_ transactions:\\n\\n```haskell\\ndata Payment = Payment\\n  { from :: CardanoSigningKey\\n  , to :: CardanoSigningKey\\n  , value :: Value\\n  }\\n```\\n\\nThe first important part of the `StateModel` instance to define is the type of `Action` that are meaningful for the given _Model_ and that can also be executed against the concrete implementation. The `Action` associated data-type is a GADT which allows the model to represent the type of _observable output_ that can be produced by the implementation and which can be part of the model\'s validation logic.\\n\\nThe Hydra model needs to represent both on-chain and off-chain actions as the properties required from Hydra relates the two. The `Action` data-type represent user-facing commands and observations that can be made on the state of the system (please note at the time of writing this, the model is incomplete):\\n\\n```haskell\\n  data Action IdealWorld a where\\n    Seed :: {seedKeys :: [(SigningKey HydraKey, CardanoSigningKey)]} -> Action IdealWorld ()\\n    Init :: Party -> ContestationPeriod -> Action IdealWorld ()\\n    Commit :: Party -> UTxOType Payment -> Action IdealWorld ActualCommitted\\n    Abort :: Party -> Action IdealWorld ()\\n    NewTx :: Party -> Payment -> Action IdealWorld ()\\n    Wait :: DiffTime -> Action IdealWorld ()\\n    ObserveConfirmedTx :: Payment -> Action IdealWorld ()\\n```\\n\\nThen one needs to define:\\n* An `initialState`,\\n* How to generate `arbitraryAction`s which will be used to produce sequences (or traces) of `Action`s to execute, depending on the current state,\\n* A `precondition` function ensuring some `Action` is valid in some state. This function may seem redundant with the generator but is actually important when _shrinking_ a failing test sequences: The execution engine will ensure the reduced sequence is still valid with respect to the model,\\n* A `nextState` (transition) function that evolves the model state according to the `Action`s,\\n* Auxiliary function `actionName` to providea  human-readable representation of actions.\\n\\nThe reader is invited to check the [Haddock](https://hackage.haskell.org/package/quickcheck-dynamic-1.1.0/docs/Test-QuickCheck-StateModel.html) documentation of the library for further details.\\n\\n### Exercising Implementation\\n\\nA _Model_ alone is somewhat useless if we don\'t provide a way to relate it to the actual implementation of the system-under-test. `quickcheck-dynamic` provides the [`RunModel`](https://hackage.haskell.org/package/quickcheck-dynamic-1.1.0/docs/Test-QuickCheck-StateModel.html#t:RunModel) typeclass for this purpose. The most important function to define is `perform` which defines how `StateModel`\'s `Action` should be executed against the implementation within some monadic context `m`. Having the actual execution `Monad m` be a parameter of the `RunModel` gives more flexibility to the implementor which is not tied to `IO` for example.\\n\\nIn the case of Hydra, the `perform` function is defined as:\\n\\n```haskell\\n  perform ::\\n    IdealWorld ->\\n    Action IdealWorld a ->\\n    LookUp (StateT (Nodes m) m ->\\n    StateT (Nodes m) m a\\n  perform st command _ = do\\n    case command of\\n      Seed{seedKeys} ->\\n        seedWorld seedKeys\\n      Commit party utxo ->\\n        performCommit (snd <$> hydraParties st) party utxo\\n...\\n```\\n\\nThe actual monad used is a classical `State` monad whose state maps a `Party` to the corresponding client connection to the Hydra node:\\n\\n```haskell\\ndata Nodes m = Nodes\\n  { nodes :: Map.Map Party (TestHydraNode Tx m)\\n  , logger :: Tracer m (HydraNodeLog Tx)\\n  }\\n```\\n\\nThe `m` parameter is here kept somewhat unconstrained in order to make it possible to run properties within the `IOSim` monad for faster tests execution. Also note the presence of the `logger` field which is used to capture logging output from all the nodes: Should an error happen or a postcondition fail, we can dump the log of each node which is invaluable to troubleshoot such failures. In general, testing systems in a black-box way emphasises the importance of good logging to provide as much context as possible should issues arise, and using quickcheck-dynamic makes no exception.\\n\\n### Expressing Properties with Dynamic Logic\\n\\nOnce we have a `StateModel` we can express interesting _properties_ to check against our `RunModel`. [Dynamic Logic](https://github.com/input-output-hk/quickcheck-dynamic/blob/abailly-iohk/link-to-blog-post/quickcheck-dynamic/src/Test/QuickCheck/DynamicLogic.hs) allows one to express properties through monadic expressions relating actions, states and logic predicates.\\n\\nDynamic Logic is a form of _modal logic_, similar to [temporal logic](https://en.wikipedia.org/wiki/Temporal_logic), but whose modalities are the _actions_ (or programs) themselves. One can intertwine _programs_ and logic predicates to specify the behaviour of the former when executing some statements and actually [Dynamic Logic](https://en.wikipedia.org/wiki/Dynamic_logic_(modal_logic)) evolved from _Hoare\'s Triples_.\\n\\nHere is the dynamic logic reformulation of the previously stated Hydra property which has been kept as close as possible to the original English statement:\\n\\n```haskell\\nconflictFreeLiveness :: DL IdealWorld ()\\nconflictFreeLiveness = do\\n  anyActions_\\n  getModelStateDL >>= \\\\case\\n    st@IdealWorld{hydraState = Open{}} -> do\\n      (party, payment) <- forAllQ (nonConflictingTx st)\\n      action $ Model.NewTx party payment\\n      eventually (ObserveConfirmedTx payment)\\n    _ -> pass\\n where\\n  nonConflictingTx st = withGenQ (genPayment st) (const [])\\n  eventually a = action (Wait 10) >> action a\\n```\\n\\nNote that in order to define this property we have introduced two \\"pseudo-actions\\" in the _Model_, `Wait` and `ObserveConfirmedTx`: Those `Action`s have no effect on the model itself, the former being used to introduce some delay in the context of distributed and asynchronous execution, and the latter serving the purpose of _observing_ the current state of the SUT. An alternative formulation would have been to make `ObserveConfirmedTx` return the set of confirmed transactions and then express the condition as a logic predicate within the `conflictFreeLiveness` property\'s body.\\n\\n### Checking Properties\\n\\nThe last step in putting quickcheck-dynamic at work is to be able to connect the _StateModel_, the _RunModel_, and the _DynamicLogic_ expression and turn those into a QuickCheck `Property` which can then be checked using the standard testing framework.\\n\\nquickcheck-dynamic provides 2 functions for that purpose. The `forAllDL_` function (actually more a family of functions) will leverage `DL` formulae to generate sequences of `Action`s:\\n\\n```haskell\\nprop_checkConflictFreeLiveness :: Property\\nprop_checkConflictFreeLiveness =\\n  forAllDL_ conflictFreeLiveness prop_HydraModel\\n```\\n\\nThe `runActions` function will execute the generated trace against the `RunModel`.\\n\\n```haskell\\nprop_HydraModel :: Actions IdealWorld -> Property\\nprop_HydraModel actions = property $\\n  runIOSimProp $ do\\n    _ <- runActions runIt actions\\n    assert True\\n```\\n\\nIn this particular instance from Hydra, we need some additional machinery (the `runIOSimProp` function) to handle the execution of some monadic `PropertyM` into `IOSim` monad, turning it into a `Property`.\\n\\nWhen run and successful, this `Property` generates the following output:\\n\\n```\\n  check conflict-free liveness\\n    +++ OK, passed 100 tests.\\n\\n    Actions (1334 in total):\\n    49.93% NewTx\\n    25.86% Commit\\n     7.50% Seed\\n     7.42% Init\\n     4.80% Abort\\n     2.25% ObserveConfirmedTx\\n     2.25% Wait\\n\\n    Transitions (1334 in total):\\n    54.42% Open -> Open\\n    23.61% Initial -> Initial\\n     7.50% Start -> Idle\\n     7.42% Idle -> Initial\\n     4.80% Initial -> Final\\n     2.25% Initial -> Open\\n```\\n\\nBy default, `runActions` decorate the QuickCheck output _tabulating_ the executed `Action`. And thanks to the `monitoring` helper provided by the `RunModel`, this example also tabulates the executed _transitions_ between each of the possible values for `GlobalState`. These pieces of information are important to assess the \\"quality\\" of the model: We want to make sure its generators and the properties execution covers all interesting parts of the Model, hence exercise all relevant parts of the implementation. Please note that, as we mentioned before, the Hydra model is still a work in progress hence the reason why there\'s no `Open -> Final` transition!\\n\\n## Conclusion\\n\\nThis articled introduced [quickcheck-dynamic](https://hackage.org/packages/quickcheck-dynamic), a novel Model-Based Testing library initially developed by Quviq for testing Plutus Smart Contracts and which has recently been open-sourced by IOG. I have tried to convey to the user a sense of the _Whys_, _Whats_ and _Hows_ questions this library answers through various examples and a high-level walkthrough of the steps needed to use this library for testing an implementation.\\n\\n_Model-Based Testing_ is a powerful tool that simultaneously addresses both aspects of [Customer-facing tests](http://www.exampler.com/old-blog/2003/09/05.1.html#agile-testing-project-4) as Brian Marick puts it in his famous _Agile Testing Quadrant_ popularised by Lisa Crispin and Janet Gregory through their [Agile Testing](https://agiletester.ca/wp-content/uploads/sites/26/2015/07/Agile-tips-final.pdf) books: _Supporting the team_ by providing a reference model to build against, and _Critiquing the product_ through the unique state-space exploration QuickCheck provides, possibly uncovering corner cases and blind spots in either the specification or the implementation.\\n\\nThe library is still evolving towards better developer experience and flexibility but it\'s already in a state that makes it possible to test something as significant as a Hydra network. And while it may appear somewhat involved when compared to more traditional forms of writing _Functional tests_, I hope I have demonstrated quickcheck-dynamic lowers the barrier to entry associated with most MBT tools."},{"id":"2022-09-23-ghcjs-heap-representation","metadata":{"permalink":"/2022-09-23-ghcjs-heap-representation","source":"@site/blog/2022-09-23-ghcjs-heap-representation.md","title":"GHCJS heap representation","description":"Introduction","date":"2022-09-23T00:00:00.000Z","formattedDate":"September 23, 2022","tags":[{"label":"ghc","permalink":"/tags/ghc"},{"label":"javascript","permalink":"/tags/javascript"}],"readingTime":8.32,"truncated":false,"authors":[{"name":"Sylvain Henry","title":"Haskell DevX Engineer @ IOG","email":"sylvain.henry@iohk.io","key":"sylvain"}],"frontMatter":{"slug":"2022-09-23-ghcjs-heap-representation","title":"GHCJS heap representation","date":"September 23, 2022","authors":["sylvain"],"tags":["ghc","javascript"]},"prevItem":{"title":"Model-Based Testing with QuickCheck","permalink":"/2022-09-28-introduce-q-d"},"nextItem":{"title":"GHCJS FFI system in the JS Backend","permalink":"/2022-08-18-js-backend-ffi"}},"content":"## Introduction\\n\\nI recently gave a short presentation about heap objects representation in GHCJS and hence in the upcoming JS backend for GHC. This post is a summary of the content.\\n\\n## Heap objects\\n\\nGHC implements Haskell code evaluation by using graph reduction. As such Haskell\\nprograms compiled by GHC use the heap to store nodes of the graph to be\\nreduced and utility nodes participating in graph reduction. These nodes are:\\n\\n- FUN: functions with their free variables as payload\\n- THUNK: suspensions with their free variables as payload\\n- PAP: partial application to a FUN. FUN closure and already applied arguments\\n  as payload.\\n- IND: indirection to another heap object\\n- BLACKHOLE: used to overwrite a THUNK when it is being evaluated\\n\\nThe heap is also used to store other values:\\n\\n- CON: boxed values (saturated constructor applications) with field values as payload\\n- Other unlifted values: TSO, BCO, arrays, MutVar#, MVar#, TVar#, stacks, stack frames...\\n\\n## Info tables\\n\\nMany heap objects share the same properties: e.g. all `Int` CON objects are\\nexactly the same except for their payload (the `Int#` value) that may be\\ndifferent.\\nHence heap objects are split in two parts to allow sharing of common properties:\\n- info table: statically known properties (at compilation time) that can be\\n  shared by several heap objects\\n- heap object itself: dynamically allocated in the heap\\n\\nHeap objects always have the same layout in the native code generated by GHC.\\nThey are composed of:\\n- a pointer to an info table\\n- some words of payload\\n\\nHeap traversal is done by following the info table pointer of every heap\\nobject to query in the info table the layout of the heap object payload.\\n\\nInfo tables contain a pointer to a function called \\"entry code\\" that can be\\nspecific to each info table. This code is mainly used to apply a node to some\\narguments.\\nNote that with tables-next-to-code optimisation enabled, to avoid an\\nindirection the info table pointer is actually a pointer to this entry code and\\nthe info table itself is stored in the words preceeding the entry code.\\n\\n## Heap objects in JavaScript\\n\\nGHCJS represents most heap objects with a JavaScript object having the following\\nfields:\\n\\n```yaml\\n{ f, d1, d2, m, cc }\\n```\\n\\nOne question I had was: why don\'t we use a JS array instead of a JS object?\\nArrays should be faster than objects (i.e. hashmaps), no? It turns out that\\nobjects like this are optimised by JS engines using \\"hidden classes\\" (see\\nhttps://v8.dev/blog/fast-properties for an explanation). That\'s why\\nthey are usually more efficient than arrays for which bound checking must be\\nmade. Also arrays are larger in memory because they need to store their size.\\n\\nLet\'s now discuss the fields of the heap objects.\\n\\n### f field\\n\\n\\"f\\" is the equivalent of the info table pointer. It contains a JavaScript\\nfunction that is the entry code for the heap object.\\n\\nSimilar to the tables-next-to-code optimisation discussed above, we use the\\nfact that JS functions are objects which have properties to store the info\\ntable fields as properties of the function itself.\\n\\nExample of an info table / entry function:\\n\\n```javascript\\n[Function: h$entry_function_xyz]\\n  { t    // (Int) object type\\n  , size // (Int) number of fields in payload (-1 if variable layout)\\n  , i    // (Array) fields layout (empty if variable layout)\\n  , n    // (String) object name for debug\\n  , a    // (Int) function arity or constructor tag\\n  , r    // (Int) arity in number of JS variables\\n  , s    // (Array) static refs that must be kept alive (SRT)\\n  , m    // GC mark\\n  }\\n```\\n\\n### d1, d2 fields\\n\\nThe d1 and d2 fields contain the payload of the heap object: constructor fields,\\nfunction free variables, etc.\\n\\nPayloads can be composed of zero, one, or many fields. A naive solution would be\\nto have one JS object field (d1, d2, d3...) per payload field. However it would\\nbe bad for two reasons:\\n\\n- performance: JS engine hidden classes optimisation mentioned above needs\\n  objects to have the same field structure.\\n\\n- genericity: we couldn\'t write generic functions (e.g. to copy a closure)\\n  without dynamically querying the number of fields composing the payload.\\n\\n\\nAnother solution would be to use a single field to store the whole payload. It\\nwould fulfill the genericity constraint. However performance may not be good\\nbecause of the extra allocation of the object containing the payload and the\\nindirection to access its fields.\\n\\nInstead GHCJS uses a middle ground approach: it always uses only two JS object\\nfields to store any number of payload fields. The following encoding is used to\\nstash any number of payload fields into two JS fields:\\n\\n| Payload      | d1       | d2                  |\\n|--------------|----------|---------------------|\\n| []           | null     | null                |\\n| [a]          | a        | null                |\\n| [a,b]        | a        | b                   |\\n| [a,b,c]      | a        | {d1=b,d2=c}         |\\n| [a,b,c,d...] | a        | {d1=b,d2=c,d3=d...} |\\n\\nIt still fulfills the genericity constraint and small objects (up to two fields\\nof payload) don\'t pay for an extra allocation/indirection. The price to pay is\\nthat two fields of payload are always allocated, even for for objects with 1\\nfield of payload.\\n\\nIt would be interesting to benchmark the performance of the different payload\\nrepresentations.\\n\\n\\n### m field\\n\\nThe \\"m\\" field is used both for reachability checking (~ garbage collection) and\\nto implement the \\"stable names\\" features.\\n\\nGHCJS can\'t rely on the JS engine to know when a heap object is collected. So it\\nimplements its own heap traversal algorithm for this. The \\"m\\" field is used as a\\nmarker for this algorithm (it will be the topic of a future blog post).\\nIn this case, the \\"m\\" field is a number (a GC mark).\\n\\nWhen a StableName is created for an object, the \\"m\\" field of the object is\\nupdated to point to the StableName object:\\n\\n```javascript\\n[h$StableName]\\n  { m // GC mark\\n  , s // stable name unique id\\n  , ...\\n  }\\n```\\n\\nThe \\"m\\" field of the StableName object is used in replacement of the mark of the object.\\n\\n### cc field\\n\\nThe \\"cc\\" field is the cost center associated to the heap object. This field is\\nonly present when profiling mode is enabled. Cost centers are entered (pushed on\\nthe cost center stack of the current thread) before the evaluation of thunks and\\nfunction applications.\\n\\nCost centers are allocated with the `h$CC` function.\\n\\n\\n## Other heap object representation\\n\\nThe generic heap object representation presented above is only used for some\\nobjects: those involved in graph reduction (e.g. updatable objects) and values\\nthat don\'t have a fixed layout (e.g. CON objects have different layouts\\ndepending on which constructor they represent). The object layout allows generic\\naccess to the infotable and to the payload, and the infotable describes the\\nobject type and the payload layout.\\n\\nSeveral other objects don\'t need this machinery: they always have the same\\nlayout and are never the result of a reduction (they are unlifted values). These\\nobjects are represented as JS objects with any fields they need (i.e. not using\\nthe d1/d2 encoding above). To determine the type of such heap objects, instead\\nof using the \\"type\\" field of an infotable the code uses the `instanceof`\\noperator. For example a TSO is represented as a `h$Thread` object.\\n\\nNote that we could be tempted to give every heap object a different object name\\nand to always use `instanceof` instead of the infotable \\"type\\" properties. It\\nwould mean adding `h$Con`, `h$Thunk`, `h$Fun`, `h$Pap`, `h$Blackhole`, and\\n`h$StackFrame` objects. Then all the heap objects could be treated in the same\\nway. However the isssue is that these objects need to be overwritable in place:\\na Thunk becomes a Fun/Con/Pap/Blackhole, etc. As far as I know we can\'t update\\nthe \\"instance\\" of an object, so all these object have to be instances of\\nthe same JS object.\\n\\nAlso note that the JS backend doesn\'t need INDirection nodes because it can\\nalways overwrite the fields of a JS object with the fields of another to update\\na closure. For the record, indirection nodes are needed in backends that\\nlayout closures as a chunk of bytes/words and when the size of the closure to\\nupdate is smaller than the size of the updatee closure.\\n\\n### Automatic unboxing\\n\\nSometimes the generic heap object representation is unnecessary. For example, a\\nboxed `Int` would be represented as a `CON` heap object with the `Int#` in its\\npayload, represented as a JavaScript number value. The only thing we can do with\\nthis heap object is to pass it around and to extract its payload. As such, it is\\nmore memory efficient to directly pass the payload (a JS number).\\n\\nGHCJS provides an optimisation that consists in automatically unboxing some CON\\nheap objects. For example, Haskell booleans (True and False datacons) are\\ndirectly mapped to JavaScript booleans, boxed numbers (Float, Double, Int, Word,\\nInt8, etc.) are directly mapped to JavaScript numbers.\\n\\nWe can do this because JavaScript already provides some boxing of its own: we\\ncan use the `typeof` operator on a heap object to know if it is a JS object, a\\nJS number, a JS boolean, etc. It makes it possible to distinguish between heap\\nobject representations. In comparison, we can\'t do this with the native (non-JS)\\nbackend when we only have a pointer to a heap object: the pointer doesn\'t carry\\nthe kind of value it points to, hence the pointed memory location must be\\ngeneric enough for this introspection to be performed (e.g. using infotable\\npointers).\\n\\n## Summary\\n\\nHeap object can be represented as JS values (number, boolean) because of the\\nautomatic unboxing, or as JS objects: discimination is done with the `typeof`\\noperator.\\n\\nHeap objects represented as JS objects come in two flavours:\\n- unlifted objects are represented with specific JS objects, disciminated with\\n  the `instanceof` operator\\n- other objects use the following generic and updatable structure:\\n\\n```yaml\\n{ f, d1, d2, m, [cc] }\\n```"},{"id":"2022-08-18-js-backend-ffi","metadata":{"permalink":"/2022-08-18-js-backend-ffi","source":"@site/blog/2022-08-18-ghcjs-ffi.md","title":"GHCJS FFI system in the JS Backend","description":"1.  The Design Space","date":"2022-08-18T00:00:00.000Z","formattedDate":"August 18, 2022","tags":[{"label":"ghc","permalink":"/tags/ghc"},{"label":"javascript","permalink":"/tags/javascript"},{"label":"ffi","permalink":"/tags/ffi"},{"label":"explanation","permalink":"/tags/explanation"},{"label":"knowledge_engineering","permalink":"/tags/knowledge-engineering"}],"readingTime":7.27,"truncated":false,"authors":[{"name":"Jeffrey M. Young","title":"Haskell DevX Engineer @ IOG","url":"https://iog.io/en/","key":"doyougnu"}],"frontMatter":{"slug":"2022-08-18-js-backend-ffi","title":"GHCJS FFI system in the JS Backend","date":"Aug 18, 2022","authors":["doyougnu"],"tags":["ghc","javascript","ffi","explanation","knowledge_engineering"]},"prevItem":{"title":"GHCJS heap representation","permalink":"/2022-09-23-ghcjs-heap-representation"},"nextItem":{"title":"GHC DevX July 2022 Update","permalink":"/2022-08-01-ghc-update"}},"content":"1.  [The Design Space](#orgcf7b9df)\\n2.  [GHCJS&rsquo;s FFI](#orgdca8008)\\n3.  [Lightweight safety checks](#org461ca2a)\\n4.  [Returning multiple values](#orge4568be)\\n5.  [Changes in the FFI System for the JS Backend](#org87ce79c)\\n\\nUsers of GHCJS enjoyed a rich\\n[FFI](https://github.com/ghcjs/ghcjs/blob/master/doc/foreign-function-interface.md)\\nsystem for foreign JavaScript imports. However, this has changed during our\\nadaptation of GHCJS to GHC 9.x. This short post goes over the GHCJS FFI system,\\nthe motivation for these changes and what the changes are. First, we must\\nconsider the design space of an FFI system.\\n\\n\\n<a id=\\"orgcf7b9df\\"></a>\\n\\n# The Design Space\\n\\nFFI code is typically employed in high performance scenarios. Additionally,\\nusers of the FFI *do not* want to deal with the object language the compiler is\\ncompiling to. Instead, users want a simple way to call functions from the object\\nlanguage and use them in their own code as normal Haskell functions. However,\\nusers of the FFI system *do* tend to be power users, and so as a design principle\\nwe want to expose the tools they need to achieve their performance needs,\\nwhatever those needs may be. We can summarize these constraints as follows:\\n\\n1.  The FFI must abstract the JavaScript backend&rsquo;s infidelities away as much as\\n    possible. That is, users of the FFI *should* need to worry about the `Int64#`\\n    representation, but should also be able to simply follow standard patterns we\\n    have written in `base`.\\n2.  The FFI must provide tools to achieve high performance code, even if those\\n    tools require up front knowledge of the runtime system to use. However, these\\n    tools should not be in the path of least resistance to use the FFI system.\\n3.  The FFI must provide a lightweight specification that user&rsquo;s program against\\n    for the JS backend to optimize the imported function and for good error\\n    messages for users.\\n\\nGHCJS&rsquo;s FFI sets a high (qualitative) benchmark on these three constraints.\\nLet&rsquo;s inspect them each in detail, in no particular order.\\n\\n\\n<a id=\\"orgdca8008\\"></a>\\n\\n# GHCJS&rsquo;s FFI\\n\\nIn GHCJS, a user could take advantage of JavaScript functions in their Haskell\\ncode using the GHCJS&rsquo;s FFI. However, the syntax was unique to GHCJS with place\\nholder variables like one might see in perl, nix, or bash. For example, here is\\na foreign import from the `base` library for `st_size`:\\n\\n    -- base/System/Posix/Internal.hs\\n    -- the JS FFI version\\n    foreign import javascript unsafe \\"$r1 = h$base_st_size($1_1,$1_2); $r2 = h$ret1;\\"\\n       st_size :: Ptr CStat -> IO Int64\\n\\nThe syntax is different from what we know and love in the normal Haskell world\\nbut the grammar is straightforward. We declare a `foreign import` from `javascript`,\\nstate that the import is `unsafe` or `interruptible` and then provide a string,\\n`h$base_fstat(...)` for the code generator to use when compiling. Compare this\\nwith the C version:\\n\\n    -- base/System/Posix/Internal.hs\\n    -- the C FFI version\\n    foreign import ccall unsafe \\"HsBase.h __hscore_st_size\\"\\n       st_size :: Ptr CStat -> IO Int64\\n\\nAnd we see that they are similar. The only difference is the strange `$n`\\nsymbols in the referrent string. Contrast this with the C version, which simply\\ndeclares a name.\\n\\nThese symbols are *place holder* variables with special meaning in GHCJS. There\\nare two intractable reasons for the placeholder patterns. First, we require\\nthese patterns to work around the limitations of JavaScript as a backend (1).\\nFor example, consider the case where we need to return an `Int64#` from an\\nimported foreign function. In C and Haskell this is not a problem because both\\ncan represent `Int64#` natively, however JavaScript only has native support for\\n32-bit values. Thus, to be able to return an `Int64#` we need to have a method to\\nreturn two 32-bit numbers. Similarly, in order to apply a function to an `Int64#`\\nthat function must take at least two arguments, one for the high bits and one\\nfor the low. Second, the referrent string is untyped and can contain arbritrary\\nJavaScript code. So placeholder patterns provide a simply and lightweight way\\nfor safety checks and eliminate classes of untyped, hard to understand errors.\\nFor example, consider an arity mismatch error between a function definition and\\ncall site. When this happens JavaScript happily continues processing with the\\nreturn value from the function application defined as `NaN` (of course). Such\\narity conflicts can easily occur, especially when dealing with 64-bit values\\nwhich require function arity assumptions.\\n\\n\\n<a id=\\"org461ca2a\\"></a>\\n\\n# Lightweight safety checks\\n\\nLightweight safety checks (3) are done by GHCJS by parsing the names of the\\nplace holder variables; each of which follows a specific naming convention. This\\nconvention is:\\n\\n-   Argument types:\\n    -   `$n`: Used for unary arguments, i.e., arguments which require only a single register.\\n    -   `$n_n`: Used for binary arguments, i.e., arguments which require two registers.\\n    -   `$c`: A continuation argument, only valid for `interruptible` foreign functions.\\n-   Return types:\\n    -   `$r`: a unary return\\n    -   `$r1`, `$r2`: a binary return\\n    -   `$r1`, `$r2`, `$r3_1`, `$r3_2`: unboxed tuple return\\n-   Top level patterns:\\n    -   `\\"&value\\"`: simply emitted as `value` by the code generator\\n    -   `\\"someFunction\\"`: emitted as `ret = someFunction(...)`, i.e., map the FFI to\\n        the result of the function call.\\n    -   `\\"$r = $1.f($2)\\"`: emitted as `r1 = a1.f(a2)`, i.e., a combination of a\\n        function call and a property access.\\n\\nWith this standard GHCJS then parses the FFI referrent string to ensure that it\\nconforms to this standard. If not then GHCJS can at least respond to the user\\nwith an ill-formatted FFI message *and* say precisely where the issue is. For\\nexample, it could respond that only half of an `Int64#` is returned based on the\\nreferrent string and the function type.\\n\\n\\n<a id=\\"orge4568be\\"></a>\\n\\n# Returning multiple values\\n\\nBut what of performant code? GHCJS achieves performant FFI by not trying to\\nabstract away from the runtime system. Instead, an advantage of GHCJS&rsquo;s FFI *is*\\nthat we can specify exactly which registers the foreign function should dump its\\nresults or even arbitrary global variables. This places more burden on the user\\nof the FFI in specific scenarios, but crucially allows the FFI system to get out\\nof the way of the user. The FFI system also exploits this capability to return\\nmultiple values from a single function call, which is a common need when\\ncompiling to JavaScript. For example, in the above code `st_size` is declared to\\nreturn an `IO Int64`, the JavaScript handler `h$base_st_size` returns the `Int64`\\nusing two registers `$r1` and `$r2`, but does so through the use of a special\\npurpose global variable called `h$ret1`:\\n\\n    function h$base_st_size(stat, stat_off) {\\n        h$ret1 = (stat.i3[(stat_off>>2)+2]);\\n        return (stat.i3[(stat_off>>2)+1]);\\n    }\\n\\nThe function inputs a pointer and an offset. Pointers in GHCJS are simply\\npointers to ByteArrays so the function indexes into the ByteArray and retrieves\\nand stores the lower 32-bits in `h$ret1`, then returns the higher 32-bits\\ndirectly. These results are picked up by the FFI code, which performs assignment\\nto set `$r1` to the result of the function call (the higher 32-bits), and set `$r2`\\nto the value of `h$ret1` (the lower 32-bits). Crucially, the runtime system needs\\nto do nothing. The registers are already handled ready to be consumed by\\nwhatever the caller of the foreign function will do.\\n\\nOne might consider using a simpler design, which trades register juggling for a\\nmore straightforward representation such as a ByteArray which stores the `Int64#`.\\nHowever, such a design would trade speed for implementation simplicity. If we\\npassed ByteArrays then each foreign function would spend time wrapping and\\nunwrapping the array to get the payload; clearly an undesirable outcome for high\\nperformance code.\\n\\n\\n<a id=\\"org87ce79c\\"></a>\\n\\n# Changes in the FFI System for the JS Backend\\n\\nSo we see that GHCJS&rsquo;s FFI system actually performs quite well in the design\\nspace. Power users are well supported and can leverage enough unsafety to bind\\nglobal variables like `h$ret1` and specific registers such as `$r1`. The system\\nprovides some lightweight checking through parsing. The nuances of the\\nJavaScript platform are generally abstracted over and the FFI system is tuned\\nfor performance critical scenarios. So why change it?\\n\\nThe short answer is to hit deadlines. By skipping the FFI parsing the JS Backend\\nteam was able to produce a working (can output &ldquo;Hello World!&rdquo;, and compile GHC&rsquo;s\\nboot libraries), integrated, JS backend in GHC faster than had we finished the\\nFFI system.\\n\\nFor the time being, we have opted to replaced each foreign function call with a\\nJavaScript fat arrow, for example:\\n\\n    foreign import javascript unsafe \\"(($1_1,$1_2) => { return h$base_st_size($1_1,$1_2); })\\"\\n       st_size :: Ptr CStat -> IO Int64\\n\\n Of course, this situation is untenable, as argued above, FFI code is assumed to\\nbe used in performance critical code, and thus any extra overhead, such as a\\nfunction closure and consequent indirection, must be avoided. But fear not! In\\nthe near future we&rsquo;ll be overhauling the FFI system and returning it to its\\nformer glory."},{"id":"2022-08-01-ghc-update","metadata":{"permalink":"/2022-08-01-ghc-update","source":"@site/blog/2022-08-01-ghc-update-2022-07.md","title":"GHC DevX July 2022 Update","description":"This is the July 2022 monthly update from the GHC DevX team at IOG.","date":"2022-08-01T00:00:00.000Z","formattedDate":"August 1, 2022","tags":[{"label":"ghc","permalink":"/tags/ghc"},{"label":"ghc-update","permalink":"/tags/ghc-update"}],"readingTime":1.25,"truncated":false,"authors":[{"name":"Sylvain Henry","title":"Haskell DevX Engineer @ IOG","email":"sylvain.henry@iohk.io","key":"sylvain"}],"frontMatter":{"slug":"2022-08-01-ghc-update","title":"GHC DevX July 2022 Update","authors":["sylvain"],"tags":["ghc","ghc-update"]},"prevItem":{"title":"GHCJS FFI system in the JS Backend","permalink":"/2022-08-18-js-backend-ffi"},"nextItem":{"title":"The GHCJS Linker","permalink":"/2022-07-26-the-ghcjs-linker"}},"content":"This is the July 2022 monthly update from the GHC DevX team at IOG.\\n\\n## JavaScript Backend for GHC\\n\\nFor a few months we have been merging GHCJS (Haskell to JavaScript compiler)\\ninto GHC. We set our first milestone to be the ability to compile and to run the\\nusual \\"Hello World\\" program. This month we finally reached it!\\n\\nWe are now focusing on:\\n\\n- fixing failing tests in GHC\'s testsuite (~2800 unexpected failures). To do that, we\\n  have to implement new primops, to fix bugs we introduced while we ported the\\n  code from GHCJS, etc.\\n\\n- implementing support for the \\"js-sources\\" Cabal stanza in Hadrian. Currently\\n  the JS backend finds the JS sources required for the RTS and for base into\\n  explicitly defined location. It was only a stop-gap measure and we now need to\\n  implement proper support for user-provided JavaScript files.\\n\\n- documenting and refactoring the source code and making it similar to other GHC\\n  modules. As an example, GHCJS used the text package which isn\'t a boot\\n  package. Hence we first switched to use GHC\'s ShortText implementation and now\\n  we switched to a FastString based implementation.\\n\\n- adding back GHCJS\'s features that we haven\'t ported for some reasons (e.g. the\\n  compactor, TH, etc.).\\n\\nYou can follow our progress on our development branch\\n[here](https://gitlab.haskell.org/ghc/ghc/-/tree/wip/js-staging).\\n\\n## Blog posts\\n\\nFor the time being, we will focus blog post topics on GHCJS internals and\\nrelated topics. A few of these blog posts are currently under review and should\\nbe published shortly."},{"id":"2022-07-26-the-ghcjs-linker","metadata":{"permalink":"/2022-07-26-the-ghcjs-linker","source":"@site/blog/2022-07-26-ghcjs-linker.md","title":"The GHCJS Linker","description":"Introduction","date":"2022-07-26T00:00:00.000Z","formattedDate":"July 26, 2022","tags":[{"label":"ghc","permalink":"/tags/ghc"},{"label":"javascript","permalink":"/tags/javascript"},{"label":"linking","permalink":"/tags/linking"}],"readingTime":5.125,"truncated":false,"authors":[{"name":"Luite Stegeman","title":"Haskell DevX Engineer @ IOG","email":"luite.stegeman@iohk.io","key":"luite"}],"frontMatter":{"slug":"2022-07-26-the-ghcjs-linker","title":"The GHCJS Linker","date":"July 26, 2022","authors":["luite"],"tags":["ghc","javascript","linking"]},"prevItem":{"title":"GHC DevX July 2022 Update","permalink":"/2022-08-01-ghc-update"},"nextItem":{"title":"Primitive Type Representation in GHC\'s upcoming JS-backend","permalink":"/2022-07-20-js-backend-prim-types"}},"content":"## Introduction\\n\\nI recently gave a short presentation on the workings of the GHCJS linker. This post is a summary of the content.\\n\\n## JavaScript \\"executables\\"\\n\\nThe task of a linker is collecting and organizing object files and resources into a loadable library or executable program. JavaScript can be run in various environments, for example the browser or node.js, and not in all of these the concept of an executable makes sense.\\n\\nTherefore, when we link a Haskell program, we generate a `jsexe` directory filled with various files that allow us to run the JavaScript result:\\n\\n| File        | Description          |\\n| :----:        | :---:             |\\n| `out.js`      | compiled/linked Haskell code          |\\n| `out.frefs.*` | list of foreign calls from `out.js` |\\n| `out.stats`   | source code size origin statistics for `out.js` |\\n| `lib.js`      | non-Haskell code, from `js-sources` in packages and RTS. possibly preprocessed |\\n| `rts.js`      | generated part of RTS (apply functions and similarly repetitive things) |\\n| `runmain.js`  | single line just starts `main` |\\n| `all.js`      | complete runnable program, created by combining `out.js`, `lib.js`, `rts.js` and `runmain.js` |\\n\\nMost of the work done by the linker is producing `out.js`, and that\'s what we\'ll be focusing on in the next sections.\\n\\n## Building `out.js`\\n\\nThe linker builds `out.js` by collecting all code reachable from `main` (and a few other symbols required by the RTS) and generating the required initialization code for all top-level data. The code is found in object files. These object files have the following structure:\\n\\n| Section        | Description          |\\n| :----:        | :---:             |\\n| Header       | version number and offsets of other sections       |\\n| String table | shared string table, referred to by `Dependencies` and `Code`, to avoid duplication in file and memory |\\n| Dependencies | Dependency data, internally between binding groups and externally to symbols in other object files |\\n| Code         | Compiled Haskell code stored as serialized JavaScript AST and metadata. Code is organized in binding groups |\\n\\nThe object files contain binding groups of mutually dependent bindings. These are the smallest units of code that can be linked. Each binding group has some associated metadata required for initialization of the heap objects in the group. The metadata contains for example constructor tags (e.g. 1 for `Nothing`, 2 for `Just`), the arity of functions and static reference tables.\\n\\nFrom a high level, the procedure that the linker follows is this:\\n\\n| Step |\\n| :---: |\\n| Read object files from dependencies into memory |\\n| Decode dependency part of all object files in dependencies (includes reading the string tables) |\\n| Using dependency data, find all code reachable from `main` |\\n| Decode reachable binding groups |\\n| Render AST to JavaScript |\\n| Construct initializers from metadata | \\n\\nWe avoid decoding (deserializing) the binding groups that do end up in the linked result to keep the memory consumption lower. Still the linker requires a lot of memory for larger programs, so we may need to make more improvements in the future.\\n\\n## The Compactor\\n\\nThe compactor is an optional link-time transformation step that reduces code size. It consists of a lightweight (i.e. no expensive operations like dataflow analysis) rewrite of the code contained in the object files. The compactor is disabled when linking with the `-debug` flag. There are a few steps involved.\\n\\n### Renaming private symbols\\n\\nHaskell names are quite long by default: they need to be globally unique, hence they contain their defining unit-id and module name. For example: `mtl-2.2.2-somehash-Control.Monad.State.Lazy.execState_go1` (special characters would be z-encoded but it isn\'t shown here).\\n\\nPrivate symbols are only referred to from within the same module. It doesn\'t matter which JavaScript name we pick for them, as long as there is no overlap between the names from different modules. The compactor renames all the private symbols using a global sequence to ensure short names that do not overlap.\\n\\n### Block Initializer\\n\\nWithout the compactor, the linker generates an `h$initObj` initialization call (or `h$o`) call for each global Haskell heap value. The code for this can get quite big. The compactor collects all heap objects to be initialized in a single large array and encodes the metadata in a string. This makes the initialization code much more compact.\\n\\n### Deduplication\\n\\nAn optional step in the compactor is deduplication of code. When deduplication is enabled with the `-dedupe` flag, the compactor looks for functionally equivalent pieces of JavaScript in the output and merges them. This can result in a significant reduction of code size.\\n\\n## Incremental Linking\\n\\nThe linker supports building programs that are loaded incrementally. This is used for example for Template Haskell. The process that runs the Template Haskell stays alive during compilation of a whole module. When the first Template Haskell expression is compiled, it is linked against all its dependencies (including the RTS) and the resulting JavaScript code is sent over to be run in the evaluator process.\\n\\nAs subsequent Template Haskell expressions are evaluated in the same process, there is no need to load already loaded dependencies (including the RTS) again and it is much more efficient to avoid doing so. Therefore the linker keeps track of which dependencies have already been linked and each subsequent TH expression is only linked against dependencies that are not already loaded in the evaluator process.\\n\\nIt\'s also possible for users to use this functionality directly, with the `-generate-base` to create a \\"linker state\\" file along with the regular `jsexe` files. Another program can then be linked with `-use-base=state_file`, resulting in a program which leaves out everything already present in the first program.\\n\\n## Future Improvements\\n\\nMemory consumption is the biggest problem in the linker at the moment. Possible ways to achieve this are compression, more efficient representation of the data structures or more incremental loading of the parts from the object files that we need.\\n\\nIn terms of functionality, we don\'t take advantage of JavaScript modules yet. It would be good if we could improve the linker to support linking a library as a JavaScript module. We should also consider making use of `foreign export javascript` for this purpose."},{"id":"2022-07-20-js-backend-prim-types","metadata":{"permalink":"/2022-07-20-js-backend-prim-types","source":"@site/blog/2022-07-20-js-backend-prim-types.md","title":"Primitive Type Representation in GHC\'s upcoming JS-backend","description":"1.  GHC Primitives","date":"2022-07-20T00:00:00.000Z","formattedDate":"July 20, 2022","tags":[{"label":"ghc","permalink":"/tags/ghc"},{"label":"javascript","permalink":"/tags/javascript"},{"label":"explanation","permalink":"/tags/explanation"},{"label":"knowledge_engineering","permalink":"/tags/knowledge-engineering"}],"readingTime":10.455,"truncated":false,"authors":[{"name":"Jeffrey M. Young","title":"Haskell DevX Engineer @ IOG","url":"https://iog.io/en/","key":"doyougnu"},{"name":"Sylvain Henry","title":"Haskell DevX Engineer @ IOG","email":"sylvain.henry@iohk.io","key":"sylvain"}],"frontMatter":{"slug":"2022-07-20-js-backend-prim-types","title":"Primitive Type Representation in GHC\'s upcoming JS-backend","date":"July 20, 2022","authors":["doyougnu","sylvain"],"tags":["ghc","javascript","explanation","knowledge_engineering"]},"prevItem":{"title":"The GHCJS Linker","permalink":"/2022-07-26-the-ghcjs-linker"},"nextItem":{"title":"Lightweight Haskell Threads on JavaScript","permalink":"/2022-07-18-lightweight-threads-on-JavaScript"}},"content":"1.  [GHC Primitives](#orge86cd4a)\\n    1.  [The Easy Cases](#org75a0c27)\\n    2.  [ByteArray#, MutableByteArray#, SmallArray#, MutableSmallArray#,](#org5eb1aee)\\n    3.  [Addr# and StablePtr#](#org0de7f9e)\\n    4.  [Numbers: The Involved Case](#orgfa8aeb4)\\n        1.  [Working with 64-bit Types](#orgc9d245e)\\n        2.  [Unwrapped Number Optimization](#org453f9cc)\\n    5.  [But what about the other stuff!](#org2e2e79e)\\n\\nOne of the key challenges in any novel backend is representing GHC primitive\\ntypes in the new backend. For JavaScript, this is especially tricky, as\\nJavaScript only has 8 primitive types and some of those types, such as `number` do\\nnot directly map to any Haskell primitive type, such as `Int8#`. This post walks\\nthrough the most important GHC primitives and describes our implementation for\\neach in the JavaScript backend. This post is intended to be an\\nexplanation-oriented post, light on details, but just enough to understand how\\nthe system works.\\n\\n\\n<a id=\\"orge86cd4a\\"></a>\\n\\n# GHC Primitives\\n\\nThere are 36 `primtype`s that GHC defines in `primops.txt.pp`:\\n\\n1.  `Char#`\\n2.  `Int8#`, `Int16#`, `Int32#`, `Int64#`, `Int#`\\n3.  `Word8#`, `Word16#`, `Word32#`, `Word64#`, `Word#`\\n4.  `Double#`, `Float#`,\\n5.  `Array#`, `MutableArray#`,, `SmallArray#`, `SmallMutableArray#`\\n6.  `ByteArray#`, `MutableByteArray#`\\n7.  `Addr#`\\n8.  `MutVar#`, `TVar#`, `MVar#`,\\n9.  `IOPort#`, `State#`, `RealWorld`, `ThreadId#`\\n10. `Weak#`, `StablePtr#`, `StableName#`, `Compact#`, `BCO`,\\n11. `Fun`, `Proxy#`\\n12. `StackSnapshot#`\\n13. `VECTOR`\\n\\nSome of these are unsupported in the JS-backend, such as `VECTOR` or lower\\npriority such as `StackSnapshot#`. We&rsquo;ll begin with the easy cases.\\n\\n\\n<a id=\\"org75a0c27\\"></a>\\n\\n## The Easy Cases\\n\\nThe easy cases are the cases that are implemented as JavaScript objects. In\\ngeneral, this is the big hammer used when nothing else will do. We&rsquo;ll expand on\\nthe use of objects&#x2014;especially representing heap objects&#x2014;in a future post,\\nbut for the majority of cases we mimic the STG-machine behavior for GHC heap\\nobjects using JavaScript heap objects. For example,\\n\\n    var someConstructor =\\n        { f  =                   // entry function of the datacon worker\\n        , m  = 0                 // garbage collector mark\\n        , d1 = first arg         // First data field for the constructor\\n        , d2 = arity = 2: second arg // second field, or object containing the remaining fields\\n               arity > 2: { d1, d2, ...} object with remaining args (starts with \\"d1 = x2\\"!)\\n        }\\n\\nThis is the general recipe; we define a JavaScript object that contains\\nproperties which correspond to the entry function of the heap object; in this\\ncase that is the entry function, `f` for a constructor, some meta data for garbage\\ncollection `m`, and pointers to the fields of the constructor or whatever else the\\nheap object might need. Using JavaScript objects allows straightforward\\ntranslations of several GHC types. For example `TVar`s and `MVar`s:\\n\\n    // stg.js.pp\\n    /** @constructor */\\n    function h$TVar(v) {\\n        TRACE_STM(\\"creating TVar, value: \\" + h$collectProps(v));\\n        this.val        = v;           // current value\\n        this.blocked    = new h$Set(); // threads that get woken up if this TVar is updated\\n        this.invariants = null;        // invariants that use this TVar (h$Set)\\n        this.m          = 0;           // gc mark\\n        this._key       = ++h$TVarN;   // for storing in h$Map/h$Set\\n    #ifdef GHCJS_DEBUG_ALLOC\\n        h$debugAlloc_notifyAlloc(this);\\n    #endif\\n    }\\n\\n    // stm.js.pp\\n    function h$MVar() {\\n      TRACE_SCHEDULER(\\"h$MVar constructor\\");\\n      this.val     = null;\\n      this.readers = new h$Queue();\\n      this.writers = new h$Queue();\\n      this.waiters = null;  // waiting for a value in the MVar with ReadMVar\\n      this.m       = 0; // gc mark\\n      this.id      = ++h$mvarId;\\n    #ifdef GHCJS_DEBUG_ALLOC\\n      h$debugAlloc_notifyAlloc(this);\\n    #endif\\n    }\\n\\nNotice that both implementations defined properties specific to the semantics of\\nthe Haskell type. JavaScript functions which create these objects follow the\\nnaming convention `h$<something>` and reside in *Shim* files. *Shim* files are\\nJavaScript files that the JS-backend links against and are written in pure\\nJavaScript. This allows us to save some compile time by not generating code\\nwhich doesn&rsquo;t change, and decompose the backend into JavaScript modules.\\n\\nThis strategy is also how functions are implemented in the JS-backend. Function\\nobjects are generated by `StgToJS.Expr.genExpr` and `StgToJS.Apply.genApp` but\\nfollow this recipe:\\n\\n    var myFUN =\\n     { f  = <function itself>\\n     , m  = <garbage collector mark>\\n     , d1 = free variable 1\\n     , d2 = free variable 2\\n     }\\n\\nTo summarize; for most cases we write custom JavaScript objects which hold\\nwhatever machinery is needed as properties to satisfy the expected semantics of\\nthe Haskell type. This is the strategy that implements: `TVar`, `MVar`, `MutVar` and\\n`Fun`.\\n\\n\\n<a id=\\"org5eb1aee\\"></a>\\n\\n## ByteArray#, MutableByteArray#, SmallArray#, MutableSmallArray#,\\n\\n`ByteArray#` and friends map to JavaScript\'s\\n[`ArrayBuffer`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/ArrayBuffer)\\nobject. The `ArrayBuffer` object provides a fixed-length, raw binary data\\nbuffer. To index into the `ArrayBuffer` we need to know the type of data the\\nbuffer is expected to hold. So we make engineering tradeoff; we allocate typed\\nviews of the buffer payload once at buffer allocation time. This prevents\\nallocations from views later when we might be handling the buffer in a hot loop,\\nat the cost of slower initialization. For example, consider the `mem.js.pp`\\nshim, which defines `ByteArray#`:\\n\\n    // mem.js.pp\\n    function h$newByteArray(len) {\\n      var len0 = Math.max(h$roundUpToMultipleOf(len, 8), 8);\\n      var buf = new ArrayBuffer(len0);\\n      return { buf: buf\\n             , len: len\\n             , i3: new Int32Array(buf)\\n             , u8: new Uint8Array(buf)\\n             , u1: new Uint16Array(buf)\\n             , f3: new Float32Array(buf)\\n             , f6: new Float64Array(buf)\\n             , dv: new DataView(buf)\\n             , m: 0\\n             }\\n    }\\n\\n `buf` is the payload of the `ByteArray#`, `len` is the length of the\\n`ByteArray#`. `i3` to `dv` are the _views_ of the payload; each view is an\\nobject which interprets the raw data in `buf` differently according to type. For\\nexample, `i3` interprets `buf` as holding `Int32`, while `dv` interprets `buf`\\nas a\\n[`DataView`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/DataView)\\nand so on. The final property, `m`, is the garbage collector marker.\\n\\n\\n<a id=\\"org0de7f9e\\"></a>\\n\\n## Addr# and StablePtr#\\n\\n`Addr#` and `StablePtr#` are implemented as a pair of `ByteArray#` and an `Int#`\\noffset into the array. We&rsquo;ll focus on `Addr#` because `StablePtr#` is the\\nsame implementation, with the exception that the `StablePtr#` is tracked in the\\nglobal variable `h$stablePtrBuf`. `Addr#`s do not have an explicit constructor,\\nrather they are implicitly constructed. For example, consider `h$rts_mkPtr`\\nwhich creates a `Ptr` that contains an `Addr#`:\\n\\n    function h$rts_mkPtr(x) {\\n      var buf, off = 0;\\n      if(typeof x == \'string\') {\\n    \\n        buf = h$encodeUtf8(x);\\n        off = 0;\\n      } else if(typeof x == \'object\' &&\\n         typeof x.len == \'number\' &&\\n         x.buf instanceof ArrayBuffer) {\\n    \\n        buf = x;\\n        off = 0;\\n      } else if(x.isView) {\\n    \\n        buf = h$wrapBuffer(x.buffer, true, 0, x.buffer.byteLength);\\n        off = x.byteOffset;\\n      } else {\\n    \\n        buf = h$wrapBuffer(x, true, 0, x.byteLength);\\n        off = 0;\\n      }\\n      return (h$c2(h$baseZCGHCziPtrziPtr_con_e, (buf), (off)));\\n    }\\n\\nThe function does some type inspection to check for the special case on\\n`string`. If we do not have a string then a `Ptr`, which contains an `Addr#`, is\\nreturned. The `Addr#` is implicitly constructed by allocating a new\\n`ArrayBuffer` and an offset into that buffer. The `object` case is an idempotent\\ncheck; if the input is already such a `Ptr`, then just return the input. The\\ncases which do the work are the cases which call to `h$wrapBuffer`:\\n\\n    // mem.js.pp\\n    function h$wrapBuffer(buf, unalignedOk, offset, length) {\\n      if(!unalignedOk && offset && offset % 8 !== 0) {\\n        throw (\\"h$wrapBuffer: offset not aligned:\\" + offset);\\n      }\\n      if(!buf || !(buf instanceof ArrayBuffer))\\n        throw \\"h$wrapBuffer: not an ArrayBuffer\\"\\n      if(!offset) { offset = 0; }\\n      if(!length || length < 0) { length = buf.byteLength - offset; }\\n      return { buf: buf\\n             , len: length\\n             , i3: (offset%4) ? null : new Int32Array(buf, offset, length >> 2)\\n             , u8: new Uint8Array(buf, offset, length)\\n             , u1: (offset%2) ? null : new Uint16Array(buf, offset, length >> 1)\\n             , f3: (offset%4) ? null : new Float32Array(buf, offset, length >> 2)\\n             , f6: (offset%8) ? null : new Float64Array(buf, offset, length >> 3)\\n             , dv: new DataView(buf, offset, length)\\n             };\\n    }\\n\\n`h$wrapBuffer` is a utility function that does some offset checks and performs\\nthe allocation for the typed views as described above.\\n\\n\\n<a id=\\"orgfa8aeb4\\"></a>\\n\\n## Numbers: The Involved Case\\n\\nTranslating numbers has three issues. First, JavaScript has no concept of\\nfixed-precision 64-bit types such as `Int64#` and `Word64#`. Second, JavaScript\\nbitwise operators only support _signed_ 32-bit values (except the unsigned\\n[right\\nshift](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Unsigned_right_shift)\\noperator of course). Third, numbers are atomic types and do not require any\\nspecial properties for correct semantics, thus using wrapping objects gains us\\nnothing at the cost of indirection.\\n\\n\\n<a id=\\"orgc9d245e\\"></a>\\n\\n### Working with 64-bit Types\\n\\nTo express 64-bit numerics, we simply use two 32-bit numbers, one to express\\nthe high bits, one for the low bits. For example, consider comparing two `Int64#:`\\n\\n    // arith.js.pp\\n    function h$hs_ltInt64(h1,l1,h2,l2) {\\n      if(h1 === h2) {\\n        var l1s = l1 >>> 1;\\n        var l2s = l2 >>> 1;\\n        return (l1s < l2s || (l1s === l2s && ((l1&1) < (l2&1)))) ? 1 : 0;\\n      } else {\\n        return (h1 < h2) ? 1 : 0;\\n      }\\n    }\\n\\nThe less than comparison function expects four inputs, two for each `Int64#` in\\nHaskell. The first number is represented by `h1` and `l1` (*high* and *low*),\\nand similarly the second number is represented by `h2` and `l2`. The comparison\\nis straightforward, we check equivalence of our high bits, if equal then we\\ncheck the lower bits while being careful with signedness. No surprises here.\\n\\nFor the bitwise operators we store both `Word32#` and `Word#` as 32-bit signed\\nvalues, and then map any values greater or equal `2^31` bits to negative values.\\nThis way we stay within the 32-bit range even though in Haskell these types only\\nsupport nonnegative values.\\n\\n\\n<a id=\\"org453f9cc\\"></a>\\n\\n### Unwrapped Number Optimization\\n\\nThe JS backend uses JavaScript values to represent both Haskell heap objects and\\nunboxed values (note that this isn\'t the only possible implementation, see\\n[^1]). As such, it doesn\'t require that all heap objects have the same\\nrepresentation (e.g. a JavaScript object with a \\"tag\\" field indicating its type)\\nbecause we can rely on JS introspection for the same purpose (especially\\n`typeof`). Hence this optimization consists in using a more efficient JavaScript\\ntype to represent heap objects when possible, and to fallback on the generic\\nrepresentation otherwise.\\n\\nThis optimization particularly applies to `Boxed` numeric values (`Int`, `Word`,\\n`Int8`, etc.) which can be directly represented with a JavaScript number,\\nsimilarly to how unboxed `Int#`, `Word#`, `Int8#`, etc. values are represented.\\n\\nPros:\\n\\n- Fewer allocations and indirections: instead of one JavaScript object with a\\n  field containing a number value, we directly have the number value.\\n\\nCons:\\n\\n- More complex code to deal with heap objects that can have different\\n  representations\\n\\nThe optimization is applicable when:\\n\\n1.  We have a single data type with a single data constructor.\\n2.  The constructor holds a single field that *can only* be a particular type.\\n\\nIf these invariants hold then, we remove the wrapping object and instead refer\\nto the value held by the constructor directly. `Int8` is the simplest case for\\nthis optimization. In Haskell we have:\\n\\n    data Int8 = Int8 Int8#\\n\\nNotice that this definition satisfies the requirements. A direct translation in\\nthe JS backend would be:\\n\\n    // An Int8 Thunk represented as an Object with an entry function, f\\n    // and payload, d1.\\n    var anInt8 = { d1 = <Int8# payload>\\n                 , f  : entry function which would scrutinize the payload\\n                 }\\n\\nWe can operationally distinguish between a `Thunk` and an `Int8` because these\\nwill have separate types in the `StgToJS` GHC pass and will have separate types\\n(`object` vs `number`) at runtime. In contrast, in Haskell an `Int8` may\\nactually be a `Thunk` until it is scrutinized *and then* becomes the `Int8`\\npayload (i.e., call-by-need). So this means that we will always know when we\\nhave an `Int8` rather than a `Thunk` and therefore we can omit the wrapper\\nobject and convert this code to just:\\n\\n    // no object, just payload\\n    var anInt8 = = <Int8# payload>\\n\\nFor the interested reader, this optimization takes place in the JavaScript code\\ngenerator module `GHC.StgToJS.Arg`, specifically the functions `allocConStatic`,\\n`isUnboxableCon`, and `primRepVt`.\\n\\n\\n<a id=\\"org2e2e79e\\"></a>\\n\\n## But what about the other stuff!\\n\\n-   `Char#`: is represented by a `number`, i.e., the [code point](https://en.wikipedia.org/wiki/Code_point)\\n-   `Float#/Double#`: Both represented as a JavaScript Double. This means that\\n    `Float#` has excess precision and thus we do not generate exactly the same\\n    answers as other platforms which are IEEE754 compliant. Full emulation of\\n    single precision Floats does not seem to be worth the effort as of writing.\\n    Our implementation represents these in a `ByteArray#`, where each `Float#`\\n    takes 4 bytes in the `ByteArray#`. This means that the precision is reduced\\n    to a 32-bit Float.\\n\\n[^1]: An alternative approach would be to use some JS ArrayBuffers as memory\\n    blocks into which Haskell values and heap objects would be allocated. As an\\n    example this is the approach used by the Asterius compiler. The RTS would\\n    then need to be much more similar to the C RTS and the optimization\\n    presented in this section wouldn\'t apply because we couldn\'t rely on\\n    introspection of JS values."},{"id":"2022-07-18-lightweight-threads-on-JavaScript","metadata":{"permalink":"/2022-07-18-lightweight-threads-on-JavaScript","source":"@site/blog/2022-07-18-ghcjs-threads.md","title":"Lightweight Haskell Threads on JavaScript","description":"Introduction","date":"2022-07-18T00:00:00.000Z","formattedDate":"July 18, 2022","tags":[{"label":"ghc","permalink":"/tags/ghc"},{"label":"javascript","permalink":"/tags/javascript"},{"label":"concurrency","permalink":"/tags/concurrency"},{"label":"ffi","permalink":"/tags/ffi"}],"readingTime":3.915,"truncated":false,"authors":[{"name":"Luite Stegeman","title":"Haskell DevX Engineer @ IOG","email":"luite.stegeman@iohk.io","key":"luite"}],"frontMatter":{"slug":"2022-07-18-lightweight-threads-on-JavaScript","title":"Lightweight Haskell Threads on JavaScript","date":"July 18, 2022","authors":["luite"],"tags":["ghc","javascript","concurrency","ffi"]},"prevItem":{"title":"Primitive Type Representation in GHC\'s upcoming JS-backend","permalink":"/2022-07-20-js-backend-prim-types"},"nextItem":{"title":"GHC DevX June 2022 Update","permalink":"/2022-07-01-ghc-update"}},"content":"## Introduction\\n\\nI recently gave a short presentation on the topic of threads in GHCJS to the GHC team at IOG. This blog post is a summary of the content.\\n\\n## JavaScript and Threads\\n\\nJavaScript is fundamentally single threaded. There are ways to share specific data between tasks but it\'s not possible to run multiple threads that have access to a shared memory space of JavaScript data.\\n\\nThe single JavaScript thread is often responsible for multiple tasks. For example a node.js server handles multiple simultaneous connections and a web application may be dealing with user input while downloading new data in the background.\\n\\nThis means that any single task should take care to never block execution of the other task. JavaScript\'s canonical answer is to use asynchronous programming. A function reading a file returns immediately without waiting for the file data to be loaded in memory. When the data is ready, a user-supplied callback is called to continue processing the data.\\n\\n## Haskell Threads\\n\\nConcurrent Haskell supports lightweight threads through `forkIO`. These threads are scheduled on top of one more more operating system thread. A blocking foreign call blocks an OS thread but other lightweight threads can still run on other OS threads if available.\\n\\nThere is no built-in support for foreign calls with a callback in the style of JavaScript. Functions imported with `foreign import ccall interruptible` can be interrupted by sending an asynchronous exception to the corresponding lightweight thread.\\n\\n## Lightweight Threads in JavaScript\\n\\nGHCJS implements lightweight threads on top of the single JavaScript thread. The scheduler switches between threads and handles synchronization through `MVar` and `STM` as expected from other Haskell platforms.\\n\\nForeign calls that don\'t block can be handled in the usual way. We extend the foreign function interface with a new type `foreign import javascript interruptible` that conveniently supports the callback mechanism used by JavaScript frameworks. The foreign call is supplied with an additional argument `$c` representing a callback to be called with the result when ready. From the Haskell side the corresponding lightweight thread is blocked until `$c` is called. This type of foreign call can be interrupted with an asynchronous exception to the lightweight Haskell thread.\\n\\nBy default, Haskell threads in the JS environment run asynchronously. A call to `h$run` returns immediately and starts the thread in the background. This works for tasks that does not require immediate actions. For situations that require more immediate action, such as dealing with event handler propagation, there is `h$runSync`. This starts a synchronous thread that is not interleaved with other task. If possible, the thread runs to completion before the call to `h$runSync` returns. If the thread blocks for any reason, such as waiting for an `MVar` or a `foreign import javascript interruptible` call, synchronous execution cannot complete. The blocking task is then either interrupted with an exception or the thread is \\"demoted\\" to a regular asynchronous thread.\\n\\n## Black Holes\\n\\nWhen a Haskell value is evaluated, its heap object is overwritten by a black hole. This black hole marks the value as being evaluated and prevents other threads from doing the same. \\"black holing\\" can be done either immediately or \\"lazily\\", when the garbage collector is run. GHCJS implements immediate blackholing.\\n\\nBlack holes give rise to an interesting problem in the presence of synchronous and asynchronous threads. Typically if we use `h$runSync`, we want to have some guarantee that at least part of the task will run succesfully without blocking. For the most past it\'s fairly clear which parts of our task depends on potentially blocking IO or thread synchronization. But black holes throw a spanner in the works: Suddenly any \\"pure\\" data structure can be a source of blocking if it is under evaluation by another thread.\\n\\nTo regain some predictability and usability of synchronous threads, the `h$runSync` scheduler can run other Haskell threads in order to \\"clear\\" a black hole. The process ends all black holes have been cleared or when any of the black holes is impossible to clear because of a blocking situation.\\n\\nThis all happens transparantly to the caller of `h$runSync`, if the black holes could be cleared it appears as if they were never there.\\n\\n## Conclusion\\n\\nWe have lightweight Haskell threads in the single-threaded JavaScript environment and extend the foreign function interface to easily support foreign calls that depend on an asynchronous callback. This way, only the Haskell lightweight thread blocks.\\n\\nBy default, Haskell threads are asynchronous and run in the background: The scheduler interleaves the tasks and synchronization between threads. For situations that require immediate results or actions there are synchronous threads. Synchronous threads cannot block and are not interleaved with other tasks except when a black hole is encountered."},{"id":"2022-07-01-ghc-update","metadata":{"permalink":"/2022-07-01-ghc-update","source":"@site/blog/2022-07-01-ghc-update-2022-06.md","title":"GHC DevX June 2022 Update","description":"This is the June 2022 monthly update from the GHC DevX team at IOG.","date":"2022-07-01T00:00:00.000Z","formattedDate":"July 1, 2022","tags":[{"label":"ghc","permalink":"/tags/ghc"},{"label":"ghc-update","permalink":"/tags/ghc-update"}],"readingTime":1.635,"truncated":false,"authors":[{"name":"Sylvain Henry","title":"Haskell DevX Engineer @ IOG","email":"sylvain.henry@iohk.io","key":"sylvain"}],"frontMatter":{"slug":"2022-07-01-ghc-update","title":"GHC DevX June 2022 Update","authors":["sylvain"],"tags":["ghc","ghc-update"]},"prevItem":{"title":"Lightweight Haskell Threads on JavaScript","permalink":"/2022-07-18-lightweight-threads-on-JavaScript"},"nextItem":{"title":"GHC DevX May 2022 Update","permalink":"/2022-06-01-ghc-update"}},"content":"This is the June 2022 monthly update from the GHC DevX team at IOG.\\n\\n## JavaScript Backend for GHC\\n\\nFor a few months we have been merging GHCJS (Haskell to JavaScript compiler) into GHC.\\nWe set our first milestone to be the ability to compile and to run the usual \\"Hello World\\" program.\\nIt turned out to be much more involved than we initially thought (requiring FFI support, etc.), but we should be getting there soon.\\n\\nThis month we have made the following progress:\\n\\n- **Linking**: GHCJS requires some functions to be directly implemented in\\n  JavaScript (e.g. the RTS, some low-level functions in base). We have added support\\n  for linking `.js` files. We\'ve also added support for a preprocessing pass with CPP\\n  for `.js.pp` files.\\n\\n- **js-sources**: there is some ongoing work to load these external JavaScript\\n  files from installed libraries. Cabal provides a `js-sources` stanza for this,\\n  we need to adapt Hadrian to make use of it.\\n\\n- **Binary vs Objectable**: GHCJS used its own ByteString-based Objectable\\n  type-class: we replaced it with GHC\'s similar Binary type-class.\\n  Josh has published a [blog\\n  post](https://engineering.iog.io/2022/05/24/april-GHCJS-Objectable-vs-GHC-Binary)\\n  about their differences.\\n\\n- **64-bit primops**: we\'ve added support for 64-bit primops (Word64# and Int64#\\n  types). In GHCJS (GHC 8.10), these were still implemented as foreign function\\n  calls. It\'s no longer true on GHC head.\\n\\n- **base library**: added CPP as required to support the JS backend. Ported and\\n  converted FFI imports from GHCJS to use JavaScript fat arrows (we haven\'t\\n  implemented GHCJS\'s fancy import syntax yet).\\n\\nNow we can compile and link the \\"HelloWorld\\" program.\\nTo reach the first milestone we only have to fix the remaining runtime errors.\\n\\nYou can follow our progress on our development branch [here](https://gitlab.haskell.org/ghc/ghc/-/tree/wip/js-staging).\\nWe now rebase this branch every Friday to avoid lagging too much behind GHC head.\\n\\n## Haskell Optimization Handbook\\n\\nThe \\"Haskell Optimization Handbook\\" is an [accepted proposal](https://github.com/haskellfoundation/tech-proposals/blob/main/proposals/accepted/026-haskell-optimization-handbook.md) of the Haskell Foundation.\\nJeff has been steadily writing some initial material as per the project plan."},{"id":"2022-06-01-ghc-update","metadata":{"permalink":"/2022-06-01-ghc-update","source":"@site/blog/2022-06-01-ghc-update-2022-05.md","title":"GHC DevX May 2022 Update","description":"This is the May 2022 monthly update from the GHC DevX team at IOG.","date":"2022-06-01T00:00:00.000Z","formattedDate":"June 1, 2022","tags":[{"label":"ghc","permalink":"/tags/ghc"},{"label":"ghc-update","permalink":"/tags/ghc-update"}],"readingTime":2.61,"truncated":false,"authors":[{"name":"Sylvain Henry","title":"Haskell DevX Engineer @ IOG","email":"sylvain.henry@iohk.io","key":"sylvain"}],"frontMatter":{"slug":"2022-06-01-ghc-update","title":"GHC DevX May 2022 Update","authors":["sylvain"],"tags":["ghc","ghc-update"]},"prevItem":{"title":"GHC DevX June 2022 Update","permalink":"/2022-07-01-ghc-update"},"nextItem":{"title":"Objectable vs GHC Binary","permalink":"/2022/05/24/april-GHCJS-Objectable-vs-GHC-Binary"}},"content":"This is the May 2022 monthly update from the GHC DevX team at IOG.\\n\\n## JavaScript Backend for GHC\\n\\nFor a few months we have been merging GHCJS (Haskell to JavaScript compiler) into GHC.\\nWe set our first milestone to be the ability to compile and to run the usual \\"Hello World\\" program.\\nIt turned out to be much more involved than we initially thought (requiring FFI support, etc.), but we should be getting there soon.\\n\\nThis month we have made the following progress:\\n\\n- **RTS**: we have modified Hadrian and ``rts.cabal`` in order to build a valid\\n  native ``rts`` unit that GHC can use, in particular containing appropriate\\n  header files.\\n\\n- **linker**: the JS linker has been hooked up with GHC\'s driver.\\n  We fixed several panics in the linker due to erroneous symbol generation code.\\n  These bugs were introduced while porting the code from the old 8.10 pretty-printing infrastructure to the newer one.\\n\\n- **boot libraries**: the JS backend can now build and link all the boot libraries.\\nNote that we are not claiming that they are all usable yet. In particular complete FFI support is lacking, but the JS backend Hadrian build completes and so we can start using the produced JS cross-compiler.\\n\\n- **levity polymorphism**: building ``ghc-prim`` uncovered a lurking bug related to\\n  levity polymorphism. It wasn\'t noticed in GHCJS 8.10 because it is also\\n  related to the ``BoxedRep`` proposal that introduced a constructor application\\n  in a commonly used ``RuntimeRep``.\\n\\n- **sized literals**: support for new sized literals have been added to the code\\n  generator.\\n\\nNow that have achieved a build process that actually produces a JS cross compiler, we are confronting and fixing issues in the produced JavaScript code, such as adding, managing, and debugging CPP conditional compilation blocks in JS shim files. You can follow our progress on our development branch [here](https://gitlab.haskell.org/ghc/ghc/-/tree/wip/js-staging).\\n\\n## External Static Plugins\\n\\nGHC doesn\'t support plugins in cross-compilers [#14335](https://gitlab.haskell.org/ghc/ghc/-/issues/14335).\\nSome time ago, we came up with a solution called \\"external static plugins\\" [!7377](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7377).\\nThese are plugins that are directly loaded from shared libaries, bypassing the issue with usual plugins.\\n\\nOur colleague Shea Levy confirmed that the approach works, backported it to GHC 8.10, and has been working on making it work in stage1 cross-compilers for Windows.\\nKudos for this work, Shea.\\n\\nAs the current user-interface based on environment variables isn\'t convenient, we have been working on adding new command-line flags to GHC instead.\\nWe expect to propose this for integration into GHC when the new interface will be fully implemented.\\n\\n## Blog posts\\n\\nInspired by our friends and colleagues at Well-Typed and Tweag, we have been starting to write blog posts for IOG\'s engineering blog.\\nThey will mostly be about stuff we are working on or that we are interested in.\\nFeel free to send us feedback about these posts and to send us topics you would be interested to read about.\\n\\n- https://engineering.iog.io/2022-04-28-on-the-inlining-of-integer-and-natural-operations\\n- https://engineering.iog.io/2022-05-02-setup-ext-stg-interp\\n- https://engineering.iog.io/2022-05-17-javascript-template-haskell-external-interpreter\\n\\n## Haskell Optimization Handbook\\n\\nThe \\"Haskell Optimization Handbook\\" is an [accepted proposal](https://github.com/haskellfoundation/tech-proposals/blob/main/proposals/accepted/026-haskell-optimization-handbook.md) of the Haskell Foundation.\\nJeff has been working behind the scene to make this proposal concrete.\\nMore about this in the upcoming months."},{"id":"/2022/05/24/april-GHCJS-Objectable-vs-GHC-Binary","metadata":{"permalink":"/2022/05/24/april-GHCJS-Objectable-vs-GHC-Binary","source":"@site/blog/2022-05-24-april-GHCJS-Objectable-vs-GHC-Binary.md","title":"Objectable vs GHC Binary","description":"As part of the integration of GHCJS into GHC as a cross-compilation backend, we\'ve converted the binary serialisation that GHCJS previously used, which was via its Objectable typeclass, into GHC\'s internal Binary typeclass representation. In doing this, we gain access to instances for serialising many of GHC\'s internal data types, and, importantly, we can reuse GHC\'s mechanism for serialising its Name and FastString types, which are written to lookup tables in order to maintain identity, as well as allowing for space savings on disk.","date":"2022-05-24T00:00:00.000Z","formattedDate":"May 24, 2022","tags":[],"readingTime":10.605,"truncated":false,"authors":[],"frontMatter":{},"prevItem":{"title":"GHC DevX May 2022 Update","permalink":"/2022-06-01-ghc-update"},"nextItem":{"title":"JavaScript, Template Haskell and the External Interpreter","permalink":"/2022-05-17-javascript-template-haskell-external-interpreter"}},"content":"As part of the integration of GHCJS into GHC as a cross-compilation backend, we\'ve converted the binary serialisation that GHCJS previously used, which was via its `Objectable` typeclass, into GHC\'s internal `Binary` typeclass representation. In doing this, we gain access to instances for serialising many of GHC\'s internal data types, and, importantly, we can reuse GHC\'s mechanism for serialising its `Name` and `FastString` types, which are written to lookup tables in order to maintain identity, as well as allowing for space savings on disk.\\n\\nIn this post, we will explain how the GHC `Binary` and GHCJS `Objectable` approaches work, and compare their tradeoffs.\\n\\n## How GHC Binary Works\\n\\nInternally, GHC uses the `Name` data type to track the uniqueness of objects during compilation. Amongst information relating to the definition of a `Name` within the Haskell source, a `Name` also contains a `Unique` integer (the value of which is provided by the complation environment monad). Using this `Unique` integer, which is unpacked in `Name`\'s definition, we can make O(1) equality comparisons without following further memory references - allowing for this operation to be very quick, which will have a large effect on compilation performance given how often it is used.\\n\\n`FastString` is used within GHC to store short, string-like data, and, similarly to `Name`, `FastString` uses a unique integer to allow for very fast equality comparisons. Primarily, `FastString` is used to represent variables and other definitions, and is used both in `Name` as the string-representation of a name with extra information attached, as well as directly, representing names that don\'t require this extra information, such as local variables.\\n\\nIn GHC\'s `.hi` interface files, `Name` and `FastString` are serialised differently compared to other data structures. They are written in the main data structure payload as indicies of a table, and these tables contain the actual string-like data of these types. So, an interface file might resemble:\\n\\n* Header\\n  * Magic number for recognising interface files\\n  * Pointer to `Name` symbol table\\n  * Pointer to `FastString` dictionary\\n* Main data structure payload\\n* `Name` symbol table\\n* `FastString` dictionary\\n\\nImportantly, the `FastString` dictionary must be written _after_ the `Name` symbol table, because `Name`s contain `FastString`s, so writing the symbol table will expand the dictionary. Additionally, because we only have one buffer, and we don\'t know the size of the payload until it\'s written, the tables cannot be written in the header, and instead serialisation code must reserve space for the table pointers and jump back to write the pointers once the table locations are known.\\n\\nDuring serialisation, GHC uses mutable data structures to store both the serialised binary buffer, as well as these tables:\\n\\n```haskell\\ndata BinHandle\\n  = BinMem {                     -- binary data stored in an unboxed array\\n     bh_usr :: UserData,         -- sigh, need parameterized modules :-)\\n     _off_r :: !FastMutInt,      -- the current offset\\n     _sz_r  :: !FastMutInt,      -- size of the array (cached)\\n     _arr_r :: !(IORef BinArray) -- the array (bounds: (0,size-1))\\n    }\\n\\ndata UserData =\\n   UserData {\\n        -- for *deserialising* only:\\n        ud_get_name :: BinHandle -> IO Name,\\n        ud_get_fs   :: BinHandle -> IO FastString,\\n\\n        -- for *serialising* only:\\n        ud_put_nonbinding_name :: BinHandle -> Name -> IO (),\\n        -- ^ serialize a non-binding \'Name\' (e.g. a reference to another\\n        -- binding).\\n        ud_put_binding_name :: BinHandle -> Name -> IO (),\\n        -- ^ serialize a binding \'Name\' (e.g. the name of an IfaceDecl)\\n        ud_put_fs   :: BinHandle -> FastString -> IO ()\\n   }\\n```\\n\\nHere, we see that various functions are stored in the handle structure, to be later referenced by their respective types in their `GHC.Utils.Binary.Binary` typeclass instances. Notice that the instance of `Binary Name` references `ud_put_nonbinding_name` and `ud_get_name`. Similarly, the `Binary FastString` instance uses `ud_put_fs` and `ud_get_fs`.\\n\\n```haskell\\nclass Binary a where\\n    put_   :: BinHandle -> a -> IO ()\\n    put    :: BinHandle -> a -> IO (Bin a)\\n    get    :: BinHandle -> IO a\\n\\ninstance Binary FastString where\\n  put_ bh f =\\n    case getUserData bh of\\n        UserData { ud_put_fs = put_fs } -> put_fs bh f\\n\\n  get bh =\\n    case getUserData bh of\\n        UserData { ud_get_fs = get_fs } -> get_fs bh\\n\\ninstance Binary Name where\\n   put_ bh name =\\n      case getUserData bh of\\n        UserData{ ud_put_nonbinding_name = put_name } -> put_name bh name\\n\\n   get bh =\\n      case getUserData bh of\\n        UserData { ud_get_name = get_name } -> get_name bh\\n```\\n\\nIn `GHC.Iface.Binary`, helper types and functions are defined to store the `Name` symbol table and `FastString` dictionary in a mutable data structure. Here, `putFastString` is intended to be partially applied - passing it an appropriately initialised `BinDictionary` so that the resulting function can be stored in the `us_put_fs` field of the `UserData`. `allocateFastString` does the low-level work here, incrementing the index and modifying the mutable map (stored as a `UniqFM`, which is map keyed on types that contain `Unique`s - recalling that these are used for fast equality comparisons):\\n\\n```haskell\\ndata BinDictionary = BinDictionary {\\n        bin_dict_next :: !FastMutInt, -- The next index to use\\n        bin_dict_map  :: !(IORef (UniqFM FastString (Int,FastString)))\\n                                -- indexed by FastString\\n  }\\n\\nputFastString :: BinDictionary -> BinHandle -> FastString -> IO ()\\nputFastString dict bh fs = allocateFastString dict fs >>= put_ bh\\n\\nallocateFastString :: BinDictionary -> FastString -> IO Word32\\nallocateFastString BinDictionary { bin_dict_next = j_r,\\n                                   bin_dict_map  = out_r} f = do\\n    out <- readIORef out_r\\n    let !uniq = getUnique f\\n    case lookupUFM_Directly out uniq of\\n        Just (j, _)  -> return (fromIntegral j :: Word32)\\n        Nothing -> do\\n           j <- readFastMutInt j_r\\n           writeFastMutInt j_r (j + 1)\\n           writeIORef out_r $! addToUFM_Directly out uniq (j, f)\\n           return (fromIntegral j :: Word32)\\n```\\n\\nLater, in `GHC.Iface.Binary`, `getWithUserData` and `putWithUserData` will structure the header, and initialise the `UserData` functions to write to/read from mutable tables. Notice that we must first reserve header space for pointers to the lookup tables, as well as initialise the mutable tables, write these initialised structures to the `UserData` (for example, we see the previous `putFastString` partially applied here), then write the main payload, then write the lookup tables (`Name` symbol table first, because writing this can add to the `FastString` dictionary), and finally jump back to fill in the pointers to these tables:\\n\\n```haskell\\nputWithUserData :: Binary a => TraceBinIFace -> BinHandle -> a -> IO ()\\nputWithUserData traceBinIface bh payload = do\\n    -- Remember where the dictionary pointer will go\\n    dict_p_p <- tellBin bh\\n    -- Placeholder for ptr to dictionary\\n    put_ bh dict_p_p\\n\\n    -- Remember where the symbol table pointer will go\\n    symtab_p_p <- tellBin bh\\n    put_ bh symtab_p_p\\n    -- Make some initial state\\n    symtab_next <- newFastMutInt 0\\n    symtab_map <- newIORef emptyUFM\\n    let bin_symtab = BinSymbolTable {\\n                         bin_symtab_next = symtab_next,\\n                         bin_symtab_map  = symtab_map }\\n    dict_next_ref <- newFastMutInt 0\\n    dict_map_ref <- newIORef emptyUFM\\n    let bin_dict = BinDictionary {\\n                       bin_dict_next = dict_next_ref,\\n                       bin_dict_map  = dict_map_ref }\\n\\n    -- Put the main thing,\\n    bh <- return $ setUserData bh $ newWriteState (putName bin_dict bin_symtab)\\n                                                  (putName bin_dict bin_symtab)\\n                                                  (putFastString bin_dict)\\n    put_ bh payload\\n\\n    -- Write the symtab pointer at the front of the file\\n    symtab_p <- tellBin bh        -- This is where the symtab will start\\n    putAt bh symtab_p_p symtab_p  -- Fill in the placeholder\\n    seekBin bh symtab_p           -- Seek back to the end of the file\\n\\n    -- Write the symbol table itself\\n    symtab_next <- readFastMutInt symtab_next\\n    symtab_map  <- readIORef symtab_map\\n    putSymbolTable bh symtab_next symtab_map\\n    case traceBinIface of\\n      QuietBinIFace         -> return ()\\n      TraceBinIFace printer ->\\n         printer (text \\"writeBinIface:\\" <+> int symtab_next\\n                                        <+> text \\"Names\\")\\n\\n    -- NB. write the dictionary after the symbol table, because\\n    -- writing the symbol table may create more dictionary entries.\\n\\n    -- Write the dictionary pointer at the front of the file\\n    dict_p <- tellBin bh          -- This is where the dictionary will start\\n    putAt bh dict_p_p dict_p      -- Fill in the placeholder\\n    seekBin bh dict_p             -- Seek back to the end of the file\\n\\n    -- Write the dictionary itself\\n    dict_next <- readFastMutInt dict_next_ref\\n    dict_map  <- readIORef dict_map_ref\\n    putDictionary bh dict_next dict_map\\n    case traceBinIface of\\n      QuietBinIFace         -> return ()\\n      TraceBinIFace printer ->\\n         printer (text \\"writeBinIface:\\" <+> int dict_next\\n                                        <+> text \\"dict entries\\")\\n```\\n\\nIn summary, we see a number of structural characteristics of code using GHC\'s Binary implementation:\\n* Use of a single buffer means that the lookup tables can\'t be written in the header, so we have to reserve space for table pointers in the header, and jump back once we know where they will be located in order to write the pointers to the buffer. Essentially, an ordering of file sections is enforced by the data dependencies of the payload containing `Name`s and `FastString`s, and `Name`s containing `FastString`s - which means these must be written in this order, but reading must be done in the reverse order, causing the need for pointers in the header.\\n* Jumping around in binary buffers results in weakly enforced types and fiddly, code that Haskell\'s type system isn\'t able to help us debug\\n* Must carry about read/write functions for the lookup table types (`Name` and `FastString`), which are `undefined` during the opposite serialisation stage, and are hard-coded into the handle, reducing extensibility.\\n\\n## How Objectable Works\\n\\nIn comparison, GHCJS previously involved using instances of the `Objectable` typeclass to serialise its interface files:\\n\\n```haskell\\nimport qualified Data.Binary as DB\\n\\ndata SymbolTable\\n  = SymbolTable !Int !(Map ShortText Int)\\n  deriving (Show)\\n\\ntype PutSM = St.StateT SymbolTable DB.PutM -- FIXME: StateT isn\'t strict enough apparently\\ntype PutS  = PutSM ()\\ntype GetS  = ReaderT ObjEnv DB.Get\\n\\nclass Objectable a where\\n  put :: a -> PutS\\n  get :: GetS a\\n  putList :: [a] -> PutS\\n  putList = putListOf put\\n  getList :: GetS [a]\\n  getList = getListOf get\\n```\\n\\nHere we see that GHCJS has opted for a different approach that avoids the mutable buffer by instead using `Data.Binary` instances that work via concatenating lazy `ByteString`s. Additionally, the mutable tables are replaced with a `State` monad that holds the symbol table as a `Map` structure.\\n\\nBecause `Data.Binary` forms lazy `ByteString`s, it\'s trivial to serialise the individual parts of the interface file and later concatenate these using `ByteString`\'s monoid instance - allowing for all of the sections of the file to be defined declaratively at the top-level of the function in order of their appearance within the file.\\n\\n```haskell\\nobject\'\\n  :: ModuleName                 -- ^ module\\n  -> SymbolTable                -- ^ final symbol table\\n  -> Deps                       -- ^ dependencies\\n  -> [([ShortText],ByteString)] -- ^ serialized units and their exported symbols, the first unit is module-global\\n  -> ByteString\\nobject\' mod_name st0 deps0 os = hdr <> symbs <> deps1 <> idx <> mconcat (map snd os)\\n  where\\n    hdr          = putHeader (Header (moduleNameTag mod_name) (bl symbs) (bl deps1) (bl idx))\\n    bl           = fromIntegral . B.length\\n    deps1        = putDepsSection deps0\\n    (sti, idx)   = putIndex st0 os\\n    symbs        = putSymbolTable sti\\n```\\n\\nIn summary, the use of multiple `ByteString` sections that are later concatenated offer several different structural characteristics compared to the use of a single mutable buffer:\\n* The final ordering of the sections is flexible, because they are serialsied separately, so any data dependencies don\'t introduce ordering in the file - which we see in the `where` clause of `object\'`\\n* Types are more strongly enforced because imperative `seekBin` instructions aren\'t required. However, each section is still _deserialised_ by taking a substring of the file to be read as that section type. Of course, all serialisation eventually results in raw binary, so the simplification of concatenating the sections into the final file without jumping around limits the places that bugs can hide\\n* Visually, the ordering of the sections within the final file is very clear - we see in `object\'` that every section is simply listed _in order_ on one line, concatenated together.\\n\\n## Conclusion\\n\\nMaking use of GHC\'s existing infrastructure lets the GHCJS backend to make use of the `FastString` and `Name` data types, as well as allowing for the removal of a significant amount of now-redundant code.\\n\\nAdditionally, interface file generation using GHC\'s `Binary` appears to be very fast - for example, attempts to hide the handle behind a reader monad significantly reduce the compiler\'s performance as measured by CI. Speculatively, looking at the generated core, this could be because the optimiser has a much better time with the style of IO code that is used - rather than being a limitation of more abstacted approaches.\\n\\nThe comparison provided the GHCJS\'s old approach makes it clear that GHC\'s `Binary` implementation, while very useful, has potential to be improved in both readability and extensiblity. However, because CI has shown that serialisation performance has a significant effect on overall compilation performance, this tradeoff must be considered when making any changes. Potentially, these readability shortfalls in GHC\'s implementation might just be the result of legacy code, and so benchmarks of other approaches, such as `Data.Binary`, should be used to guide future work in improving the readability and flexibility of GHC\'s serialisation without sacrificing performance."},{"id":"2022-05-17-javascript-template-haskell-external-interpreter","metadata":{"permalink":"/2022-05-17-javascript-template-haskell-external-interpreter","source":"@site/blog/2022-05-17-javascript-template-haskell-ext-interp.md","title":"JavaScript, Template Haskell and the External Interpreter","description":"Introduction","date":"2022-05-17T00:00:00.000Z","formattedDate":"May 17, 2022","tags":[{"label":"ghc","permalink":"/tags/ghc"},{"label":"ghcjs","permalink":"/tags/ghcjs"},{"label":"javascript","permalink":"/tags/javascript"},{"label":"tooling","permalink":"/tags/tooling"},{"label":"profiling","permalink":"/tags/profiling"}],"readingTime":6.805,"truncated":false,"authors":[{"name":"Luite Stegeman","title":"Haskell DevX Engineer @ IOG","email":"luite.stegeman@iohk.io","key":"luite"}],"frontMatter":{"slug":"2022-05-17-javascript-template-haskell-external-interpreter","title":"JavaScript, Template Haskell and the External Interpreter","date":"May 17, 2022","authors":["luite"],"tags":["ghc","ghcjs","javascript","tooling","profiling"]},"prevItem":{"title":"Objectable vs GHC Binary","permalink":"/2022/05/24/april-GHCJS-Objectable-vs-GHC-Binary"},"nextItem":{"title":"GHC April 2022 Update","permalink":"/ghc-update-2022-04"}},"content":"## Introduction\\n\\nAt IOG DevX we have been working on integrating various bits of GHCJS into GHC, with the goal of having a fully working JavaScript backend for the 9.6 release. For some parts this has mostly consisted of an update of the code to use the newer GHC API and dependencies. Other bits, like the Template Haskell runner, need more work.\\n\\nThis post gives an overview of the existing approaches for running Template Haskell in GHC based cross compilers and our plan for the JavaScript backend. Hopefully we can revisit this topic once all the work has been done, and see what exactly we ended up with.\\n\\n## The GHCJS Template Haskell Runner\\n\\nWhen I first worked on Template Haskell (TH) support for GHCJS, there was no mechanism to combine Template Haskell with cross compilation in GHC.\\n\\nNormally, Template Haskell is run by loading library code directly into the GHC process and using the bytecode interpreter for the current module. Template Haskell can directly access GHC data structures through the `Q` monad. Clearly this would not be possible for GHCJS: We only have JavaScript code available for the libraries and the organization of the JavaScript data structures is very different from what GHC uses internally.\\n\\nSo I had to look for an alternative. Running Template Haskell consists of two parts:\\n\\n   1. loading/executing the TH code\\n   2. handling compiler queries from the TH code, for example looking up names or types\\n\\nRunning the TH code can be done by first compiling the Haskell to JavaScript and then using the JavaScript `eval` feature.\\n\\nTemplate Haskell code can query the compiler using the `Quasi` typeclass. I noticed that none of the methods required passing around functions or complicated data structures, so it would be possible to serialize each request and response and send it to another process.\\n\\nSo I went ahead and implemented this approach with a script `thrunner.js` to load and start the code in a node.js server, a message type with serialization, and a new instance of the `Quasi` typeclass to handle the communication with the compiler via the messages. This is still what\'s in use by GHCJS to this day. Every time GHCJS encounters Template Haskell, it starts a `thrunner` process and the compiler communicates with it over a pipe.\\n\\nAfter starting `thrunner.js` GHCJS sends the Haskell parts of the Template Haskell runnner to the script. This includes the runtime system and the implementation of the `Quasi` typeclass and communication protocol. After that, the TH session starts. A typical TH session looks as follows:\\n\\n| Compiler | thrunner |\\n| :---     | :----    |\\n| `RunTH THExp <js code> <source location>` | |\\n| | `LookupName (Just <name-string>)` |\\n| `LookupName\' (Just <name>)` |\\n| | `Reify <name>` |\\n| `Reify\' <name-info>` | |\\n| | `RunTH\' <result>` |\\n| `RunTH THDec <js code> <source location>` | |\\n| | `AddTopDecls <declarations>` |\\n| `AddTopDecls\'` | |\\n| | `RunTH\' <result>` |\\n| `FinishTH True` | |\\n| | `FinishTH\' <memory-consumption>` |\\n\\nEach message is followed up by a corresponding reply. For example, a `LookupName\'` response follows a `LookupName` request and a `RunTH` message will eventually generate a `RunTH\'` result. The first `RunTH` message contains the compiled JavaScript for the Template Haskell code, along with its dependencies. Each subsequent `RunTH` only includes dependencies that have not already been sent.\\n\\nThe `thrunner` process stays alive during the compilation of at least an entire module, allowing for persistent state (`putQ`/`getQ`).\\n\\n## The GHC External Interpreter\\n\\nIf we build a Haskell program with (cost centre) profiling, the layout of our data structures changes to include bookkeeping of cost centre information. This means that we need a special profiling runtime system to run this code.\\n\\nWhat can we do if we want to run our profiled build in GHCi or Template Haskell? We cannot load compiled profiling libraries into GHC directly; its runtime system expects non-profiled code. We could use a profiled version of the compiler itself, but this would make all compilation very slow. Or we could somehow separate the profiled code of our own program from the non-profiled code in the compiler.\\n\\nThis was Simon Marlow\'s motivation for adapting the GHCJS `thrunner` approach, integrating in GHC and extending it it to support GHCi and bytecode. This functionality can be activated with the `-fexternal-interpreter` flag and has been available since GHC version 8.0.1. When the external interpreter is activated, GHC starts a separate process, `iserv` (customizable with the `-pgmi` flag) which has the role analogous to the `thrunner` script for GHCJS.\\n\\nOver time, the `iserv` code has evolved with GHC and has been extended to include more operations. By now, there are quite a few differences in features:\\n\\n| Feature | thrunner | iserv |\\n| :--- | :----:   | :---: |\\n| Template Haskell support | yes       | yes   |\\n| GHCi   | no | yes |\\n| Debugger | no | yes |\\n| Bytecode | no | yes |\\n| Object code | through pipe | from file |\\n| Object code linking | compiler | iserv process |\\n\\n`thrunner` is not quite as complete as `iserv`: It lacks GHCi and the debugger, and there is no bytecode support. But these features are not essential for basic Template Haskell.\\n\\n## Proxies and Bytecodes\\n\\nWe have now seen two systems for running Template Haskell code outside the compiler process: The original GHCJS `thrunner` and the extended GHC `iserv`.\\n\\nClearly it isn\'t ideal to have multiple \\"external interpreter\\" systems in GHC, therefore we plan to switch from `thrunner` to `iserv` for the upcoming JavaScript GHC backend. We don\'t need the debugger or GHCi support yet, but we do need to adapt to other changes in the infrastructure. So what does this mean in practice?\\n\\nThe biggest change is that we have to rework the linker: `thrunner` does not contain any linking logic by itself: GHCJS compiles everything to JavaScript and sends compiled code to the `thrunner` process, ready to be executed. In contrast, `iserv` has a loader for object and archive files. When dependencies need to be loaded into the interpreter, GHC just gives it the file name.\\n\\nAnother change is using the updated message types. In the `thrunner` session example above we could see that each message is paired with a response. For example a `RunTH\'` response always follows a `RunTH` message, with possibly other messages in between. `iserv` has an interesting approach for the `Message` datatype: Instead of having pairs of data constructors for each message and its response, `iserv` has a GADT `Message a`, where the `a` type parameter indicates the expected response payload for each data constructor.\\n\\nDuring development of the `thrunner` program it turned out to be very useful to save and replay Template Haskell sessions for debugging purposes. We\'d like to do this again, but now saving the message in a readable/writable format. Since we\'re dealing with JavaScript, JSON appears to be the obvious choice.\\n\\nOur plan is to have an `iserv` implementation that consists of a JavaScript part that runs in node.js and a proxy process to handle communication with GHC. The proxy process converts the messages between GHC\'s own (`binary` based) serialization format and JSON. The proxy process is relatively simple, but it does reveal one downside of the new GADT based message types: A proxy is stateful. We must always know which message we have sent to convert the response back from JSON to `binary`.\\n\\nIt\'s not yet known whether we will implement a full bytecode interpreter. We expect it to become clear during implementation whether we can get away without one early on.\\n\\n## Conclusion\\n\\nWe have seen how Template Haskell and GHCi code can be run outside the GHC process for profiling or cross compiling, with both the `thrunner` approach in GHCJS and the newer `iserv` in GHC.\\n\\nWe at IOG DevX are working on switching to the `iserv` infrastructure for the upcoming GHC JavaScript backend, which involves a substantial rewrite, mainly because of differences in linking. This is a work in progress, and we intend to revisit this topic in another blog post once the final design has been implemented."},{"id":"ghc-update-2022-04","metadata":{"permalink":"/ghc-update-2022-04","source":"@site/blog/2022-05-13-ghc-update-2022-04.md","title":"GHC April 2022 Update","description":"Welcome to the (rather late) April 2022 monthly update from the GHC DevX team at IOG. Since the last update we\'ve continued work on the upcoming JavaScript backend for GHC. Unfortunately, we have nothing to show quite yet but that doesn\'t mean nothing has happened! On the contrary, we\'ve made great progress and are close to that crucial first milestone hello world. Besides our work on the JavaScript backend, we were pleased to finally push through the Modularizing GHC paper that Sylvain has been working on for 2+ years! It causes quite the splash on the Haskell discourse and reddit, we recommend reading it if you haven\'t already (links below). Alright, enough introduction let\'s get into the update.","date":"2022-05-13T00:00:00.000Z","formattedDate":"May 13, 2022","tags":[{"label":"ghc","permalink":"/tags/ghc"},{"label":"ghc-update","permalink":"/tags/ghc-update"}],"readingTime":1.94,"truncated":false,"authors":[{"name":"Sylvain Henry","title":"Haskell DevX Engineer @ IOG","email":"sylvain.henry@iohk.io","key":"sylvain"},{"name":"Jeffrey M. Young","title":"Haskell DevX Engineer @ IOG","url":"https://iog.io/en/","key":"doyougnu"}],"frontMatter":{"slug":"ghc-update-2022-04","title":"GHC April 2022 Update","authors":["sylvain","doyougnu"],"tags":["ghc","ghc-update"]},"prevItem":{"title":"JavaScript, Template Haskell and the External Interpreter","permalink":"/2022-05-17-javascript-template-haskell-external-interpreter"},"nextItem":{"title":"Setting up Csaba\'s External STG Interpreter","permalink":"/2022-05-02-setup-ext-stg-interp"}},"content":"Welcome to the (rather late) April 2022 monthly update from the GHC DevX team at IOG. Since the last update we\'ve continued work on the upcoming JavaScript backend for GHC. Unfortunately, we have nothing to show quite yet but that doesn\'t mean nothing has happened! On the contrary, we\'ve made great progress and are close to that crucial first milestone `hello world`. Besides our work on the JavaScript backend, we were pleased to finally push through the [Modularizing GHC](https://hsyl20.fr/home/posts/2022-05-03-modularizing-ghc-paper.html) paper that Sylvain has been working on for 2+ years! It causes quite the splash on the Haskell discourse and reddit, we recommend reading it if you haven\'t already (links below). Alright, enough introduction let\'s get into the update.\\n\\n## JavaScript Backend\\n\\nWe have made the following progresses in the implementation of a JavaScript\\nbackend for GHC (adapted from GHCJS):\\n\\n- **linker**: ported GHCJS\'s linker code into GHC. A lot of code was duplicated from GHC and\\n  slightly modified for GHCJS\'s needs, making the process far from trivial.\\n\\n- **testsuite**: fixed Hadrian to run GHC\'s testsuite with cross-compilers\\n  [!7850](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7850). There are\\n  remaining issues though (see\\n  [#21292](https://gitlab.haskell.org/ghc/ghc/-/issues/21292)).\\n\\n- **build system**: fixes for GHC\'s configure script were ported (e.g. support for\\n  the \\"ghcjs\\" target in ``config.sub``). GHCJS\'s custom\\n  build script was integrated into ``configure.ac``. We can now\\n  configure the build with: ``./configure --target=js-unknown-ghcjs``\\n\\n- **TH**: we have conducted some experiments to find the best way to bridge GHCJS\'s\\n  TH runner and GHC\'s external interpreter. This will be described in details in\\n  a future blog post.\\n\\n- **FFI**: basic support for JavaScript FFI has been ported from GHCJS to GHC. We\\n  haven\'t ported the JavaScript parser, so we have dropped the fancy import\\n  syntax (e.g. \\"$1.xyz\\"). It should be enough to build boot libraries and we\\n  will add JS parsing support later.\\n\\nAt this stage, we are working on building boot libraries and on supporting\\nlinking with the JS RTS.\\n\\nDevelopment happens in the following branch: https://gitlab.haskell.org/ghc/ghc/-/tree/wip/js-staging\\n\\n\\n## Modularity paper\\n\\nSylvain, Jeffrey, and John Ericson (from Obsidian Systems) wrote a paper about\\n\\"modularizing GHC\\" using domain-driven design.\\n\\n- Announce blog post: https://hsyl20.fr/home/posts/2022-05-03-modularizing-ghc-paper.html\\n- Paper: https://hsyl20.fr/home/files/papers/2022-ghc-modularity.pdf\\n- Reddit: https://www.reddit.com/r/haskell/comments/uhdu4l/modularizing_ghc_paper/\\n- Discourse: https://discourse.haskell.org/t/modularizing-ghc-paper/4471\\n\\nWe\'ve got a lot of great feedback about it (expect a first revision soon).\\nWe also got a GHC contribution directly inspired by the paper (see\\n[!8160](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/8160)) which was\\nvery welcome!"},{"id":"2022-05-02-setup-ext-stg-interp","metadata":{"permalink":"/2022-05-02-setup-ext-stg-interp","source":"@site/blog/2022-05-02-setup-ext-stg-interp.md","title":"Setting up Csaba\'s External STG Interpreter","description":"Table of Contents","date":"2022-05-02T00:00:00.000Z","formattedDate":"May 2, 2022","tags":[{"label":"ghc","permalink":"/tags/ghc"},{"label":"stg","permalink":"/tags/stg"},{"label":"tooling","permalink":"/tags/tooling"},{"label":"profiling","permalink":"/tags/profiling"},{"label":"optimization","permalink":"/tags/optimization"}],"readingTime":17.305,"truncated":false,"authors":[{"name":"Jeffrey M. Young","title":"Haskell DevX Engineer @ IOG","url":"https://iog.io/en/","key":"doyougnu"}],"frontMatter":{"slug":"2022-05-02-setup-ext-stg-interp","title":"Setting up Csaba\'s External STG Interpreter","date":"May 2, 2022","authors":["doyougnu"],"tags":["ghc","stg","tooling","profiling","optimization"]},"prevItem":{"title":"GHC April 2022 Update","permalink":"/ghc-update-2022-04"},"nextItem":{"title":"On the inlining of Integer and Natural operations","permalink":"/2022-04-28-on-the-inlining-of-integer-and-natural-operations"}},"content":"## Table of Contents\\n- [Making sense of the project](#orgfeb334e)\\n- [Building a working external STG interpreter](#org1d461dc)\\n  - [ghc.nix](#orgb670539)\\n  - [Building ghc-wpc](#orgbb3f1d5)\\n  - [Building the stg tooling](#org9ef4bc5)\\n- [Building the external-stg-interpreter](#org4a2eaf9)\\n- [Linking the external-stg-interpreter](#org1d34a2e)\\n- [The whole setup process on a demo](#org2daa4b8)\\n- [Summary](#org8193a1a)\\n  - [File Descriptions](#org940ba90)\\n  - [Step-by-Step guide for running the interpreter on your code](#org8e9f409)\\n\\nHaskell is a great language camouflaged by lackluster tooling. This situation\\nhas led to well-known problems (who could forget Cabal hell?). A less discussed\\nproblem is what I will call the &ldquo;Black-box syndrome&rdquo;: It is hard to\\nknow *exactly* what the memory representation and runtime performance of my\\nHaskell programs are[^1]. Now black-box syndrome is not *only* a problem,\\nit is also one of the nice features in the language since like all good\\nabstractions it elides things I&rsquo;d rather not care about, at least most of\\nthe time. In other words, I am happy I don&rsquo;t have to do manual memory\\nmanipulation!\\n\\nHowever, when I have my optimization hat on, I run face first into black-box syndrome. The crux of the problem is a tension between the need for observation during performance engineering and optimization, and the need to ship fast code. During development we want to be able to open up a system, see exactly how it is working, make tweaks, package it back up and test again. I want to be able to answer questions like &ldquo;Why is my executable this size?&rdquo;, &ldquo;Which code is a hot loop?&rdquo;, or &ldquo;When does my code do direct, known or unknown function calls?&rdquo;.\\n\\nIn order to answer these questions we need the ability to observe *every part of that system as the machine experiences it*, without this ability we have no way to make progress other than test, change some code, compile and test again in an ad-hoc manner. And therein lies the problem, most Haskell tooling is insufficient to provide the observability that we would like, instead the tooling often expects and requires us to make source code changes to our program or even recompile all of our libraries and code for a profiling way. This leads to the idea and *the expectation* in the Haskell community that Haskell programs are hard to optimize because the barrier to entry for optimization has artificially increased.\\n\\n[Csaba Hruska](https://www.patreon.com/csaba_hruska) has recently been making headway in this area with his work on the [GRIN](https://youtu.be/iXhh0NSR67k) compiler and an external STG interpreter. His STG interpreter (and patched ghc) exactly solve these problems and he has demonstrated dumping the entire call graph of large Haskell projects, filter to hot loops and finding unknown function calls in these graphs. If you haven&rsquo;t seen his [demo](https://www.youtube.com/watch?v=wt6iCgYmVGA&t=2054s) be sure to watch it, it is well worth your time.\\n\\nThis post is the first in a new blog series. In this blog series we&rsquo;re going to kick the tires on the external STG interpreter see what it can do, and what we can uncover in some popular libraries by using it. In particular, I&rsquo;m interested in running it on projects I&rsquo;ve previously optimized&#x2014;such as ghc itself, containers, unordered-containers&#x2014;using the standard methods: ticky-ticky profiling, prof, flamegraphs, heap profiling, ghc-debug, cachegrind etc. This post, however, will be focused on setting up the patched ghc and interpreter on a NixOS system. My goals are threefold:\\n\\n1.  Give an overview of the project and project layout to lower barrier to entry for the system.\\n2.  Give step by step instructions on setting up the interpreter on a nix-based system and provide a forked github repo for nix users. This should allow nix users to just `git clone foo` and `nix-build` (spoiler: it won&rsquo;t be that easy but still not hard.)\\n3.  Popularize Csaba&rsquo;s project! It is a refreshing take on Haskell optimization and compilation.\\n\\n\\n<a id=\\"orgfeb334e\\"></a>\\n\\n# Making sense of the project\\n\\nThe external STG interpreter is part of the [GRIN compiler](https://github.com/grin-compiler) project. We are not doing anything with the GRIN compiler (yet!) and so we are only interested in [The GHC whole compiler project](https://github.com/grin-compiler/ghc-whole-program-compiler-project). The whole-compiler-project has several sub-projects that we&rsquo;ll be building and using directly:\\n\\n-   [external-stg](https://github.com/grin-compiler/ghc-whole-program-compiler-project/tree/master/external-stg): This subproject provides utilites we&rsquo;ll be using, in particular `mkfullpak`\\n-   [external-stg-interpreter](https://github.com/grin-compiler/ghc-whole-program-compiler-project/tree/master/external-stg-interpreter): This is the actual STG interpreter. The good news is that this is independent of the rest of the project and can be built just like a regular Haskell executable\\n-   [ghc-wpc](https://github.com/grin-compiler/ghc-wpc/tree/b51ab235f5c07caa5eb3dd3b40487f67f50fb838): This is a fork of `ghc-8.10.x` (I&rsquo;m not sure exactly which version it forks to be honest) which we must build in order to use the external STG interpreter. Ghc-wpc serves as a frontend for the external-stg-interpreter.\\n\\n\\n<a id=\\"org1d461dc\\"></a>\\n\\n# Building a working external STG interpreter\\n\\nThe external STG interpreter can be built like any regular haskell executable. But in order to use the interpreter we have to build `ghc-wpc`. `ghc-wpc` is necessary because it serves as a frontend for the STG interpreter. It compiles a Haskell program like normal and then dumps an enriched STG IR to file. This file is then run through a utility `gen-exe` (gen-exe is an executable built in the [external-stg-compiler](https://github.com/grin-compiler/ghc-whole-program-compiler-project/tree/master/external-stg-compiler) sub-project) which picks up the compilation pipeline from the STG IR and creates an executable like we would expect from a normal compilation pipeline.\\n\\nThe major difference between this process and the usual compiler pipeline is that `ghc-wpc` leaves enough compiler information on disk for the rest of the tooling to consume, namely, in files with a `*.o_stgbin` (this is STG IR generated at compile time), and `*.o_stgapp` (project linker and dependency information) extension. Thus, once we build this custom ghc version we can use it to build the source code we wish to analyze and begin our optimization work.\\n\\nFor the rest of this tutorial I&rsquo;ll be referencing my [fork](https://github.com/doyougnu/ghc-whole-program-compiler-project) of the `ghc-whole-compiler-project` that includes everything you need if you want to follow along, including `.nix` files for creating a `nix-shell` which will prepare a suitable environment to run the entire toolchain.\\n\\n\\n<a id=\\"orgb670539\\"></a>\\n\\n## ghc.nix\\n\\nThe usual way to build ghc using a nix based system is with the [ghc.nix](https://github.com/alpmestan/ghc.nix) project. Ghc.nix provides a `default.nix` with a suitable environment to run hadrian and build ghc. For `ghc-wpc` we&rsquo;ll need some special packages, and we need our boot compiler to be *exactly* `ghc-8.3.3`. The custom `ghc.nix` file is included in my fork, I&rsquo;ve taken the liberty to pin the nixpkgs to the right version for `ghc-8.3.3`. So let&rsquo;s begin:\\n\\nClone the forked repo:\\n\\n```bash\\n$ git clone https://github.com/doyougnu/ghc-whole-program-compiler-project.git\\n\\n$ cd ghc-whole-program-compiler-project\\n\\n$ tree -L 1\\n.\\n\u251c\u2500\u2500 dist-newstyle\\n\u251c\u2500\u2500 external-stg\\n\u251c\u2500\u2500 external-stg-compiler\\n\u251c\u2500\u2500 external-stg-interpreter\\n\u251c\u2500\u2500 ghc.nix.wpc\\n\u251c\u2500\u2500 ghc-wpc\\n\u251c\u2500\u2500 lambda\\n\u251c\u2500\u2500 mod-pak\\n\u251c\u2500\u2500 README.md\\n\u251c\u2500\u2500 shell.nix\\n\u251c\u2500\u2500 stack.yaml\\n\u2514\u2500\u2500 stack.yaml.lock\\n```\\n\\nYou&rsquo;ll find the patched `ghc.nix` included (`ghc.nix.wpc`) and a `shell.nix` for a `nix-shell`. The `shell.nix` file simply references `ghc.nix.wpc/default.nix` with the appropriate options:\\n\\n```nix\\n$ cat shell.nix\\nimport (./ghc.nix.wpc/default.nix) {\\nuseClang = true;\\nwithHadrianDeps = true;\\nwithIde   = false;\\nwithLlvm  = true;\\n}\\n```\\n\\n\\n<a id=\\"orgbb3f1d5\\"></a>\\n\\n## Building ghc-wpc\\n\\nNow we can enter a nix-shell and build `ghc-wpc`:\\n\\n```bash\\n$ pwd\\n/home/doyougnu/programming/haskell/ghc-whole-program-compiler-project\\n\\n$ nix-shell shell.nix  # or just nix-shell\\ntrace: checking if /home/doyougnu/programming/haskell/ghc-whole-program-compiler-project/hadrian/hadrian.cabal is present:  no\\nRecommended ./configure arguments (found in $CONFIGURE_ARGS:\\nor use the configure_ghc command):\\n\\n  --with-gmp-includes=/nix/store/sznfxigwvrvn6ar3nz3f0652zsld9xqj-gmp-6.2.0-dev/include\\n  --with-gmp-libraries=/nix/store/447im4mh8gmw85dkrvz3facg1jsbn6c7-gmp-6.2.0/lib\\n  --with-curses-includes=/nix/store/84g84bg47xxg01ba3nv0h418v5v3969n-ncurses-6.1-20190112-dev/include\\n  --with-curses-libraries=/nix/store/xhhkr936b9q5sz88jp4l29wljbbcg39k-ncurses-6.1-20190112/lib\\n  --with-libnuma-includes=/nix/store/bfrcskjspk9a179xqqf1q9xqafq5s8d2-numactl-2.0.13/include\\n  --with-libnuma-libraries=/nix/store/bfrcskjspk9a179xqqf1q9xqafq5s8d2-numactl-2.0.13/lib\\n  --with-libdw-includes=/nix/store/sv6f05ngaarba50ybr6fdfc7cciv6nbv-elfutils-0.176/include\\n  --with-libdw-libraries=/nix/store/sv6f05ngaarba50ybr6fdfc7cciv6nbv-elfutils-0.176/lib\\n  --enable-dwarf-unwind\\n\\n[nix-shell:~/programming/haskell/ghc-whole-program-compiler-project]$\\n```\\n\\nNow we need to `cd` into `ghc-wpc` and tweak the hadrian build.\\n\\n**MAJOR CONSTRAINT: You must build ghc-wpc with hadrian/build-stack**, if you build in any other way you&rsquo;ll run into shared object errors, see this [ticket](https://github.com/grin-compiler/ghc-whole-program-compiler-project/issues/4) for details.\\n\\nSo in order to build `ghc-wpc` with stack we&rsquo;ll have to tweak the `stack.yaml` file. **You must do this since it is not included in the fork**:\\n\\nQuick side note: To make the formatting nicer I truncate\\n`nix-shell:~/foo/bar/baz/ghc-whole-program-compiler-project` to just `...`, so\\n`nix-shell:.../ghc-wpc` is equivalent to\\n`~/path/to/ghc-whole-compiler-project/ghc-wpc`.\\n\\n```bash\\n[nix-shell:...]$ cd ghc-wpc/hadrian/\\n\\n[nix-shell:.../ghc-wpc/hadrian]$ cat stack.yaml\\nresolver: lts-15.5\\n\\npackages:\\n- \'.\'\\n- \'GHC-Cabal\'\\n\\nsystem-ghc: true\\n\\nnix:\\n   enable: true\\n   shell-file: ../../shell.nix\\n```\\n\\nThe changes are: (1) tell `stack` we are using `nix`, and (2) reference the `shell.nix` file which points to `ghc.wpc.nix` at the root of the project, i.e., `ghc-whole-program-compiler-project/shell.nix`.\\n\\nNow we should be able to begin our build, return to the root of `ghc-wpc` and run the following:\\n\\n```bash\\n[nix-shell:.../ghc-wpc/hadrian]$ cd ..\\n\\n[nix-shell:.../ghc-wpc]$ ./boot && ./configure\\n\\n[nix-shell:.../ghc-wpc]$ hadrian/build-stack -j\\n```\\n\\nand go get some coffee since this will take some time. Once it finishes you should have the `ghc-wpc` binary in `_build/stage1/bin`\\n\\n```bash\\n[nix-shell:.../ghc-wpc]$ ls -l _build/stage1/bin/\\ntotal 8592\\n-rwxr-xr-x 1 doyougnu users 1843752 Apr 29 23:01 ghc\\n-rw-r--r-- 1 doyougnu users   11082 Apr 29 23:01 ghc.dyn_o_ghc_stgapp\\n-rwxr-xr-x 1 doyougnu users  660128 Apr 29 22:50 ghc-pkg\\n-rw-r--r-- 1 doyougnu users    9977 Apr 29 22:50 ghc-pkg.dyn_o_ghc_stgapp\\n-rwxr-xr-x 1 doyougnu users 4624680 Apr 29 23:01 haddock\\n-rw-r--r-- 1 doyougnu users   16883 Apr 29 23:01 haddock.dyn_o_ghc_stgapp\\n-rwxr-xr-x 1 doyougnu users   49344 Apr 29 22:25 hp2ps\\n-rw-r--r-- 1 doyougnu users    2504 Apr 29 22:25 hp2ps.dyn_o_ghc_stgapp\\n-rwxr-xr-x 1 doyougnu users  716440 Apr 29 22:35 hpc\\n-rw-r--r-- 1 doyougnu users    9959 Apr 29 22:35 hpc.dyn_o_ghc_stgapp\\n-rwxr-xr-x 1 doyougnu users  738544 Apr 29 22:35 hsc2hs\\n-rw-r--r-- 1 doyougnu users   10264 Apr 29 22:35 hsc2hs.dyn_o_ghc_stgapp\\n-rwxr-xr-x 1 doyougnu users   58384 Apr 29 22:34 runghc\\n-rw-r--r-- 1 doyougnu users    8864 Apr 29 22:34 runghc.dyn_o_ghc_stgapp\\n```\\n\\nNotice that this build dumped `*.<way>_o_ghc_stgapp` files!\\n\\n\\n<a id=\\"org9ef4bc5\\"></a>\\n\\n## Building the stg tooling\\n\\nNow that we have a working `ghc-wpc` we need to build the rest of the project by pointing `stack` to the `ghc-wpc` binary in `ghc-wpc/_build/stage1/bin`. That is, we must change the `ghc-whole-program-compiler-project/stack.yaml` file:\\n\\n```bash\\n[nix-shell:~/programming/haskell/ghc-whole-program-compiler-project]$ cat stack.yaml\\nresolver: lts-16.13\\n\\nallow-newer: true\\n\\npackages:\\n  - \'external-stg-compiler\'\\n  - \'external-stg\'\\n\\nghc-options:\\n  \\"$everything\\": -fno-stgbin -fno-stgapp -optcxx-std=c++17\\n\\nextra-deps:\\n  - async-pool-0.9.1@sha256:4015140f896c3f1652b06a679b0ade2717d05557970c283ea2c372a71be2a6a1,1605\\n  - souffle-haskell-1.1.0\\n  - zip-1.7.0\\n\\n\\n# use custom ext-stg whole program compiler GHC\\ncompiler:     ghc-8.11.0\\nskip-ghc-check: true\\n\\nnix:\\n  enable: false\\n\\n\\n# use local GHC (for development)\\nsystem-ghc: true\\nextra-path:\\n  - /home/doyougnu/programming/haskell/ghc-whole-program-compiler-project/ghc-wpc/_build/stage1/bin\\n\\n# DEBUG INFO\\n#dump-logs: all\\n#build:\\n#  keep-tmp-files: true\\n#  cabal-verbose: true\\n```\\n\\nThe changes are: (1) set `compiler: ghc-8.11.0` (the `ghc-wpc` fork), (2) set `skip-ghc-check: true` so that stack doesn&rsquo;t complain about the ghc version, (3) set `nix.enable: false`, confusingly if you leave this as true then stack will try to use `nixpkgs` to get a ghc binary, but we want it to use our local binary so we disable this even though we&rsquo;ll still be in our original nix-shell (4) set `system-path: true` to tell stack we will be using a ghc we have on our system, and finally (5) set `extra-path: <path-to-ghc-wpc-binary>`.\\n\\nNow we can run stack and install the stg tooling:\\n\\n```bash\\n[nix-shell:...]$ stack --stack-root `pwd`/.stack-root install\\nTrouble loading CompilerPaths cache: UnliftIO.Exception.throwString called with:\\n\\nCompiler file metadata mismatch, ignoring cache\\nCalled from:\\n  throwString (src/Stack/Storage/User.hs:277:8 in stack-2.7.5-9Yv1tjrmAU3JiZWCo86ldN:Stack.Storage.User)\\n\\nWARNING: Ignoring tagged\'s bounds on template-haskell (>=2.8 && <2.17); using template-haskell-2.17.0.0.\\nReason: allow-newer enabled.\\nWARNING: Ignoring aeson\'s bounds on template-haskell (>=2.9.0.0 && <2.17); using template-haskell-2.17.0.0.\\nReason: allow-newer enabled.\\nWARNING: Ignoring th-abstraction\'s bounds on template-haskell (>=2.5 && <2.17); using template-haskell-2.17.0.0.\\nReason: allow-newer enabled.\\nWARNING: Ignoring unliftio-core\'s bounds on base (>=4.5 && <4.14); using base-4.14.0.0.\\nReason: allow-newer enabled.\\nWARNING: Ignoring souffle-haskell\'s bounds on megaparsec (>=7.0.5 && <8); using megaparsec-8.0.0.\\nstack --stack-root `pwd`/.stack-root install\\n... # bunch of output\\n...\\n...\\nCopied executables to /home/doyougnu/.local/bin:\\n- dce-fullpak\\n- ext-stg\\n- fullpak\\n- gen-exe\\n- gen-exe2\\n- gen-obj\\n- gen-obj2\\n- mkfullpak\\n- show-ghc-stg\\n\\nWarning: Installation path /home/doyougnu/.local/bin not found on the PATH environment variable.\\n```\\n\\nYou can add `~/.local/bin` to your `PATH` if you want, I&rsquo;ll just be directly referencing these binaries as we go.\\n\\n\\n<a id=\\"org4a2eaf9\\"></a>\\n\\n# Building the external-stg-interpreter\\n\\nWe are almost all done, all that is left is to build the external-stg-interpreter and run a small script that links everything together into a shared object for the interpreter. So:\\n\\n```bash\\n[nix-shell:...]$ cd external-stg-interpreter/\\n\\n[nix-shell:.../external-stg-interpreter]$ stack install\\n...  # bunch of output\\n...\\nCopied executables to /home/doyougnu/.local/bin:\\n- ext-stg\\n- ext-stg-interpreter\\n- fullpak\\n- mkfullpak\\n\\nWarning: Installation path /home/doyougnu/.local/bin not found on the PATH environment variable.\\n```\\n\\nNow we have our `ext-stg-interpreter` built! There are a few caveats I want to point out here. I&rsquo;ve modified `ghc-whole-program-compiler-project/external-stg-interpreter/stack.yaml` to load the right packages and use nix:\\n\\n```bash\\n[nix-shell:.../external-stg-interpreter]$ cat stack.yaml\\nresolver: lts-16.13\\n\\npackages:\\n  - \'.\'\\n  - \'external-stg\'\\n\\nextra-deps:\\n  - souffle-haskell-2.1.0\\n  - primitive-0.7.1.0\\n  - zip-1.7.0\\n\\nnix:\\n  enable: true\\n  packages: [ zlib, libffi, pkg-config, bzip2 ]\\n```\\n\\nNotice the `nix:` block. We could have just as easily built this using `nix` directly or using our `shell.nix` file.\\n\\n\\n<a id=\\"org1d34a2e\\"></a>\\n\\n# Linking the external-stg-interpreter\\n\\nThe only task left is to link into a shared object library called\\n`libHSbase-4.14.0.0.cbits.so`. To do that we need to use the script called, `c`,\\nin `ghc-whole-program-compiler-project/external-stg-interpreter/data`. This\\nscript is a bit of a hack, it generates the shared object file so that we can link the symbols requested by the C\\nFFI in `base`, but it populates those functions with our replacements, which do absolutely nothing. For example, we supply a fake garbage collect:\\n```c\\n// in .../external-stg-interpreter/data/cbits.so-script/c-src/fake_rts.c\\n...\\nvoid performGC(void) {\\n}\\n\\nvoid performMajorGC(void) {\\n}\\n...\\n```\\n\\nThis works because we won\'t be using the runtime system at all, we\'ll be using\\nthe external STG interpreter instead, however we still need to provide these\\nsymbols in order to link. ****MAJOR NOTE: this file must be next to any\\n\\\\*.fullpak file you&rsquo;ll be running the interpreter on**** or else\\nyou&rsquo;ll get an undefined symbol error during linking, for example:\\n\\n```bash\\n[nix-shell:.../external-stg-interpreter/data]$ ls\\ncbits.so-script  ghc-rts-base.fullpak  minigame-strict.fullpak\\n\\n### notice no .so file\\n[nix-shell:.../external-stg-interpreter/data]$ ~/.local/bin/ext-stg-interpreter ghc-rts-base.fullpak\\next-stg-interpreter: user error (dlopen: ./libHSbase-4.14.0.0.cbits.so: cannot open shared object file: No such file or directory)\\n\\n## we error\'d out because it was missing, also\\n## if you get this error then you have an old cbits.so file and need to rerun the c script\\n[nix-shell:.../external-stg-interpreter/data]$ ~/.local/bin/ext-stg-interpreter ghc-rts-base.fullpak\\next-stg-interpreter: user error (dlopen: ./libHSbase-4.14.0.0.cbits.so: undefined symbol: getProcessElapsedTime)\\n```\\n\\nTo link the interpreter we need to run `c` in the `data/cbits.so-script` sub-folder:\\n\\n```bash\\n[nix-shell:.../external-stg-interpreter]$ cd data/cbits.so-script/\\n\\n[nix-shell:.../external-stg-interpreter/data/cbits.so-script]$ ls\\nar  c  cbits-rts.dyn_o  c-src  libHSbase-4.14.0.0.cbits.so  stub-base.dyn_o\\n\\n[nix-shell:.../external-stg-interpreter/data/cbits.so-script]$ ./c\\n++ ls ar/libHSbase-4.14.0.0-ghc8.11.0.20210220.dyn_o_cbits.a ar/libHSbindings-GLFW-3.3.2.0-Jg9TvsfYUZwD0ViIP0H2Tz-ghc8.11.0.20210306.dyn_o_cbits.a ar/libHSbytestring-0.10.9.0-ghc8.11.0.20210306.dyn_o_cbits.a ar/libHScriterion-measurement-0.1.2.0-73BCI2Fnk7qE8QjjTa1xNa-ghc8.11.0.20210324.dyn_o_cbits.a ar/libHSghc-8.11.0.20210306-ghc8.11.0.20210306.dyn_o_cbits.a ar/libHSGLUT-2.7.0.15-1pzTWDEZBcYHcS36qZ2lpp-ghc8.11.0.20201112.dyn_o_cbits.a ar/libHSGLUT-2.7.0.15-1pzTWDEZBcYHcS36qZ2lpp-ghc8.11.0.20210324.dyn_o_stubs.a ar/libHShashable-1.3.0.0-Kn7aNSFvzgo2qY16wYzuCX-ghc8.11.0.20210306.dyn_o_cbits.a ar/libHSinteger-gmp-1.0.3.0-ghc8.11.0.20210220.dyn_o_cbits.a ar/libHSlambdacube-quake3-engine-0.1.0.0-7CKLP3Rqgq0PR81lhlwlR-ghc8.11.0.20210306.dyn_o_cbits.a ar/libHSmersenne-random-pure64-0.2.2.0-ExYg8DmthtrLG9JevQbt2m-ghc8.11.0.20210306.dyn_o_cbits.a ar/libHSOpenGLRaw-3.3.4.0-5vXBlmbOM3AIT7GRYfpE3o-ghc8.11.0.20201112.dyn_o_cbits.a ar/libHSprimitive-0.7.0.1-2k3g9qX0zz16vEv34R307m-ghc8.11.0.20210306.dyn_o_cbits.a ar/libHSprocess-1.6.8.2-ghc8.11.0.20210220.dyn_o_cbits.a ar/libHStext-1.2.4.0-ghc8.11.0.20210220.dyn_o_cbits.a ar/libHSunix-2.7.2.2-ghc8.11.0.20210220.dyn_o_cbits.a ar/libHSunix-2.7.2.2-ghc8.11.0.20210220.dyn_o_stubs.a ar/libHSzlib-0.6.2.1-1I6DmfbLEyTBgDZI7SbZfW-ghc8.11.0.20210306.dyn_o_stubs.a\\n++ ls stub-base.dyn_o/Blank_stub.dyn_o stub-base.dyn_o/ClockGetTime_stub.dyn_o stub-base.dyn_o/Internals_stub.dyn_o stub-base.dyn_o/RUsage_stub.dyn_o\\n++ ls cbits-rts.dyn_o/StgPrimFloat.dyn_o cbits-rts.dyn_o/TTY.dyn_o\\n++ ls c-src/fake_rts.c c-src/hack.c c-src/hschooks.c\\n+ gcc -o libHSbase-4.14.0.0.cbits.so -shared -Wl,--whole-archive ar/libHSbase-4.14.0.0-ghc8.11.0.20210220.dyn_o_cbits.a ar/libHSbindings-GLFW-3.3.2.0-Jg9TvsfYUZwD0ViIP0H2Tz-ghc8.11.0.20210306.dyn_o_cbits.a ar/libHSbytestring-0.10.9.0-ghc8.11.0.20210306.dyn_o_cbits.a ar/libHScriterion-measurement-0.1.2.0-73BCI2Fnk7qE8QjjTa1xNa-ghc8.11.0.20210324.dyn_o_cbits.a ar/libHSghc-8.11.0.20210306-ghc8.11.0.20210306.dyn_o_cbits.a ar/libHSGLUT-2.7.0.15-1pzTWDEZBcYHcS36qZ2lpp-ghc8.11.0.20201112.dyn_o_cbits.a ar/libHSGLUT-2.7.0.15-1pzTWDEZBcYHcS36qZ2lpp-ghc8.11.0.20210324.dyn_o_stubs.a ar/libHShashable-1.3.0.0-Kn7aNSFvzgo2qY16wYzuCX-ghc8.11.0.20210306.dyn_o_cbits.a ar/libHSinteger-gmp-1.0.3.0-ghc8.11.0.20210220.dyn_o_cbits.a ar/libHSlambdacube-quake3-engine-0.1.0.0-7CKLP3Rqgq0PR81lhlwlR-ghc8.11.0.20210306.dyn_o_cbits.a ar/libHSmersenne-random-pure64-0.2.2.0-ExYg8DmthtrLG9JevQbt2m-ghc8.11.0.20210306.dyn_o_cbits.a ar/libHSOpenGLRaw-3.3.4.0-5vXBlmbOM3AIT7GRYfpE3o-ghc8.11.0.20201112.dyn_o_cbits.a ar/libHSprimitive-0.7.0.1-2k3g9qX0zz16vEv34R307m-ghc8.11.0.20210306.dyn_o_cbits.a ar/libHSprocess-1.6.8.2-ghc8.11.0.20210220.dyn_o_cbits.a ar/libHStext-1.2.4.0-ghc8.11.0.20210220.dyn_o_cbits.a ar/libHSunix-2.7.2.2-ghc8.11.0.20210220.dyn_o_cbits.a ar/libHSunix-2.7.2.2-ghc8.11.0.20210220.dyn_o_stubs.a ar/libHSzlib-0.6.2.1-1I6DmfbLEyTBgDZI7SbZfW-ghc8.11.0.20210306.dyn_o_stubs.a -Wl,--no-whole-archive stub-base.dyn_o/Blank_stub.dyn_o stub-base.dyn_o/ClockGetTime_stub.dyn_o stub-base.dyn_o/Internals_stub.dyn_o stub-base.dyn_o/RUsage_stub.dyn_o cbits-rts.dyn_o/StgPrimFloat.dyn_o cbits-rts.dyn_o/TTY.dyn_o -fPIC c-src/fake_rts.c c-src/hack.c c-src/hschooks.c -lm -lgmp -ltinfo -lGL -lX11 -lXi -lXrandr -lXxf86vm -lXcursor -lXinerama -lpthread\\n```\\n\\nThis will produce `libHSbase-4.14.0.0.cbits.so` in the immediate directory:\\n\\n```bash\\n[nix-shell:.../external-stg-interpreter/data/cbits.so-script]$ ls -l\\ntotal 984\\ndrwxr-xr-x 2 doyougnu users   4096 Apr 27 14:10 ar\\n-rwxr-xr-x 1 doyougnu users    300 Apr 27 14:10 c\\ndrwxr-xr-x 2 doyougnu users   4096 Apr 27 14:10 cbits-rts.dyn_o\\ndrwxr-xr-x 2 doyougnu users   4096 Apr 27 14:10 c-src\\n-rwxr-xr-x 1 doyougnu users 986008 Apr 30 11:50 libHSbase-4.14.0.0.cbits.so    ## <----- new\\ndrwxr-xr-x 2 doyougnu users   4096 Apr 27 14:10 stub-base.dyn_o\\n```\\n\\nNow we can test our interpreter by running it on the `*.fullpak` files in `external-stg-interpreter/data`:\\n\\n```bash\\n[nix-shell:.../external-stg-interpreter/data/cbits.so-script]$ cd ..\\n\\n[nix-shell:.../external-stg-interpreter/data]$ ls\\ncbits.so-script  ghc-rts-base-call-graph-summary  ghc-rts-base-call-graph.tsv  ghc-rts-base.fullpak  libHSbase-4.14.0.0.cbits.so  minigame-strict.fullpak\\n\\n## remove the old .so file\\n[nix-shell:.../external-stg-interpreter/data]$ rm libHSbase-4.14.0.0.cbits.so\\n\\n## soft-link to the one we just built\\n[nix-shell:.../external-stg-interpreter/data]$ ln -s cbits.so-script/libHSbase-4.14.0.0.cbits.so libHSbase-4.14.0.0.cbits.so\\n\\n[nix-shell:.../external-stg-interpreter/data]$ ls -l\\ntotal 79220\\ndrwxr-xr-x 6 doyougnu users     4096 Apr 30 11:50 cbits.so-script\\n-rw-r--r-- 1 doyougnu users       48 Apr 30 11:47 ghc-rts-base-call-graph-summary\\n-rw-r--r-- 1 doyougnu users    28238 Apr 30 11:47 ghc-rts-base-call-graph.tsv\\n-rw-r--r-- 1 doyougnu users 22450708 Apr 27 14:10 ghc-rts-base.fullpak\\nlrwxrwxrwx 1 doyougnu users       43 Apr 30 11:55 libHSbase-4.14.0.0.cbits.so -> cbits.so-script/libHSbase-4.14.0.0.cbits.so  ### <---- new\\n-rw-r--r-- 1 doyougnu users 58630129 Apr 27 14:10 minigame-strict.fullpak\\n\\n[nix-shell:.../external-stg-interpreter/data]$ ~/.local/bin/ext-stg-interpreter ghc-rts-base.fullpak\\nhello\\nhello\\nssHeapStartAddress: 53522\\nssTotalLNECount: 69\\nssClosureCallCounter: 360\\nexecuted closure id count: 114\\ncall graph size: 150\\n\\n[nix-shell:.../external-stg-interpreter/data]$ ls -l\\ntotal 79220\\ndrwxr-xr-x 6 doyougnu users     4096 Apr 30 11:50 cbits.so-script\\n-rw-r--r-- 1 doyougnu users       48 Apr 30 11:56 ghc-rts-base-call-graph-summary    ### <---- interpreter output\\n-rw-r--r-- 1 doyougnu users    28238 Apr 30 11:56 ghc-rts-base-call-graph.tsv        ### <---- interpreter output\\n-rw-r--r-- 1 doyougnu users 22450708 Apr 27 14:10 ghc-rts-base.fullpak\\nlrwxrwxrwx 1 doyougnu users       43 Apr 30 11:55 libHSbase-4.14.0.0.cbits.so -> cbits.so-script/libHSbase-4.14.0.0.cbits.so\\n-rw-r--r-- 1 doyougnu users 58630129 Apr 27 14:10 minigame-strict.fullpak\\n```\\n\\nAnd it works, we have two new files, `<foo>-call-graph-summary` and `<foo>-call-graph.tsv` which we can analyze to inspect the behavior of our program (more on this later).\\n\\n\\n<a id=\\"org2daa4b8\\"></a>\\n\\n# The whole setup process on a demo\\n\\nThat was a rather involved example, to make clear the dependencies and steps required to run this on your own code the rest of this tutorial will run the interpreter on two of Csaba&rsquo;s demo&rsquo;s from his skillshare talk. First let&rsquo;s grab the code:\\n\\n```bash\\n$ pwd\\n/home/doyougnu/programming/haskell\\n\\n$ git clone https://github.com/grin-compiler/ext-stg-interpreter-presentation-demos.git\\n\\n$ ls\\next-stg-interpreter-presentation-demos ghc-whole-program-compiler-project ..\\n```\\n\\nNow we&rsquo;ll run the first demo which is a simply fold over a list:\\n\\n```bash\\n$ nix-shell ghc-whole-program-compiler-project/shell.nix\\ntrace: checking if /home/doyougnu/programming/haskell/hadrian/hadrian.cabal is present:  no\\nRecommended ./configure arguments (found in $CONFIGURE_ARGS:\\nor use the configure_ghc command):\\n\\n  --with-gmp-includes=/nix/store/sznfxigwvrvn6ar3nz3f0652zsld9xqj-gmp-6.2.0-dev/include\\n  --with-gmp-libraries=/nix/store/447im4mh8gmw85dkrvz3facg1jsbn6c7-gmp-6.2.0/lib\\n  --with-curses-includes=/nix/store/84g84bg47xxg01ba3nv0h418v5v3969n-ncurses-6.1-20190112-dev/include\\n  --with-curses-libraries=/nix/store/xhhkr936b9q5sz88jp4l29wljbbcg39k-ncurses-6.1-20190112/lib\\n  --with-libnuma-includes=/nix/store/bfrcskjspk9a179xqqf1q9xqafq5s8d2-numactl-2.0.13/include\\n  --with-libnuma-libraries=/nix/store/bfrcskjspk9a179xqqf1q9xqafq5s8d2-numactl-2.0.13/lib\\n  --with-libdw-includes=/nix/store/sv6f05ngaarba50ybr6fdfc7cciv6nbv-elfutils-0.176/include\\n  --with-libdw-libraries=/nix/store/sv6f05ngaarba50ybr6fdfc7cciv6nbv-elfutils-0.176/lib\\n  --enable-dwarf-unwind\\n\\n[nix-shell:~/programming/haskell]$ cd ext-stg-interpreter-presentation-demos/demo-01-tsumupto/\\n\\n[nix-shell:~/programming/haskell/ext-stg-interpreter-presentation-demos/demo-01-tsumupto]$ ../../ghc-whole-program-compiler-project/ghc-wpc/_build/stage1/bin/ghc -O2 tsumupto.hs\\n[1 of 1] Compiling Main             ( tsumupto.hs, tsumupto.o )\\nLinking tsumupto ...\\n$ cd ext-stg-interpreter-presentation-demos/demo-01-tsumupto\\n\\n$ ls\\ntsumupto  tsumupto.hi  tsumupto.hs  tsumupto.o  tsumupto.o_ghc_stgapp  tsumupto.o_modpak\\n```\\n\\nNote, that we have two new files: `*.o_ghc_stgapp` and `.o_modpak` as a result of building with `ghc-wpc`. If you try to run this from outside the nix-shell you&rsquo;ll get an error about missing `mkmodpak`:\\n\\n```bash\\n$ ../../ghc-whole-program-compiler-project/ghc-wpc/_build/stage1/bin/ghc -O2 tsumupto.hs\\n[1 of 1] Compiling Main             ( tsumupto.hs, tsumupto.o )\\nghc: could not execute: mkmodpak\\n```\\n\\nNow that we have those files we can run the interpreter, but first though we need to make a `*.fullpak` file from the `*.o_ghc_stgapp` file and create a symbolic link to `libHSbase-4.14.0.0.cbits.so`:\\n\\n```bash\\n## make the fullpack file\\n$ ~/.local/bin/mkfullpak tsumupto.o_ghc_stgapp\\nall modules: 259\\napp modules: 113\\napp dependencies:\\n... # bunch of output\\n...\\nmain                                                         Main\\ncreating tsumupto.fullpak\\n\\n## create the link to the shared object file\\n$ ln -s ../../ghc-whole-program-compiler-project/external-stg-interpreter/data/cbits.so-script/libHSbase-4.14.0.0.cbits.so libHSbase-4.14.0.0.cbits.so\\n\\n## the final directory should look like this\\n$ ls\\nlibHSbase-4.14.0.0.cbits.so  tsumupto  tsumupto.fullpak  tsumupto.hi  tsumupto.hs  tsumupto.o  tsumupto.o_ghc_stgapp  tsumupto.o_modpak\\n```\\n\\nAnd now we can run the interpreter:\\n\\n```bash\\n$ ~/.local/bin/ext-stg-interpreter tsumupto.fullpak\\n50005000\\nssHeapStartAddress: 44082\\nssTotalLNECount: 43\\nssClosureCallCounter: 30275\\nexecuted closure id count: 112\\ncall graph size: 146\\n```\\n\\nThe first line is the output of the program and the rest are diagnostics that the interpreter outputs. More importantly we should have a tab-separated csv file and call graph file in our local directory after running the interpreter:\\n\\n```bash\\n$ ls -l\\ntotal 23876\\nlrwxrwxrwx 1 doyougnu users      114 Apr 30 12:21 libHSbase-4.14.0.0.cbits.so -> ../../ghc-whole-program-compiler-project/external-stg-interpreter/data/cbits.so-script/libHSbase-4.14.0.0.cbits.so\\n-rwxr-xr-x 1 doyougnu users  9442648 Apr 30 12:12 tsumupto\\n-rw-r--r-- 1 doyougnu users       53 Apr 30 12:23 tsumupto-call-graph-summary   ### <---- interpreter output\\n-rw-r--r-- 1 doyougnu users    27490 Apr 30 12:23 tsumupto-call-graph.tsv       ### <---- interpreter output\\n-rw------- 1 doyougnu users 14922366 Apr 30 12:19 tsumupto.fullpak\\n-rw-r--r-- 1 doyougnu users     1769 Apr 30 12:12 tsumupto.hi\\n-rw-r--r-- 1 doyougnu users      207 Apr 28 22:56 tsumupto.hs\\n-rw-r--r-- 1 doyougnu users     4488 Apr 30 12:12 tsumupto.o\\n-rw-r--r-- 1 doyougnu users     8817 Apr 30 12:12 tsumupto.o_ghc_stgapp\\n-rw------- 1 doyougnu users     9803 Apr 30 12:12 tsumupto.o_modpak\\n```\\n\\nWhich can be loaded into `gephi` for closer inspection of the call graph of our program. Be sure to watch the rest of the demo in Csaba&rsquo;s talk for this part! For now we&rsquo;ll be going over using `gephi` and these files in our next blog post in this series, stay tuned!\\n\\n\\n<a id=\\"org8193a1a\\"></a>\\n\\n# Summary\\n\\n\\n<a id=\\"org940ba90\\"></a>\\n\\n## File Descriptions\\n\\n-   `foo.modpak`: A zip file which contains the Core, STG, CMM, source code, and assembly for the module `foo`\\n-   `foo.fullpak`: A zip file which contains the same information as `modpack` but for every module of the program rather than just module `foo`.\\n-   `foo.o_ghc_stgapp`: a yaml like file that contains:\\n    -   the module&rsquo;s dependencies including package dependencies\\n    -   a bunch of file paths for shared objects of the libraries\\n    -   the flags the module was built with\\n-   `libHSbase-4.14.0.0.cbits.so`: shared object file created by `ext-stg-interpreter/data/cbits.so-script.c`. Required to be in the same directory as `ext-stg-interpreter` will be invoked.\\n\\n\\n<a id=\\"org8e9f409\\"></a>\\n\\n## Step-by-Step guide for running the interpreter on your code\\n\\n1.  Build your project with `ghc-wpc/_build/stage1/bin` by directly invoking that `ghc` (as I did in the demo-01 project) or by pointing stack to it with `system-ghc` and `extra-path` in `stack.yaml`, or by passing `-w <path-to-ghc-wpc-binary` with cabal.\\n2.  Generate the `foo.fullpak` file with `mkfullpak foo.o_ghc_stgapp`\\n3.  Soft-link to `libHSbase-4.14.0.0.cbits.so` in the directory you will run the interpreter in. This file must be present when you run the interpreter!\\n4.  Now run the interpreter on `project.fullpak`\\n5.  Analyze `foo-call-graph-summary` and `foo-call-graph.tsv` with whatever tools make sense to you\\n\\n## Footnotes\\n\\n[^1]: This isn&rsquo;t completely true, there is the `RuntimeRep` type controls\\n  exactly this and the levity polymorphism work by [Richard\\n  Eisenberg](https://richarde.dev/). See [this\\n  video](https://www.youtube.com/watch?v=Mb_B-j8ePfc) for examples on using these\\n  features. We do plan to include a more thorough and real world example on using\\n  levity polymorphism for better performance in the [haskell optimization\\n  handbook](https://github.com/haskellfoundation/tech-proposals/pull/26)."},{"id":"2022-04-28-on-the-inlining-of-integer-and-natural-operations","metadata":{"permalink":"/2022-04-28-on-the-inlining-of-integer-and-natural-operations","source":"@site/blog/2022-04-28-on-the-inlining-of-integer-and-natural-operations-bot8CUQvoe-import.md","title":"On the inlining of Integer and Natural operations","description":"In this post I discuss the inlining of Integer and Natural operations in Haskell. It\u2019s a promising performance work I\u2019ve been conducting six months ago, which was blocked by an independent issue, but that I will likely resume soon as the issue has been fixed in the meantime.","date":"2022-04-28T00:00:00.000Z","formattedDate":"April 28, 2022","tags":[{"label":"ghc","permalink":"/tags/ghc"}],"readingTime":4.135,"truncated":false,"authors":[{"name":"Sylvain Henry","title":"Haskell DevX Engineer @ IOG","email":"sylvain.henry@iohk.io","key":"sylvain"}],"frontMatter":{"slug":"2022-04-28-on-the-inlining-of-integer-and-natural-operations","title":"On the inlining of Integer and Natural operations","authors":["sylvain"],"tags":["ghc"],"custom_edit_url":null},"prevItem":{"title":"Setting up Csaba\'s External STG Interpreter","permalink":"/2022-05-02-setup-ext-stg-interp"},"nextItem":{"title":"GHC March 2022 Update","permalink":"/2022-04-19-ghc-march-2022-update"}},"content":"In this post I discuss the inlining of Integer and Natural operations in Haskell. It\u2019s a promising performance work I\u2019ve been conducting six months ago, which was blocked by an independent issue, but that I will likely resume soon as the issue has been fixed in the meantime.\\n\\n---\\n\\n\\nTo follow this post, you must know that `Natural` numbers are represented as follows in `ghc-bignum`:\\n\\n```haskell\\n-- | Natural number\\n--\\n-- Invariant: numbers <= WORD_MAXBOUND use the `NS` constructor\\ndata Natural\\n   = NS !Word#\\n   | NB !BigNat#\\n```\\n\\nSmall naturals are represented with a `Word#` and large ones with a `BigNat#` (a `ByteArray#`).\\n\\nNow consider the following simple example using Natural:\\n\\n```haskell\\n-- | Add 2 to a Word. Use Natural to avoid Word overflow\\nfoo :: Word -> Natural\\nfoo x = fromIntegral x + 2\\n```\\n\\nThere are only small naturals involved: `fromIntegral x` is small because `x` is a `Word`, and `2` is small. We could hope that GHC would use `Word#` primops to implement this and would allocate a `Natural` heap object for the result *only*. However it\u2019s not what happens currently, even in GHC HEAD. In the following STG dump, we can see that a `Natural` heap object is allocated for `x` before calling `naturalAdd` (`let` bindings in STG reflect heap allocations):\\n\\n```haskell\\nfoo1 = NS! [2##];\\n\\nfoo =\\n    \\\\r [x_sXn]\\n        case x_sXn of {\\n        W# x#_sXp ->\\n        let { sat_sXq = NS! [x#_sXp]; } in  naturalAdd sat_sXq foo1;\\n        };\\n```\\n\\nLet\u2019s look at `naturalAdd`:\\n\\n```haskell\\n-- | Add two naturals\\nnaturalAdd :: Natural -> Natural -> Natural\\n{-# NOINLINE naturalAdd #-}\\nnaturalAdd (NS x) (NB y) = NB (bigNatAddWord# y x)\\nnaturalAdd (NB x) (NS y) = NB (bigNatAddWord# x y)\\nnaturalAdd (NB x) (NB y) = NB (bigNatAdd x y)\\nnaturalAdd (NS x) (NS y) =\\n   case addWordC# x y of\\n      (# l,0# #) -> NS l\\n      (# l,c  #) -> NB (bigNatFromWord2# (int2Word# c) l)\\n```\\n\\nWe are clearly in the last case where both arguments are small. It seems beneficial to allow this function to be inlined. If we did we would get:\\n\\n```javascript\\nfoo =\\n    \\\\r [x_s158]\\n        case x_s158 of {\\n        W# x#_s15a ->\\n        case addWordC# [x#_s15a 2##] of {\\n        (#,#) l_s15c ds_s15d ->\\n        case ds_s15d<TagProper> of ds1_s15e {\\n          __DEFAULT ->\\n              case int2Word# [ds1_s15e] of sat_s15f {\\n              __DEFAULT ->\\n              case bigNatFromWord2# sat_s15f l_s15c of ds2_s15g {\\n              __DEFAULT -> NB [ds2_s15g];\\n              };\\n              };\\n          0# -> NS [l_s15c];\\n        };\\n        };\\n        };\\n```\\n\\nwhich produces much better assembly code, especially if there is no carry:\\n\\n```\\n    addq $2,%rax       ; add 2 to a machine word\\n\\tsetc %bl           ; test the carry.\\n\\tmovzbl %bl,%ebx    ; it could be done\\n\\ttestq %rbx,%rbx    ; more efficiently\\n\\tjne _blk_c17c      ; with \\"jc\\"\\n_blk_c17i:\\n\\tmovq $NS_con_info,-8(%r12) ; alloc NS datacon value\\n\\tmovq %rax,(%r12)           ; with the addition result as payload.\\n\\tleaq -7(%r12),%rbx         ; make it the first argument\\n\\taddq $8,%rbp               ; and then\\n\\tjmp *(%rbp)                ; call continuation\\n...\\n```\\n\\nSo why aren\u2019t we always inlining `naturalAdd`? We even explicitly disallow it with a `NOINLINE` pragma. The reason is that `naturalAdd` and friends are involved in constant-folding rules.\\n\\nFor example, consider:\\n\\n```haskell\\nbar :: Natural -> Natural\\nbar x = x + 2\\n\\nbaz = bar 0x12345678913245678912345679123456798\\n```\\n\\nCurrently we get the following Core:\\n\\n```haskell\\nbar1 = NS 2##\\n\\nbar = \\\\ x_aHU -> naturalAdd x_aHU bar1\\n\\nbaz = NB 99114423092485377935703335253042771879834\\n```\\n\\nYou can see that `baz`  is a constant thanks to constant-folding.\\n\\nHowever if we let `naturalAdd` inline we get:\\n\\n```haskell\\nbaz\\n  = case bigNatAddWord# 99114423092485377935703335253042771879832 2##\\n    of ds_d11H\\n    { __DEFAULT ->\\n    NB ds_d11H\\n    }\\n```\\n\\n`baz` is no longer a constant.\\n\\nA solution would be to add constant-folding rules for `BigNat#` functions, such as `bigNatAddWord#`. This is exactly what we have started doing in [#20361](https://gitlab.haskell.org/ghc/ghc/-/issues/20361). Our new plan is:\\n\\n* Make `BigNat#` operation `NOINLINE` and add constant-folding rules for them\\n* Make Integer/Natural operations `INLINEABLE` (expose their unfolding)\\n* Hence rely on constant-folding for `Word#/Int#/BigNat#` to provide constant folding for `Integer` and `Natural`\\n\\nThe good consequences of this plan are:\\n\\n* Less allocations when bignum operations are inlined and some of the arguments are known to be small/big or fully known (constant).\\n* `Integer` and `Natural` are less magical: you can implement your own similar types and expect the same performance without having to add new rewrite rules\\n\\nThere were some unforeseen difficulties with this plan though:\\n\\n\\n1. Some of the rewrite rules we need involve unboxed values such as `BigNat#` and `Word#` and the weren\u2019t supported. Luckily, this has been recently fixed ([#19313](https://gitlab.haskell.org/ghc/ghc/-/issues/19313)) by removing the \u201capp invariant\u201d ([#20554](https://gitlab.haskell.org/ghc/ghc/-/issues/20554)). Thanks Joachim! That\u2019s the reason why we could resume this work now.\\n2. Some unfoldings (RHSs) become bigger due to the inlining of bignum operations. Hence they may not themselves be inlined further due to inlining thresholds even if it would be beneficial. A better inlining heuristic would fix this (see [#20516](https://gitlab.haskell.org/ghc/ghc/-/issues/20516)). It will likely be the topic of the next post."},{"id":"2022-04-19-ghc-march-2022-update","metadata":{"permalink":"/2022-04-19-ghc-march-2022-update","source":"@site/blog/2022-04-19-ghc-march-2022-update-jeDstmSW5A-import.md","title":"GHC March 2022 Update","description":"JS Backend","date":"2022-04-19T00:00:00.000Z","formattedDate":"April 19, 2022","tags":[{"label":"ghc","permalink":"/tags/ghc"},{"label":"ghc-update","permalink":"/tags/ghc-update"}],"readingTime":2.4,"truncated":false,"authors":[{"name":"Sylvain Henry","title":"Haskell DevX Engineer @ IOG","email":"sylvain.henry@iohk.io","key":"sylvain"}],"frontMatter":{"slug":"2022-04-19-ghc-march-2022-update","title":"GHC March 2022 Update","authors":["sylvain"],"tags":["ghc","ghc-update"],"custom_edit_url":null},"prevItem":{"title":"On the inlining of Integer and Natural operations","permalink":"/2022-04-28-on-the-inlining-of-integer-and-natural-operations"},"nextItem":{"title":"haskell.nix March Update","permalink":"/2022-04-08-haskell-nix-march-update"}},"content":"## JS Backend\\n\\nIn March the team focused on porting more GHCJS code to GHC head.\\n\\n* Most of us are new to GHCJS\u2019s codebase so we are taking some time to better understand it and to better document it as code gets integrated into GHC head.\\n* Development process: initially we had planned to integrate features one after the others into GHC head. However it was finally decided that features would be merged into a [wip/javascript-backend](https://gitlab.haskell.org/ghc/ghc/-/commits/wip/javascript-backend) branch first and then later merged into GHC head. After trying this approach we decided to work directly into another branch: [wip/js-staging](https://gitlab.haskell.org/ghc/ghc/-/commits/wip/js-staging) . Opening merge requests that can\u2019t be tested against a branch that isn\u2019t GHC head didn\u2019t bring any benefit and slowed us too much.\\n* Documentation: we wrote a document comparing the different approaches to target JavaScript/WebAssembly [ https://gitlab.haskell.org/ghc/ghc/-/wikis/javascript](https://gitlab.haskell.org/ghc/ghc/-/wikis/javascript)\\n* RTS: some parts of GHCJS\u2019s RTS are generated from Haskell code, similarly to code generated with the genapply program in the C RTS. This code has been ported to GHC head. As JS linking---especially linking with the RTS---will only be performed by GHC in the short term, we plan to make it generate this code dynamically at link time.\\n* Linker: most of GHCJS\u2019s linker code has been adapted to GHC head. Because of the lack of modularity of GHC, a lot of GHC code was duplicated into GHCJS and slightly modified. Now that both codes have diverged we need to spend some time making them converge again, probably by making the Linker code in GHC more modular.\\n* Adaptation to GHC head: some work is underway to replace GHCJS\u2019s Objectable type-class with GHC\u2019s Binary type-class which serves the same purpose. Similarly a lot of uses of Text have been replaced with GHC\u2019s ShortText or FastString.\\n* Template Haskell: GHCJS has its own TH runner which inspired GHC\u2019s external interpreter (\u201cIserv\u201d) programs. We have been exploring options to port TH runner code as an Iserv implementation. The Iserv protocol uses GADTs to represent its messages which requires more boilerplate code to convert them into JS because we can\u2019t automatically derive aeson instances for them.\\n* Plugins: we have an MR adding support for \u201cexternal static plugins\u201d to GHC [!7377](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7377). Currently it only supports configuring plugins *via* environment variables. We have been working on adding support for command-line flags instead.\\n* Testsuite: we have fixed GHC\u2019s build system so that it can run GHC\u2019s testsuite when GHC is built as a cross-compiler ([!7850](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7850)). There is still some work to do (tracked in [#21292](https://gitlab.haskell.org/ghc/ghc/-/issues/21292)) to somehow support tests that *run* compiled programs: with cross-compilers, target programs can\u2019t be directly executed by the host architecture.\\n\\n## Misc\\n\\n* [Performance book](https://github.com/haskellfoundation/tech-proposals/pull/26): some time was spent on the infrastructure (CI) and on switching the format of the book to ReStructured Text\\n* Modularity: some time was spent discussing GHC\u2019s design and refactoring (c.f. [!7442](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7442) and [#20927](https://gitlab.haskell.org/ghc/ghc/-/issues/20927))."},{"id":"2022-04-08-haskell-nix-march-update","metadata":{"permalink":"/2022-04-08-haskell-nix-march-update","source":"@site/blog/2022-04-08-haskell-nix-march-update-XOLP1OBCuw-import.md","title":"haskell.nix March Update","description":"Changes","date":"2022-04-08T00:00:00.000Z","formattedDate":"April 8, 2022","tags":[{"label":"nix","permalink":"/tags/nix"}],"readingTime":1.99,"truncated":false,"authors":[],"frontMatter":{"slug":"2022-04-08-haskell-nix-march-update","title":"haskell.nix March Update","authors":[],"tags":["nix"],"custom_edit_url":null},"prevItem":{"title":"GHC March 2022 Update","permalink":"/2022-04-19-ghc-march-2022-update"},"nextItem":{"title":"GHC February 2022 Update","permalink":"/2022-03-09-ghc-february-2022-update"}},"content":"## Changes\\n\\n* To cross compile Haskell code for windows a `wine` process must be used to evaluate Template Haskell code at compile time.  Some times this code needs DLLs to be present for the Template Haskell code to run.  We had been maintaining a list of DLLs manually ([#1400](https://github.com/input-output-hk/haskell.nix/pull/1400) for instance added `secp256k1`).  A more general solution ([#1405](https://github.com/input-output-hk/haskell.nix/pull/1405)) was found that uses the `pkgsHostTarget` environment variable to obtain a list of all the packages dependencies.  Then the DLLs from the are made available to the `wine` process running the Template Haskell code.  This should make more libraries build correctly while reducing unnecessary dependencies.\\n* The way Haskell.nix cleans source trees has changed with [#1403](https://github.com/input-output-hk/haskell.nix/pull/1403), [#1409](https://github.com/input-output-hk/haskell.nix/pull/1409) and [#1418](https://github.com/input-output-hk/haskell.nix/pull/1418).  When using Nix `>=2.4` source in the store is now filtered in the same way it is locally.  This has a couple of key advantages:\\n  * It makes it less likely that results on CI systems (where the source is likely to be in the store) will differ from results for local builds (where the source is in a cloned git repository).\\n  * Potential for reducing load on CI.  Although more work may be needed, this kind of filtering combined with the experimental content addressing features of Nix reduce the required rebuilds.\\n* In the past rather cryptic error messages were given when an attempt was made to use an old version of GHC on a platform Haskell.nix did not support it.  In some cases Haskell.nix would even attempt to build GHC and only fail after some time.  Better error messages are now given right away when an attempt is made to use a GHC version that is not supported for a particular platform [#1411](https://github.com/input-output-hk/haskell.nix/pull/1411)\\n\\n## Version Updates\\n\\n* GHC 9.2.2 was added [#1394](https://github.com/input-output-hk/haskell.nix/pull/1394)\\n\\n## Bug fixes\\n\\n* `gitMinimal` replaces `git` to reduce the dependency tree of `cabalProject` functions [#1387](https://github.com/input-output-hk/haskell.nix/pull/1387)\\n* Less used of `allowSubstitutes=false` [#1389](https://github.com/input-output-hk/haskell.nix/pull/1389)\\n* Fixed `aarch64-linux` builds by using correct boot compiler [#1390](https://github.com/input-output-hk/haskell.nix/pull/1390)\\n* `icu-i18n` package mapping added to make `text-icu` build [#1395](https://github.com/input-output-hk/haskell.nix/pull/1395)\\n* Fixes needed for newer `nixpkgs` versions\\n  * Use list for `configureFlags` [#1396](https://github.com/input-output-hk/haskell.nix/pull/1396)\\n  * The spdx json file is in a `.json` output [#1397](https://github.com/input-output-hk/haskell.nix/pull/1397)\\n  * `gdk_pixbuf` is now `gdk-pixbuf` [#1398](https://github.com/input-output-hk/haskell.nix/pull/1398)\\n* Replaced deprecated NixOS binary cache settings in docs [#1410](https://github.com/input-output-hk/haskell.nix/pull/1410)\\n* Enable static build of `secp256k1` on musl [#1413](https://github.com/input-output-hk/haskell.nix/pull/1413)\\n\\nFinally, we\u2019d like to thank all the awesome contributors, who make\xa0`haskell.nix`\xa0a thriving open source project!\xa0:heart:"},{"id":"2022-03-09-ghc-february-2022-update","metadata":{"permalink":"/2022-03-09-ghc-february-2022-update","source":"@site/blog/2022-03-09-ghc-february-2022-update-bnE9FHoNRc-import.md","title":"GHC February 2022 Update","description":"JS backend","date":"2022-03-09T00:00:00.000Z","formattedDate":"March 9, 2022","tags":[{"label":"ghc","permalink":"/tags/ghc"},{"label":"ghc-update","permalink":"/tags/ghc-update"}],"readingTime":1.87,"truncated":false,"authors":[{"name":"Sylvain Henry","title":"Haskell DevX Engineer @ IOG","email":"sylvain.henry@iohk.io","key":"sylvain"}],"frontMatter":{"slug":"2022-03-09-ghc-february-2022-update","title":"GHC February 2022 Update","authors":["sylvain"],"tags":["ghc","ghc-update"],"custom_edit_url":null},"prevItem":{"title":"haskell.nix March Update","permalink":"/2022-04-08-haskell-nix-march-update"},"nextItem":{"title":"2021 GHC update","permalink":"/2022-03-01-2021-ghc-update"}},"content":"## JS backend\\n\\nThis month we worked on adapting code from GHCJS to merge into GHC head. We also started discussing the implementation process publicly and especially with our colleagues at Well-Typed.\\n\\n* Ticket about adapting GHCJS\u2019 code into a proper JS backend for GHC has been opened \\\\[[#21078](https://gitlab.haskell.org/ghc/ghc/-/issues/21078)\\\\]. Feedback was very positive!\\n* There were discussions about the process and an agreement to target GHC 9.6 release \\\\[[email on ghc-devs](https://mail.haskell.org/pipermail/ghc-devs/2022-February/020580.html), [wiki page](https://gitlab.haskell.org/ghc/ghc/-/wikis/javascript-backend)\\\\]\\n* `deriveConstants` is a program used to generate some header file included in the rts package. While it is mainly useful for native targets, we had to make it support Javascript targets \\\\[[!7585](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7585)\\\\]\\n* Javascript is going to be the first official target platform supported by GHC that has its own notion of managed heap objects. Hence we may need a new `RuntimeRep` to represent these values for Haskell codes interacting with JS codes via FFI. We opened [!7577](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7577) into which we tried to make this new `RuntimeRep` non JS specific so that it could be reused for future backends targeting other managed platforms (e.g. CLR, JVM). It triggered a lot of discussions summarized in [#21142](https://gitlab.haskell.org/ghc/ghc/-/issues/21142).\\n* GHCJS\u2019s code generator was ported to GHC head \\\\[[!7573](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7573)\\\\]. In its current state, we can generate Javascript unoptimised code -- the optimiser hasn\u2019t been ported yet -- by compiling a module with `-c -fjavascript`. It required many changes, not only to adapt to changes between GHC 8.10 and GHC head but also to avoid adding new package dependencies. It was also an opportunity to refactor and to document the code, which is still a work in progress.\\n* GHC doesn\u2019t use any lens library, hence to port the code generator we had to replace lenses with usual record accessors. It turned out that `case` alternatives in STG lacked them because they were represented with a triple. We took the opportunity to introduce a proper record type for them  [!7652](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7652)\\n\\n## Plutus-apps JS demo\\n\\n* We improved the proof of concept JavaScript library for generating Plutus transactions with a given set of constraints and lookups, exposing functionality from the `plutus-ledger-constraints` package. \\\\[[Report](https://github.com/hamishmack/plutus-apps/blob/1f331225853f502807aab370f82ec975bdec38ee/plutus-pab/mktx/README.md)\\\\]\\n\\n## Reporting\\n\\n* we wrote a blog post about the work we have done in 2021 as it wasn\u2019t covered anywhere else: <https://engineering.iog.io/2022-03-01-2021-ghc-update>"},{"id":"2022-03-01-2021-ghc-update","metadata":{"permalink":"/2022-03-01-2021-ghc-update","source":"@site/blog/2022-03-01-2021-ghc-update-g8gkJay36G-import.md","title":"2021 GHC update","description":"IOG is committed to improving Haskell developer experience, both by sponsoring the Haskell Foundation and by directly founding a team committed to this task: the Haskell DX team.","date":"2022-03-01T00:00:00.000Z","formattedDate":"March 1, 2022","tags":[{"label":"ghc","permalink":"/tags/ghc"},{"label":"ghc-update","permalink":"/tags/ghc-update"}],"readingTime":8.415,"truncated":false,"authors":[{"name":"Sylvain Henry","title":"Haskell DevX Engineer @ IOG","email":"sylvain.henry@iohk.io","key":"sylvain"}],"frontMatter":{"slug":"2022-03-01-2021-ghc-update","title":"2021 GHC update","authors":["sylvain"],"tags":["ghc","ghc-update"],"custom_edit_url":null},"prevItem":{"title":"GHC February 2022 Update","permalink":"/2022-03-09-ghc-february-2022-update"},"nextItem":{"title":"haskell.nix February Update","permalink":"/2022-03-01-haskell-nix-february-update"}},"content":"IOG is committed to improving Haskell developer experience, both by [sponsoring the Haskell Foundation](https://iohk.io/en/blog/posts/2020/11/04/iohk-sponsors-new-haskell-foundation) and by directly founding a team committed to this task: the Haskell DX team.\\n\\nThe team now tries to provide regular (monthly) updates about its work. This post is a bit longer because it covers all of 2021 which has not been covered anywhere else.\\n\\n## Code generation\\n\\n* Added a new backend for AArch64 architectures, especially to support Apple\u2019s M1. Previously AArch64 was only supported via the LLVM based backend which is much slower. \\\\[[!5884](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5884)\\\\]\\n* Added support for Apple\u2019s M1 calling convention. In GHC 9.2.1 it implied making lifted sized types (e.g. `Word8`, `Int16`...) use their unlifted counterparts (e.g. `Word8#`, `Int16#`...); in GHC 8.10.7 \u2013 a minor release \u2013\xa0 a less invasive but more fragile solution was implemented \\\\[[commit](https://gitlab.haskell.org/ghc/ghc/-/commit/c49250d88915db6acf88d2574db827cc2c4fa080)\\\\].\\n* Fixed a very old GHC issue \\\\[[#1257](https://gitlab.haskell.org/ghc/ghc/-/issues/1257)\\\\] by making GHCi support unboxed values \\\\[[!4412](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/4412)\\\\]: ByteCode is now generated from STG instead of directly from Core. It allows more Haskell codes to be supported by HLS and it even allows GHC code to be loaded into GHCi \\\\[[link](https://mail.haskell.org/pipermail/ghc-devs/2021-October/020345.html)\\\\].\\n* Fixed a bug in the Cmm sinking pass that led to register corruption at runtime with the C backend. Even if we don\u2019t use the C backend, fixing this avoided spurious errors in CI jobs using it \\\\[[#19237](https://gitlab.haskell.org/ghc/ghc/-/issues/19237),[!5755](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5755/)\\\\]\\n* Fixed a register clobbering issue for 64-bit comparisons generated with the 32-bit x86 NCG backend \\\\[[commit](https://gitlab.haskell.org/ghc/ghc/-/commit/ecd6d14215eb40ac441c075e432ddaa0237f3c72)\\\\].\\n* Fixed generation of switches on sized literals in StgToCmm \\\\[[!6211](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6211)\\\\]\\n* Fixed LLVM shifts \\\\[[#19215](https://gitlab.haskell.org/ghc/ghc/-/issues/19215),[!4822](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/4822)\\\\]\\n\\n## Linker\\n\\n* Fixed an off-by-one error in the MachO (Darwin) linker \\\\[[!6041](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6041/)\\\\]. The fix is simple but the debugging session was epic!\\n* Fix to avoid linking plugin units unconditionally with target code, which is wrong in general but even more so when GHC is used as a cross-compiler: plugins and target code aren\u2019t for the same platform \\\\[[#20218](https://gitlab.haskell.org/ghc/ghc/-/issues/20218),[!6496](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6496)\\\\]\\n\\n## Cross-compilation\\n\\n* With John Ericson (Obsidian Systems) we finally made GHC independent of its target \\\\[[!6791](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6791),[!6539](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6539)\\\\]. It means that there is no need to rebuild GHC to make it target another platform, so it now becomes possible to add support for a `--target=...` command-line flag \\\\[[#11470](https://gitlab.haskell.org/ghc/ghc/-/issues/11470)\\\\]. It also means that a cross-compiling GHC could build plugins for its host platform in addition to building code for its target platform.\\n* A side-effect of the previous bullet is that primops\u2019 types are now platform independent. Previously some of them would use Word64 on 32-bit architectures and Word on 64-bit architectures: now Word64 is used on every platform. A side-effect of this side-effect is that we had to make Word64 as efficient as Word: it now benefits from the same optimizations (constant folding [#19024](https://gitlab.haskell.org/ghc/ghc/-/issues/19024), etc.). On 32-bit platforms, it reduced allocations by a fair amount in some cases: e.g. -25.8% in T9203 test and -11.5% when running haddock on base library \\\\[[!6167](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6167)\\\\]. We hope it will benefit other 32-bit architectures such as JavaScript or WebAssembly.\\n* GHC built as a cross-compiler doesn\u2019t support compiler plugins \\\\[[#14335](https://gitlab.haskell.org/ghc/ghc/-/issues/14335)\\\\]. We have been working on refactoring GHC to make it support two separate environments in a given compiler session \u2013 one for target code and another for the plugin/compiler code. The implementation in \\\\[[!6748](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6748)\\\\] conflicts quite a lot with the support of multiple home-units that was added at about the same time. GHC needs to be refactored a lot more to correctly support this approach, so instead we implemented a different approach to load plugins which is more low-level and bypasses the issue \\\\[[#20964](https://gitlab.haskell.org/ghc/ghc/-/issues/20964), [!7377](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7377)\\\\].\\n* We made GHC consider the target platform instead of the host platform in guessOutputFile \\\\[[!6116](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6116)\\\\]\\n* Use target platform instead of host platform to detect literal overflows \\\\[[#17336](https://gitlab.haskell.org/ghc/ghc/-/issues/17336),[!4986](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/4986)\\\\]\\n\\n## GHCJS\\n\\n* We updated GHCJS to use GHC 8.10.7 \\\\[[branch](https://github.com/ghcjs/ghcjs/tree/ghc-8.10)\\\\]\\n* We worked on making GHCJS\u2019s codebase more suitable for integration into GHC: reducing the number of dependencies, avoiding the use of Template Haskell, reusing GHC\u2019s build system, etc. There is now a GHCJS integrated into a GHC 8.10.7 fork \\\\[[branch](https://github.com/ghcjs/ghc/tree/ghc-8.10-ghcjs)\\\\].\\n* This experience led us to plan the realization of a JS backend into GHC head based on GHCJS. More information about this topic in our next report.\\n* We worked on making GHC\u2019s testsuite pass with GHCJS, triaging tests that legitimately fail on a JS platform from tests revealing real GHCJS issues. **\\\\[LINK\\\\]**\\n\\n## Windows\\n\\n* We seemed to be the first to try to build GHC on Windows with the updated GNU autotools 2.70 and this release made a breaking change to the way auxiliary files (config.guess, config.sub) were handled, breaking GHC\u2019s build ([#19189](https://gitlab.haskell.org/ghc/ghc/-/issues/19189#note_332168)). The root cause of the issue couldn\u2019t be easily solved so we modified GHC\u2019s build system to avoid the use of these auxiliary files, bypassing the issue. Most GHC devs won\u2019t ever notice that something was broken to begin with when they will update their GNU toolchain on Windows. \\\\[[!4768](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/4768),[!4987](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/4987),[!5065](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5065/)\\\\]\\n* Fixed cross-compilation of GHC from Linux to Windows using Hadrian \\\\[[#20657](https://gitlab.haskell.org/ghc/ghc/-/issues/20657),[!6945](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6945),[!6958](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6958)\\\\]\\n\\n## Numeric\\n\\n* Fixed Natural to Float/Double conversions to align with the method used for Integer to Float/Double and added missing rewrite rules \\\\[[!6004](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6004/)\\\\]\\n* Made most bignum literals be desugared into their final form in HsToCore stage instead of CoreToStg stage to ensure that Core optimizations were applied correctly to them \\\\[[#20245](https://gitlab.haskell.org/ghc/ghc/-/issues/20245),[!6376](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6376)\\\\]\\n* Some constant folding rules were missing and were added:\\n  * bitwise `and` primops when applied to a full mask (e.g. 0xFF for a 8-bit word). \\\\[[#20448](https://gitlab.haskell.org/ghc/ghc/-/issues/20448),[!6629](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6629)\\\\]\\n  * `negate` primops [#20347](https://gitlab.haskell.org/ghc/ghc/-/issues/20347),[!6535](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6535)\\n  * `timesInt2#` primop [#20374](https://gitlab.haskell.org/ghc/ghc/-/issues/20374),[!6531](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6531)\\n  * `ctz#/clz#/popCnt#` [#20376](https://gitlab.haskell.org/ghc/ghc/-/issues/20376),[!6532](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6532)\\n  * missing rewrite rule to make the implementation of `nat2Word#` efficient \\\\[[#15547](https://gitlab.haskell.org/ghc/ghc/-/issues/15547),[!6847](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6847)\\\\]\\n  * rules for `Natural` \\\\[[#15821](https://gitlab.haskell.org/ghc/ghc/-/issues/15821),[!4837](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/4837)\\\\]\\n* Allowed some ghc-bignum operations to inline to get better performance, while still managing to keep constant-folding working \\\\[[#19641](https://gitlab.haskell.org/ghc/ghc/-/issues/19641),[!6677](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6677),[!6696](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6696),[!6306](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6306)\\\\]. There is some work left to do (cf [#20361](https://gitlab.haskell.org/ghc/ghc/-/issues/20361)) but it is blocked by [#19313](https://gitlab.haskell.org/ghc/ghc/-/issues/19313) which in turn is blocked by [#20554](https://gitlab.haskell.org/ghc/ghc/-/issues/20554) which should be fixed soon ([!6865](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6865), thanks Joachim!).\\n* The ubiquitous `fromIntegral` function used to have many associated rewrite rules to make it fast (avoiding heap allocation of a passthrough Integer when possible) that were difficult to manage due to the combinatorial number of needed rules ([#19907](https://gitlab.haskell.org/ghc/ghc/-/issues/19907), [#20062](https://gitlab.haskell.org/ghc/ghc/-/issues/20062)). We found a way to remove all these rules ([!5862](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5862)).\\n\\n## Technical debt & modularity\\n\\n* Made several component of the compiler independent of `DynFlags` (parsed command-line flags):\\n  * TmpFS (dealing with temporary files) \\\\[[!6186](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6186)\\\\]\\n  * Diagnostic options \\\\[[!6043](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6043)\\\\]\\n  * Tracing functions \\\\[[!5970](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5970)\\\\]\\n  * Logger \\\\[[!4757](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/4757)\\\\]\\n  * Logger & Parser \\\\[[!5845](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5845)\\\\]\\n  * Hooks \\\\[[!4812](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/4812)\\\\]\\n* Made the handling of \u201cpackage imports\u201d less fragile \\\\[[!6586](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6586)\\\\] and refactored some code related to dependencies and recompilation avoidance \\\\[[!6528](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6528),[!6346](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6346)\\\\].\\n* Abstracted plugin related fields from HscEnv \\\\[[!7175](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7175)\\\\]\\n* Made a home-unit optional in several places \\\\[[!7013](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7013/)\\\\]: the home-unit should only be required when compiling code, not when loading code (e.g. when loading plugins in cross-compilers [#14335](https://gitlab.haskell.org/ghc/ghc/-/issues/14335)).\\n* Made GHC no longer expose the (wrong) selected ghc-bignum backend with `ghc --info`. ghc-bignum now exposes a backendName function for this purpose \\\\[[#20495](https://gitlab.haskell.org/ghc/ghc/-/issues/20495),[!6903](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6903)\\\\]\\n* Moved `tmpDir` from Settings to `DynFlags` \\\\[[!6297](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6297/)\\\\]\\n* Removed use of `unsafePerfomIO` in `getProgName` \\\\[[!6137](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6137/)\\\\]\\n* Refactored warning flags handling \\\\[[!5815](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5815)\\\\]\\n* Made assertions use normal functions instead of CPP \\\\[[!5693](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5693)\\\\]\\n* Made the interpreter more independent of the driver \\\\[[!5627](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5627)\\\\]\\n* Replaced `ptext . sLit` with `text` \\\\[[!5625](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5625)\\\\]\\n* Removed broken \u201cdynamic-by-default\u201d setting \\\\[[#16782](https://gitlab.haskell.org/ghc/ghc/-/issues/16782),[!5467](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5467)\\\\]\\n* Abstracted some components from the compiler session state (`HscEnv`):\\n  * unit-related fields into a new `UnitEnv`datatype \\\\[[!5425](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5425)\\\\]\\n  * `FinderCache` and `NameCache`\\\\[[!4951](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/4951)\\\\]\\n  * Loader state \\\\[[!5287](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5287)\\\\]\\n* Removed the need for a home unit-id to initialize an external package state (EPS) \\\\[[!5043](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5043)\\\\]\\n* Refactored `-dynamic-too` handling \\\\[[#19264](https://gitlab.haskell.org/ghc/ghc/-/issues/19264),[!4905](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/4905)\\\\]\\n\\n## Performance\\n\\n* Made `divInt#, modInt# and divModInt#` branchless and inlineable \\\\[[#18067](https://gitlab.haskell.org/ghc/ghc/-/issues/18067),[#19636](https://gitlab.haskell.org/ghc/ghc/-/issues/19636),[!3229](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/3229)\\\\]\\n* Fixed Integral instances for Word8/16/32 and `showWord` to use `quotRemWordN` \\\\[[!5891](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5891),[!5846](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5846/)\\\\]\\n* Improved performance of occurrence analysis \\\\[[#19989](https://gitlab.haskell.org/ghc/ghc/-/issues/19989),[!5977](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5977)\\\\]\\n* Fixed unnecessary pinned allocations in `appendFS` \\\\[[!5989](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5989/)\\\\]\\n* Added a rewrite rules for string literals:\\n  * Concatenation of string literals \\\\[[#20174](https://gitlab.haskell.org/ghc/ghc/-/issues/20174),[#16373](https://gitlab.haskell.org/ghc/ghc/-/issues/16373),[!6259](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6259)\\\\]\\n  * `(++) . unpackCString# \u21d2 unpackAppendCString#` leading to a 15% reduction in compilation time on a specific example. \\\\[[!6619](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6619)\\\\]\\n  * Compute SDoc literal size at compilation time \\\\[[#19266](https://gitlab.haskell.org/ghc/ghc/-/issues/19266), [!4901](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/4901)\\\\]\\n* Fix for Dwarf strings generated by the NCG that were unnecessarily retained in the FastString table \\\\[[!6621](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6621)\\\\]\\n* Worked on improving inlining heuristics by taking into account applied constructors at call sites \\\\[[#20516](https://gitlab.haskell.org/ghc/ghc/-/issues/20516),[!6732](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6732)\\\\]. More work is needed though.\\n* Fixed [#20857](https://gitlab.haskell.org/ghc/ghc/-/issues/20857) by making the Id cache for primops used more often \\\\[[!7241](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7241)\\\\]\\n* Replaced some avoidable uses of `replicateM . length` with more efficient code \\\\[[!7198](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7198)\\\\]. No performance gain this time but the next reader of this code won\u2019t have to wonder if fixing it could improve performance.\\n* Made `exprIsCheapX` inline for modest but easy perf improvements \\\\[[!7183](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7183)\\\\]\\n* Removed an allocation in the code used to write text on a Handle (used by putStrLn, etc.) \\\\[[!7160](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7160)\\\\]\\n* Replaced inefficient list operations with more efficient `Monoid ([a],[b])` operations in the driver \\\\[[!7069](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7069)\\\\], leading to 1.9% reduction in compiler allocations in MultiLayerModules test.\\n* Disabled some callstack allocations in non-debug builds \\\\[[!6252](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6252/)\\\\]\\n* Made file copy in GHC more efficient \\\\[[!5801](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5801)\\\\]\\n* Miscellaneous pretty-printer enhancements \\\\[[!5226](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5226)\\\\]\\n* Type tidying perf improvements with strictness \\\\[[#14738](https://gitlab.haskell.org/ghc/ghc/-/issues/14738),[!4892](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/4892)\\\\]\\n\\n## RTS\\n\\n* Fixed issues related to the RTS\u2019s ticker\\n  * Fixed some races \\\\[[#18033](https://gitlab.haskell.org/ghc/ghc/-/issues/18033),[#20132](https://gitlab.haskell.org/ghc/ghc/-/issues/20132),[!6201](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6201)\\\\]\\n  * Made the RTS open the file descriptor for its timer (`timerfd`) on Linux synchronously to avoid weird interactions with Haskell code manipulating file descriptors \\\\[[#20618](https://gitlab.haskell.org/ghc/ghc/-/issues/20618),[!6902](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6902)\\\\].\\n* Moved GHC\u2019s global variables used to manage Uniques into the RTS to fix plugin issues \\\\[[#19940](https://gitlab.haskell.org/ghc/ghc/-/issues/19940),[!5900](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5900)\\\\]\\n\\n## Build system / CI\\n\\n* Fixed Hadrian output to display warnings and errors after the multi screen long command lines \\\\[[#20490](https://gitlab.haskell.org/ghc/ghc/-/issues/20490),[!6690](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/6690)\\\\]\\n* Avoided the installation of a global `platformConstants` file; made GHC load constants from the RTS unit instead, allowing it to be reinstalled with different constants \\\\[[!5427](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5427)\\\\]\\n* Made `deriveConstants` output its file atomically \\\\[[#19684](https://gitlab.haskell.org/ghc/ghc/-/issues/19684),[!5520](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5520)\\\\]\\n* Made compression with `xz` faster on CI \\\\[[!5066](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5066)\\\\]\\n* Don\u2019t build extra object with `-no-hs-main` \\\\[[#18938](https://gitlab.haskell.org/ghc/ghc/-/issues/18938),[!4974](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/4974)\\\\]\\n* Add `hi-boot` dependencies with `ghc -M` \\\\[[#14482](https://gitlab.haskell.org/ghc/ghc/-/issues/14482),[!4876](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/4876)\\\\]\\n\\n## Misc\\n\\n* Stack: fixed interface reading in `hi-file-parser` to support GHC 8.10 and 9.0 \\\\[[PR](https://github.com/commercialhaskell/hi-file-parser/pull/2), [Stack#5134](https://github.com/commercialhaskell/stack/issues/5134)\\\\]\\n* Enhanced pretty-printing of coercions in Core dumps \\\\[[!4856](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/4856)\\\\]"},{"id":"2022-03-01-haskell-nix-february-update","metadata":{"permalink":"/2022-03-01-haskell-nix-february-update","source":"@site/blog/2022-03-01-haskell-nix-february-update-wDy26Ro4GN-import.md","title":"haskell.nix February Update","description":"Documentation","date":"2022-03-01T00:00:00.000Z","formattedDate":"March 1, 2022","tags":[{"label":"nix","permalink":"/tags/nix"}],"readingTime":1.275,"truncated":false,"authors":[],"frontMatter":{"slug":"2022-03-01-haskell-nix-february-update","title":"haskell.nix February Update","authors":[],"tags":["nix"],"custom_edit_url":null},"prevItem":{"title":"2021 GHC update","permalink":"/2022-03-01-2021-ghc-update"},"nextItem":{"title":"GHC January 2022 update","permalink":"/2022-02-01-ghc-january-2022-update"}},"content":"## Documentation\\n\\n* A tutorial has been added on [building DWARF-enabled executables](https://outline.zw3rk.com/share/d461004d-1f2f-4d7a-95f2-4e20acb18cac) on linux systems.  There was also a related fix for building DWARF executables in a nix shell ([#1385](https://github.com/input-output-hk/haskell.nix/pull/1385))\\n\\n## Changes\\n\\n* Support for external Hackage repositories was improved by [#1370](https://github.com/input-output-hk/haskell.nix/pull/1370). We can now use an extra package repository just by adding a `repository` block to the `cabal.project` file.  This makes it easy to make use of an extra hackage databases such as [hackage.head](https://ghc.gitlab.haskell.org/head.hackage/) and [hackage-overlay-ghcjs](https://github.com/input-output-hk/hackage-overlay-ghcjs).  A `sha256` for the repository it can be added as a comment in the `repository` block or by including it in the `sha256map` argument.\\n\\n## Version Updates\\n\\n* nix-tools was updated to use the Cabal 3.6.2 and hnix 0.16 [nix-tools#113](https://github.com/input-output-hk/nix-tools/pull/113)\\n* Nixpkgs pins were bumped [#1371](https://github.com/input-output-hk/haskell.nix/pull/1371)\\n* Update booting on aarch64 linux to ghc 8.8.4 [1325](https://github.com/input-output-hk/haskell.nix/pull/1325) and [1374](https://github.com/input-output-hk/haskell.nix/pull/1374)\\n\\n## Bug fixes\\n\\n* Allow linking pcre statically with musl [#1363](https://github.com/input-output-hk/haskell.nix/pull/1363)\\n* Add gpiod to system nixpkgs map [#1359](https://github.com/input-output-hk/haskell.nix/pull/1359)\\n* Add poppler-cpp to png-config Nixpkgs map [#1373](https://github.com/input-output-hk/haskell.nix/pull/1373)\\n* Use the same logic that cabal-install uses for determining the path of a packages `.tar.gz` in a repository  [nix-tools#114](https://github.com/input-output-hk/nix-tools/pull/114)\\n* Fix libnuma dependency in rts.conf [1342](https://github.com/input-output-hk/haskell.nix/commit/18ebf60137dd2ff1be7363eb46f67ebfa366d1dd)\\n* Fix when \\"materialized\\" dir is deep [#1376](https://github.com/input-output-hk/haskell.nix/pull/1376)\\n* Prefer local building for `git-ls-files` [#1378](https://github.com/input-output-hk/haskell.nix/pull/1378) and [#1381](https://github.com/input-output-hk/haskell.nix/issues/1381)\\n* Fix stack cache generator `sha256` is a string not a lambda [#1383](https://github.com/input-output-hk/haskell.nix/pull/1383)\\n* Only pass `--index-state` to `cabal` when asked [#1384](https://github.com/input-output-hk/haskell.nix/pull/1384)\\n* Pass `enableDWARF` to `makeConfigFiles` to fix `-g3` support in `nix-shell` [#1385](https://github.com/input-output-hk/haskell.nix/pull/1385)\\n\\nFinally, we\u2019d like to thank all the awesome contributors, who make\xa0`haskell.nix`\xa0a thriving open source project!\xa0:heart:"},{"id":"2022-02-01-ghc-january-2022-update","metadata":{"permalink":"/2022-02-01-ghc-january-2022-update","source":"@site/blog/2022-02-01-ghc-january-2022-update-jTlkXUxJSn-import.md","title":"GHC January 2022 update","description":"Hopefully 2022 should be the year GHC will get a JavaScript backend without relying on GHCJS. This month the team has been busy planning the work that needs to be done to get there!","date":"2022-02-01T00:00:00.000Z","formattedDate":"February 1, 2022","tags":[{"label":"ghc","permalink":"/tags/ghc"},{"label":"ghc-update","permalink":"/tags/ghc-update"}],"readingTime":0.9,"truncated":false,"authors":[{"name":"Sylvain Henry","title":"Haskell DevX Engineer @ IOG","email":"sylvain.henry@iohk.io","key":"sylvain"}],"frontMatter":{"slug":"2022-02-01-ghc-january-2022-update","title":"GHC January 2022 update","authors":["sylvain"],"tags":["ghc","ghc-update"],"custom_edit_url":null},"prevItem":{"title":"haskell.nix February Update","permalink":"/2022-03-01-haskell-nix-february-update"},"nextItem":{"title":"haskell.nix January Update","permalink":"/2022-02-01-haskell-nix-january-update"}},"content":"Hopefully 2022 should be the year GHC will get a JavaScript backend without relying on GHCJS. This month the team has been busy planning the work that needs to be done to get there!\\n\\n## Cross-compilation\\n\\n* GHCJS has been [updated](https://github.com/ghcjs/ghc/tree/ghc-8.10-ghcjs) to reduce the gap with GHC 8.10.7 codebase to the point that GHC\u2019s build system is used to build GHCJS\\n* Internal work planning for the integration of GHCJS into GHC\\n* A different approach to load plugins into cross-compilers has been implemented \\\\[[#20964](https://gitlab.haskell.org/ghc/ghc/-/issues/20964), [!7377](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7377)\\\\]\\n* GHCJS has been exercised to showcase compilation of some Plutus applications\\n\\n## Modularity\\n\\n* A few \u201csubsystems\u201d of GHC have been made more modular and reusable by making them independent of the command-line flags (`DynFlags`) \\\\[[#17957](https://gitlab.haskell.org/ghc/ghc/-/issues/17957), [!7158](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7158), [!7199](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7199), [!7325](https://gitlab.haskell.org/ghc/ghc/-/merge_requests/7325)\\\\]. This work resulted in a 10% reduction in call sites to `DynFlags` and has now removed all references to `DynFlags` up to the `CoreToStg` pass, which is almost the entire backend of GHC.\\n\\n## Performance\\n\\n* Jeffrey wrote a new HF [proposal](https://github.com/haskellfoundation/tech-proposals/pull/26) about writing a Haskell Optimization handbook and has started working on it"},{"id":"2022-02-01-haskell-nix-january-update","metadata":{"permalink":"/2022-02-01-haskell-nix-january-update","source":"@site/blog/2022-02-01-haskell-nix-january-update-vNau7aVn4Q-import.md","title":"haskell.nix January Update","description":"January 2022","date":"2022-02-01T00:00:00.000Z","formattedDate":"February 1, 2022","tags":[{"label":"nix","permalink":"/tags/nix"}],"readingTime":1.215,"truncated":false,"authors":[],"frontMatter":{"slug":"2022-02-01-haskell-nix-january-update","title":"haskell.nix January Update","authors":[],"tags":["nix"],"custom_edit_url":null},"prevItem":{"title":"GHC January 2022 update","permalink":"/2022-02-01-ghc-january-2022-update"}},"content":"## **January 2022**\\n\\nThis month we merged some very significant improvements to the support for compiling for Android and iOS based AArch64 devices.\xa0 When the build system is also AArch64 template haskell can often be run locally.\xa0 This will make targeting mobile devices from AArch64 builders much easier.\\n\\nA long running branch containing bug fixes for cross compilation to JavaScript with GHCJS was merged.\xa0 One nice feature included is better support for adding bindings to C code compiled with emscripten.\xa0 In some cases it can be as easy as adding a single JavaScript file to the package with wrappers for the C functions.\\n\\n#### Changes\\n\\n* Much improved AArch64 support including Template Haskell (#1316)\\n* Improved GHCJS and support for calling C code compiled with emscripten (#1311)\\n* The environment variables LANG and LOCALE_ARCHIVE are no longer set in shells allowing the users prefered settings to persist (#1341).\\n* source-repo-override argument added for cabal projects to allow the location of source-repository-package packages to be replaced (#1354)\\n\\n#### Version Updates\\n\\n* GHC 9.0.2 was added to the available GHC versions (#1338)\\n* The nixpkgs pins for 21.05, 21.11 and unstable were all updated (#1334).\\n* Remaining uses of cabal 3.4 were updated to 3.6.2 (#1328)\\n\\n#### Bug fixes\\n\\n* Dwarf build of ghc 9.2.1 now skipped on hydra to work around 4GB hydra limit (#1333)\\n* Removed use of propagatedBuildInputs in ghc derivation (#1318).\\n* Caching of the check-hydra CI script was fixed (#1340)"}]}')}}]);